<!doctype html><html lang=en><head><meta charset=utf-8><meta name=description content="Evergreen Notes."><title>Quant Apprentice.</title><meta name=viewport content="width=device-width,initial-scale=1"><link rel="shortcut icon" type=image/png href=../icon.png><script>MathJax={tex:{inlineMath:[["$","$"]]},displayMath:[["$$","$$"],["[[","]]"]],svg:{fontCache:"global"}}</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;700&family=Source+Sans+Pro:wght@400;700&family=Fira+Code:wght@400;700&display=swap" rel=stylesheet><style>:root{--light:#faf8f8;--dark:#141021;--secondary:#284b63;--tertiary:#84a59d;--visited:#afbfc9;--primary:#f28482;--gray:#4e4e4e;--lightgray:#f0f0f0;--outlinegray:#dadada}[saved-theme=dark]{--light:#1e1e21 !important;--dark:#fbfffe !important;--secondary:#5b778a !important;--visited:#4a575e !important;--tertiary:#84a59d !important;--primary:#f58382 !important;--gray:#d4d4d4 !important;--lightgray:#292633 !important;--outlinegray:#343434 !important}</style><style>:root{--lt-colours-light:var(--light) !important;--lt-colours-lightgray:var(--lightgray) !important;--lt-colours-dark:var(--secondary) !important;--lt-colours-secondary:var(--tertiary) !important;--lt-colours-gray:var(--outlinegray) !important}h1,h2,h3,h4,ol,ul,thead{font-family:Inter;color:var(--dark)}p,ul,text{font-family:source sans pro,sans-serif;color:var(--gray);fill:var(--gray)}a{font-family:Inter;font-weight:700;font-size:1em;text-decoration:none;transition:all .2s ease;color:var(--secondary)}a:hover{color:var(--tertiary)!important}#TableOfContents>ol{counter-reset:section;margin-left:0;padding-left:1.5em}#TableOfContents>ol>li{counter-increment:section}#TableOfContents>ol>li>ol{counter-reset:subsection}#TableOfContents>ol>li>ol>li{counter-increment:subsection}#TableOfContents>ol>li>ol>li::marker{content:counter(section)"." counter(subsection)"  "}#TableOfContents>ol>li::marker{content:counter(section)"  "}#TableOfContents>ol>li::marker,#TableOfContents>ol>li>ol>li::marker{font-family:Source Sans Pro;font-weight:700}footer{margin-top:4em;text-align:center}table{width:100%}img{width:100%;border-radius:3px;margin:1em 0}p>img+em{display:block;transform:translateY(-1em)}sup{line-height:0}p,tbody,li{font-family:Source Sans Pro;color:var(--gray);line-height:1.5em}h2{opacity:.85}h3{opacity:.75}blockquote{margin-left:0;border-left:3px solid var(--secondary);padding-left:1em;transition:border-color .2s ease}blockquote:hover{border-color:var(--tertiary)}table{padding:1.5em}td,th{padding:.1em .5em}.footnotes p{margin:.5em 0}article a{font-family:Source Sans Pro;font-weight:600;text-decoration:underline;text-decoration-color:var(--tertiary);text-decoration-thickness:.15em}sup>a{text-decoration:none;padding:0 .1em 0 .2em}pre{font-family:fira code;padding:.75em;border-radius:3px;overflow-x:scroll}code{font-family:fira code;font-size:.85em;padding:.15em .3em;border-radius:5px;background:var(--lightgray)}html{scroll-behavior:smooth}body{margin:0;height:100vh;width:100vw;overflow-x:hidden;background-color:var(--light)}@keyframes fadeIn{0%{opacity:0}100%{opacity:1}}footer{margin-top:4em}footer>a{font-size:1em;color:var(--secondary);padding:0 .5em 3em}hr{width:25%;margin:4em auto;height:2px;border-radius:1px;border-width:0;color:var(--dark);background-color:var(--dark)}a[href^="/"]{text-decoration:none;background-color:#afbfc922;padding:0 .2em;border-radius:3px}.singlePage{margin:4em 30vw}@media all and (max-width:1200px){.singlePage{margin:25px 5vw}}.page-end{display:flex;flex-direction:row}@media all and (max-width:780px){.page-end{flex-direction:column}}.page-end>*{flex:1 0}.page-end>.backlinks-container>ul{list-style:none;padding-left:0;margin-right:2em}.page-end>.backlinks-container>ul>li{margin:.5em 0;padding:.25em 1em;border:var(--outlinegray)1px solid;border-radius:5px}.page-end #graph-container{border:var(--outlinegray)1px solid;border-radius:5px}.centered{margin-top:30vh}header{display:flex;flex-direction:row;align-items:center}@media all and (max-width:600px){header>nav{display:none}}header>nav>a{margin-left:2em}header>.spacer{flex:auto}header>svg{cursor:pointer;width:18px;min-width:18px;margin:0 1em}header>svg:hover .search-path{stroke:var(--tertiary)}header>svg .search-path{stroke:var(--gray);stroke-width:2px;transition:stroke .5s ease}#search-container{position:fixed;z-index:9999;left:0;top:0;width:100vw;height:100vh;display:none;backdrop-filter:blur(4px);-webkit-backdrop-filter:blur(4px)}#search-container>div{width:50%;margin-top:15vh;margin-left:auto;margin-right:auto}@media all and (max-width:1200px){#search-container>div{width:90%}}#search-container>div>*{width:100%;border-radius:4px;background:var(--light);box-shadow:0 14px 50px rgba(27,33,48,.12),0 10px 30px rgba(27,33,48,.16);margin-bottom:2em}#search-container>div>input{box-sizing:border-box;padding:.5em 1em;font-family:Inter,sans-serif;color:var(--dark);font-size:1.1em;border:1px solid var(--outlinegray)}#search-container>div>input:focus{outline:none}#search-container>div>#results-container>.result-card{padding:1em;cursor:pointer;transition:background .2s ease;border:1px solid var(--outlinegray);border-bottom:none}#search-container>div>#results-container>.result-card:hover{background:rgba(180,180,180,.15)}#search-container>div>#results-container>.result-card:first-of-type{border-top-left-radius:5px;border-top-right-radius:5px}#search-container>div>#results-container>.result-card:last-of-type{border-bottom-left-radius:5px;border-bottom-right-radius:5px;border-bottom:1px solid var(--outlinegray)}#search-container>div>#results-container>.result-card>h3,#search-container>div>#results-container>.result-card>p{margin:0}#search-container>div>#results-container>.result-card .search-highlight{background-color:#afbfc966;padding:.05em .2em;border-radius:3px}</style><style>.darkmode{float:right;padding:1em;min-width:30px;position:relative}@media all and (max-width:450px){.darkmode{padding:1em}}.darkmode>.toggle{display:none;box-sizing:border-box}.darkmode svg{opacity:0;position:absolute;width:20px;height:20px;top:calc(50% - 10px);margin:0 7px;fill:var(--gray);transition:opacity .1s ease}.toggle:checked~label>#dayIcon{opacity:0}.toggle:checked~label>#nightIcon{opacity:1}.toggle:not(:checked)~label>#dayIcon{opacity:1}.toggle:not(:checked)~label>#nightIcon{opacity:0}</style><style>.chroma{color:#f8f8f2;background-color:#282a36}.chroma .lntd{vertical-align:top;padding:0;margin:0;border:0}.chroma .lntable{border-spacing:0;padding:0;margin:0;border:0;width:auto;overflow:auto;display:block}.chroma .hl{display:block;width:100%;background-color:#ffc}.chroma .lnt{margin-right:.4em;padding:0 .4em;color:#7f7f7f}.chroma .ln{margin-right:.4em;padding:0 .4em;color:#7f7f7f}.chroma .k{color:#ff79c6}.chroma .kc{color:#ff79c6}.chroma .kd{color:#8be9fd;font-style:italic}.chroma .kn{color:#ff79c6}.chroma .kp{color:#ff79c6}.chroma .kr{color:#ff79c6}.chroma .kt{color:#8be9fd}.chroma .na{color:#50fa7b}.chroma .nb{color:#8be9fd;font-style:italic}.chroma .nc{color:#50fa7b}.chroma .nf{color:#50fa7b}.chroma .nl{color:#8be9fd;font-style:italic}.chroma .nt{color:#ff79c6}.chroma .nv{color:#8be9fd;font-style:italic}.chroma .vc{color:#8be9fd;font-style:italic}.chroma .vg{color:#8be9fd;font-style:italic}.chroma .vi{color:#8be9fd;font-style:italic}.chroma .s{color:#f1fa8c}.chroma .sa{color:#f1fa8c}.chroma .sb{color:#f1fa8c}.chroma .sc{color:#f1fa8c}.chroma .dl{color:#f1fa8c}.chroma .sd{color:#f1fa8c}.chroma .s2{color:#f1fa8c}.chroma .se{color:#f1fa8c}.chroma .sh{color:#f1fa8c}.chroma .si{color:#f1fa8c}.chroma .sx{color:#f1fa8c}.chroma .sr{color:#f1fa8c}.chroma .s1{color:#f1fa8c}.chroma .ss{color:#f1fa8c}.chroma .m{color:#bd93f9}.chroma .mb{color:#bd93f9}.chroma .mf{color:#bd93f9}.chroma .mh{color:#bd93f9}.chroma .mi{color:#bd93f9}.chroma .il{color:#bd93f9}.chroma .mo{color:#bd93f9}.chroma .o{color:#ff79c6}.chroma .ow{color:#ff79c6}.chroma .c{color:#6272a4}.chroma .ch{color:#6272a4}.chroma .cm{color:#6272a4}.chroma .c1{color:#6272a4}.chroma .cs{color:#6272a4}.chroma .cp{color:#ff79c6}.chroma .cpf{color:#ff79c6}.chroma .gd{color:#8b080b}.chroma .ge{text-decoration:underline}.chroma .gh{font-weight:700}.chroma .gi{font-weight:700}.chroma .go{color:#44475a}.chroma .gu{font-weight:700}.chroma .gl{text-decoration:underline}.lntd:first-of-type>.chroma{padding-right:0}.chroma code{font-family:fira code!important;font-size:.85em;line-height:1em;background:0 0;padding:0}.chroma{border-radius:3px;margin:0}</style><script>const userPref=window.matchMedia('(prefers-color-scheme: light)').matches?'light':'dark',currentTheme=localStorage.getItem('theme')??userPref;currentTheme&&document.documentElement.setAttribute('saved-theme',currentTheme);const switchTheme=a=>{a.target.checked?(document.documentElement.setAttribute('saved-theme','dark'),localStorage.setItem('theme','dark')):(document.documentElement.setAttribute('saved-theme','light'),localStorage.setItem('theme','light'))};window.addEventListener('DOMContentLoaded',()=>{const a=document.querySelector('#darkmode-toggle');a.addEventListener('change',switchTheme,!1),currentTheme==='dark'&&(a.checked=!0)})</script></head><body><div id=search-container><div><input autocomplete=off id=search-bar name=search type=text aria-label=Search placeholder="Search for something..."><div id=results-container></div></div></div><script src=https://cdn.jsdelivr.net/gh/nextapps-de/flexsearch@0.7.2/dist/flexsearch.bundle.js></script><script>const removeMarkdown=(c,b={listUnicodeChar:!1,stripListLeaders:!0,gfm:!0,useImgAltText:!1,preserveLinks:!1})=>{let a=c||"";a=a.replace(/^(-\s*?|\*\s*?|_\s*?){3,}\s*$/gm,"");try{b.stripListLeaders&&(b.listUnicodeChar?a=a.replace(/^([\s\t]*)([\*\-\+]|\d+\.)\s+/gm,b.listUnicodeChar+" $1"):a=a.replace(/^([\s\t]*)([\*\-\+]|\d+\.)\s+/gm,"$1")),b.gfm&&(a=a.replace(/\n={2,}/g,"\n").replace(/~{3}.*\n/g,"").replace(/~~/g,"").replace(/`{3}.*\n/g,"")),b.preserveLinks&&(a=a.replace(/\[(.*?)\][\[\(](.*?)[\]\)]/g,"$1 ($2)")),a=a.replace(/<[^>]*>/g,"").replace(/^[=\-]{2,}\s*$/g,"").replace(/\[\^.+?\](\: .*?$)?/g,"").replace(/\s{0,2}\[.*?\]: .*?$/g,"").replace(/\!\[(.*?)\][\[\(].*?[\]\)]/g,b.useImgAltText?"$1":"").replace(/\[(.*?)\][\[\(].*?[\]\)]/g,"$1").replace(/^\s{0,3}>\s?/g,"").replace(/(^|\n)\s{0,3}>\s?/g,"\n\n").replace(/^\s{1,2}\[(.*?)\]: (\S+)( ".*?")?\s*$/g,"").replace(/^(\n)?\s{0,}#{1,6}\s+| {0,}(\n)?\s{0,}#{0,} {0,}(\n)?\s{0,}$/gm,"$1$2$3").replace(/([\*_]{1,3})(\S.*?\S{0,1})\1/g,"$2").replace(/([\*_]{1,3})(\S.*?\S{0,1})\1/g,"$2").replace(/(`{3,})(.*?)\1/gm,"$2").replace(/`(.+?)`/g,"$1").replace(/\n{2,}/g,"\n\n")}catch(a){return console.error(a),c}return a}</script><script>const contentIndex=new FlexSearch.Worker({tokenize:"strict",charset:"latin:advanced",context:!0,depth:3,cache:10,suggest:!0}),scrapedContent={"/":{content:"Do not go gentle into that good night.\n\nRage, rage against the dying of the light. \n\n\n[[MOC|Map of Contents]]\n\n---\n\n\n\n\n\n",title:"Untitled Page"},"/ANOVA":{content:"---\nArea: Statistics\nSource: Book\nStatus: Todo\nType: Notes\n---\n\n\n## ANOVA\n\nANOVA permits comparisons of multiple populations and even subgroups.\n\n### One-way ANOVA\n\nThe design matrix has a special form:\n\n$$\\mathbf{X}=\\left[\\begin{array}{cccc}1 \u0026 0 \u0026 0 \u0026 0 \\\\\u0026 \\vdots \u0026 \u0026 \\\\1 \u0026 0 \u0026 0 \u0026 0 \\\\0 \u0026 1 \u0026 0 \u0026 0 \\\\\u0026 \\vdots \u0026 \u0026 \\\\0 \u0026 1 \u0026 0 \u0026 0 \\\\0 \u0026 0 \u0026 1 \u0026 0 \\\\\u0026 \\vdots \u0026 \u0026 \\\\0 \u0026 0 \u0026 1 \u0026 0 \\\\0 \u0026 0 \u0026 0 \u0026 1 \\\\\u0026 \\vdots \u0026 \u0026 \\\\0 \u0026 0 \u0026 0 \u0026 1\\end{array}\\right]$$\n\n#### Partitioning a Sum of Squares\n\n$$ S_{\\mathrm{Tot}}^{2}=S_{\\mathrm{Resid}}^{2}+S_{\\mathrm{Betw}}^{2}\n\n$$\n\n$$ S_{\\text {Resid }}^{2}=\\sum_{i=1}^{p} \\sum_{j=1}^{n_{i}}\\left(Y_{i j}-\\bar{Y}_{i+}\\right)^{2}, S_{\\text {Betw }}^{2}=\\sum_{i=1}^{p} n_{i}\\left(\\bar{Y}_{i+}-\\bar{Y}_{++}\\right)^{2} ,S_{\\mathrm{Tot}}^{2}=\\sum_{i=1}^{p} \\sum_{j=1}^{n_{i}}\\left(Y_{i j}-\\bar{Y}_{++}\\right)^{2}$$\n\n-   $\\bar Y_{++}$ is the overall average of all n observations.\n-   $S_{Resid}^2 /\\sigma^2$ has the $\\chi^2$ distribution with $n- p$ degrees of freedom and is independent of $S_{Betw}$.\n\n#### Testing Hypotheses\n\n$$U ^2 = \\frac{S_{Betw}^ 2 /(p - 1)}{S_{Resid}^2/(n-p)}$$\n\nhas the $F$ distribution with $p - 1$ and $n - p$ degrees of freedom.\n\nImportant ratio:\n\n$$\\frac{\\text{Variability AMONG/BETWEEN the means}}{\\text{Variability AROUND/WITHIN the distributions}}$$\n\n-   If the variabitlity BETWEEN the means (distance from overall mean) in the numerator is relatively large compared to the variance WITHIN the samples (internal spread) in the denominator, the ratio will be much larger than 1. The samples then most likely do NOT come from a common population; REJECT Null Hypothesis that mean(s) are equal.\n\n### Two-way ANOVA\n",title:"Untitled Page"},"/Data Preprocessing and EDA":{content:"---\nArea: Coding\nSource: Website\nStatus: Ongoing\nType: Notes\n---\n\n## Rows and Columns\n\nSlice with labels for row and single label for column. As mentioned above, note that both the start and stop of the slice are included.\n\n```python\ndf.loc['cobra':'viper', 'max_speed']\n```\n\nBoolean list with the same length as the row axis\n\n```python\ndf.loc[[False, False, True]]\n```\n\nConditional that returns a boolean Series\n\n```python\ndf.loc[df['shield'] \u003e 6] \ndf.loc[df['shield'] \u003e 6, ['max_speed']] \ndf.loc[**lambda** df: df['shield'] == 8]\n```\n\nFor Series, the row labels are prefixed. For DataFrame, the column labels are prefixed.\n\n```python\ndf.add_prefix('col_')\ndf.add_suffix('_col')\n```\n\nPossible values or ranges\n\nList the theoretical limits on the values and validate against the data.\n\n## Types and Formats\n\n### Data Types\n\nCreate a series:\n\n```python\nser = pd.Series([1, 2], dtype='int32')\nser.astype('int64')\n```\n\nConvert to categorical type:\n\n```python\nser.astype('category')\n```\n\nConvert to ordered categorical type with custom ordering:\n\n```python\ncat_dtype = pd.api.types.CategoricalDtype(categories=[2, 1], ordered=**True**)\nser.astype(cat_dtype)\n```\n\n### Data Formats\n\n```python\npd.to_datetime(data_311['created_date'], format='%m/%d/%Y %I:%M:%S %p')\n\npd.to_datetime([1, 2, 3], unit='D',origin=pd.Timestamp('1960-01-01'))\n#DatetimeIndex(['1960-01-02', '1960-01-03', '1960-01-04'], dtype='datetime64[ns]', freq=None)\n\nfrom datetime import date\nwater_quality[\"Week\"] = water_quality['created_date_time'].apply(lambda x: x.strftime(\"%w\"))\nwater_quality[\"Day\"] = water_quality['created_date_time'].apply(lambda x: x.strftime(\"%x\"))\nwater_quality[\"Year\"] = water_quality['created_date_time'].apply(lambda x: x.year)\nwater_quality[\"Month\"] = water_quality['created_date_time'].apply(lambda x: x.strftime(\"%b\"))\n\nwater_quality[\"year_month\"] = water_quality['created_date_time'].apply(\n    lambda x: date(year=x.year, month=x.month, day=1)\n)\n\n#change month name to string num\nd={'July':'07', 'August':'08', 'September':'09', 'October':'10', 'November':'11', 'December':'12',\\\\\n   'January':'01', 'February':'02', 'March':'03', 'April':'04', 'May':'05', 'June':'06'}\nresort_hotel.loc[:,'month_num']=resort_hotel['arrival_date_month'].map(d)\n\n#change year to str\nresort_hotel.loc[:,'arrival_date_year']=resort_hotel['arrival_date_year'].apply(\n    lambda x :str(x))\n#change 1 to 01 day\nresort_hotel.loc[:,'arrival_date_day_of_month']=resort_hotel['arrival_date_day_of_month'].apply(\n    lambda x:(len(str(x)) ==1 and '0'+str(x)) or str(x))\n```\n\n## Missing Values\n\n### Drop NAs\n\n```python\ndf.dropna(self, axis=0, how='any', thresh=None, subset=None, inplace=False)\n# how=‘any’ : If any NA values are present, drop that row or column.\n# how=‘all’ : If all values are NA, drop that row or column.\ndf.dropna(how='all') \n# Keep only the rows with at least 2 non-NA values.\ndf.dropna(thresh=2) \n# Define in which columns to look for missing values.\ndf.dropna(subset=['name', 'born'])\n\n```\n\n### Fill NAs\n\n```python\ndf.fillna(self, value=None, method=None, axis=None, inplace=False, limit=None, downcast=None)\n```\n\n### Percentage of missing values and visualizations\n\n## Duplications\n\n```python\ndf.drop_duplicates(['k'])\n# keep{‘first’, ‘last’, False}, default ‘first’:\n# Determines which duplicates (if any) to keep.\n# - first: Drop duplicates except for the first occurrence. \n# - last: Drop duplicates except for the last occurrence. \n# - False: Drop all duplicates.\n```\n\n## Numerical Summarization\n\nUse summary statistics to find out the moments.\n\n-   [ ] Locations\n    \n    Mean, median, quartiles, mode...\n    \n-   [ ] Spreads\n    \n    range, variance, standard deviation, IQR\n    \n-   [ ] Skewness\n    \n    asymmetries\n    \n-   [ ] Kurtosis\n    \n\n## Distributions\n\nVisualize the distributions of the values\n\n### Value count bar plot\n\n```python\ndf.groupby(\"descriptor\").size().plot(kind=\"barh\", title=\"Requests by Descriptor\")\n```\n\n### Stack bar plot\n\n```python\norder_ratio=resort_hotel.pivot_table(\n    index='Year-Month', columns='reservation_status', \n    values='is_canceled', aggfunc=len\n)\n\np1 = plt.bar(order_ratio.index,'Check-Out', width=10,data=order_ratio)\np2 = plt.bar(order_ratio.index,'Canceled',bottom='Check-Out',width=10,data=order_ratio)\np3=plt.bar(order_ratio.index,'No-Show',bottom='Check-Out',width=10,data=order_ratio)\n#plt.ylabel('Scores')\nplt.title('Reservation Status of Booking Orders Per Month ')\n#plt.xticks(ind, ('G1', 'G2', 'G3', 'G4', 'G5'))\n#plt.yticks(np.arange(0, 81, 10))\nplt.legend((p1[0], p2[0],p3[0]), ('Check-Out', 'Canceled','No-Show'))\n\nplt.show()\n```\n\n![https://s3-us-west-2.amazonaws.com/secure.notion-static.com/2dfbdcaa-5d48-488b-947b-35035413d0ea/Untitled.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/2dfbdcaa-5d48-488b-947b-35035413d0ea/Untitled.png)\n\n### Histogram\n\n```python\nplt.hist(water_quality['solving_time_num'],bins=100)\n```\n\n### KDE\n\n```python\nimport seaborn as sns\n\nsns.distplot(quick_solve['solving_time_num'], hist=True, kde=True, \n             bins=int(180/5), \n             hist_kws={'edgecolor':'red'},\n             kde_kws={'linewidth': 4})\n```\n\n### Box plot\n\n```python\ndf.boxplot(column='solving_time_num',by='borough')\n```\n\n### Point plot\n\n```python\nimport seaborn as sns\nfig1=plt.figure()\nax1 = fig1.add_subplot(211)\nax1=sns.pointplot(y=\"meal\", x=\"is_canceled\",data=resort_hotel,join=False,capsize=.05)\nax1.set(xlim=(0,1))\nax2 = fig1.add_subplot(212)\nax2=sns.pointplot(y=\"customer_type\", x=\"is_canceled\",data=resort_hotel,join=False,capsize=.05)\nax2.set(xlim=(0,1))\n\nfig2=plt.figure()\nax4 = fig2.add_subplot(211)\nax4=sns.pointplot(y=\"reserved_room_type\", x=\"is_canceled\",data=resort_hotel,join=False,capsize=.1)\nax4.set(xlim=(0,1))\nax5 = fig2.add_subplot(212)\nax5=sns.pointplot(y=\"market_segment\", x=\"is_canceled\",data=resort_hotel,join=False,capsize=.1)\nax5.set(xlim=(0,1))\n```\n\n![https://s3-us-west-2.amazonaws.com/secure.notion-static.com/92410985-9ea9-43f6-8261-104d82c6df2d/Untitled.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/92410985-9ea9-43f6-8261-104d82c6df2d/Untitled.png)\n\n### Pivot table plot\n\n```python\nwater_quality.pivot_table(\n    index='year_month', columns='borough', \n    values='solving_time_num', aggfunc=len\n).plot().legend(loc='center right', bbox_to_anchor=(1.2, 0.5))\n```\n\n### Geography\n\n```python\nplt.scatter(water_quality['longitude'],water_quality['latitude'],alpha=1,s=20)\nplt.xlabel('Longitude')\nplt.ylabel('Latitude')\nplt.show()\n\n# 3 dims\nplt.scatter(water_quality['longitude'],water_quality['latitude'],c=water_quality['solving_time_num'])\nplt.clim(0,100)\nplt.colorbar()\n```\n\n![https://s3-us-west-2.amazonaws.com/secure.notion-static.com/a870cb5b-ac78-496e-ab5d-1eccc137395c/Untitled.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/a870cb5b-ac78-496e-ab5d-1eccc137395c/Untitled.png)\n\n```python\n# Categories of geography\nfig1=plt.figure()\ndescriptor=list(water_quality['descriptor'].unique())\nc=['#c41832','#ef342a','#a84d18','#f68f26','#faca07','#07594a',\n   '#4ba946','#5fc0a7','#0376c2','#6dade2','#4dc7ec','#a8b7d8','#b8a1a9','#f8c9cb','#f2f1f6']\nfor index in range(14):\n    longi = water_quality.loc[water_quality['descriptor'] == descriptor[index]]['longitude']\n    lati = water_quality.loc[water_quality['descriptor'] == descriptor[index]]['latitude']\n    plt.scatter(longi, lati,c=c[index],cmap='brg',alpha=1,s=20)  \n\nax = fig1.gca()\nplt.xlabel('Longitude')\nplt.ylabel('Latitude')\n#added this to get the legend to work\nhandles,labels = ax.get_legend_handles_labels()\nax.legend(handles, labels = descriptor, loc='center right', bbox_to_anchor=(1.5, 0.5))\n\nplt.show()\n```\n\n![https://s3-us-west-2.amazonaws.com/secure.notion-static.com/be4182d1-b8ea-4432-b8ca-4ce67a4c6311/Untitled.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/be4182d1-b8ea-4432-b8ca-4ce67a4c6311/Untitled.png)\n\n### Contour plot\n\n## Bin values into discrete intervals\n\n```python\npd.cut([0, 1, 1, 2], bins=4, labels=False)\n# Quantile-based discretization function.\npd.qcut(range(5), 3, labels=[\"good\", \"medium\", \"bad\"])\n\nresort_hotel['stays_in_weekend_nights'].apply(lambda x :(x\u003e4 and '\u003e4') or str(x))\n```\n\n## Dummy variables\n\n```python\npd.get_dummies(water_quality['descriptor'],prefix='descriptor')\npd.get_dummies(pd.cut(values,bins)\n```\n\n## Dispersion of the target value\n\nIs the dispersion of the target value small enough for the algorithm to perform a good prediction?\n\n## Correlations and Similarities\n\n### Pairplot\n\n### Correlations\n\nPearson, Kendall Tau Correlation\n\n```python\nfig, ax = plt.subplots()\nim = ax.imshow(resort_hotel_le[categoricals].corr())\n\n# We want to show all ticks...\nax.set_xticks(np.arange(len(categoricals)))\nax.set_yticks(np.arange(len(categoricals)))\n# ... and label them with the respective list entries\nax.set_xticklabels(categoricals)\nax.set_yticklabels(categoricals)\n\n# Rotate the tick labels and set their alignment.\nplt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n         rotation_mode=\"anchor\")\n\nax.set_title(\"Correlation between Each Feature\")\nfig.tight_layout()\nplt.show()\n```\n\n### Distances\n\nCalculate the distance between features or rows to understand the relations between them; Euclidean distance, Mahalanobis distance, Minkowski distance, Jaccard distance\n\n## Combining Data Files\n\n### Merge\n\n```python\npd.merge(left, right, how= 'inner', on=None, left_on=None, right_on=None)\n# how: inner, outer, left, right\n```\n\n### Concat\n\n```python\npd.concat([s1,s2],axis=1)# if with same index\n```\n\n## Reshape\n\n### Stack and unstack\n\n```python\n#Single level columns\ndf_single_level_cols = pd.DataFrame([[0, 1], [2, 3]],\n                                    index=['cat', 'dog'],\n                                    columns=['weight', 'height'])\n#Stacking a dataframe with a single level column axis returns a Series:\ndf_single_level_cols\n#     weight height\n#cat       0      1\n#dog       2      3\ndf_single_level_cols.stack()\n#cat  weight    0\n#     height    1\n#dog  weight    2\n#     height    3\n\n#Multi level columns: simple case\n\nmulticol1 = pd.MultiIndex.from_tuples([('weight', 'kg'),\n                                       ('weight', 'pounds')])\ndf_multi_level_cols1 = pd.DataFrame([[1, 2], [2, 4]],\n                                    index=['cat', 'dog'],\n                                    columns=multicol1)\n#Stacking a dataframe with a multi-level column axis:\n\ndf_multi_level_cols1\n#     weight\n#         kg    pounds\n#cat       1        2\n#dog       2        4\ndf_multi_level_cols1.stack()\n#            weight\n#cat kg           1\n#    pounds       2\n#dog kg           2\n#    pounds       4\n```\n\n### Pivot table and melt\n\n```python\ntable = pd.pivot_table(df, values=['D', 'E'], index=['A', 'C'],\n                    aggfunc={'D': np.mean,\n                             'E': [min, max, np.mean]})\n\ndf = pd.DataFrame({'A': {0: 'a', 1: 'b', 2: 'c'},\n                   'B': {0: 1, 1: 3, 2: 5},\n                   'C': {0: 2, 1: 4, 2: 6}})\n#df\n#   A  B  C\n#0  a  1  2\n#1  b  3  4\n#2  c  5  6\n\ndf.melt(id_vars=['A'], value_vars=['B'],\n        var_name='myVarname', value_name='myValname')\n#   A myVarname  myValname\n#0  a         B          1\n#1  b         B          3\n#2  c         B          5\n```\n\n### Crosstab\n\n```python\npd.crosstab(data.Nationality,data.Handedness,margin=True)\n```\n\n## Group by and Agg\n\n```python\nprices['Return']=prices.groupby('Code')['Close'].apply(lambda x:x/x.shift(1)-1)\n\ntips.groupby(['day','smoker'],as_index=False).mean()\n\nframe=pd.DataFrame({'data1':np.random.randn(1000),\n'data2':np.random.randn(1000)})\nquartiles=pd.cut(frame.data1,4)\ndef get_stats(group):\n	return {'min':group.min(),'max':group.max(),'count':group.count(),'mean':group.mean()}\ngrouped=frame.data2.groupby(quartiles)\ngrouped.apply(get_stats).unstack()\n\n# fill NA by group\ndata.groupby(group_key).apply(lambda g:g.fillna(g.mean()))\n\n# regression\nimport statsmodels.api as sm\ndef regress(data,yvar,xvars):\n	Y=data[yvar]\n	X=data[xvars]\n	X['intercept']=1.\n	result=sm.OLS(Y,X).fit()\n	return result.params\nby_year.apply(regress,'AAPL',['SPX'])\n```\n\n## Objectives of EDA\n\n### Polish the Questions\n\nCheck if the questions to be answered are valid or well stated; If not, modify them or come up with new ones\n\n### Validate Data I/O Methods\n\nCheck and validate the methods to load and save the datasets\n\n### Retrieve Domain Knowledge and Anomalies\n\nDetermine the ranges, outliers of the dataset; Talk to domain experts and validate with domain experts.\n\n### Does the result make sense?",title:"Untitled Page"},"/Financial Time Series Analysis":{content:"---\nArea: Statistics\nSource: Book\nStatus: Todo\nType: Notes\n---\n\n## 1 线性时间序列模型\n\n### 1.1 平稳性\n\n**时间序列**：设有随机变量序列 $\\{ x_t, t=\\dots, -2, -1, 0, 1, 2, \\dots \\}$， 称其为一个时间序列。\n\n**自协方差函数**： 时间序列$\\{ X_t \\}$中两个随机变量的协方差 $\\text{Cov}(X_s, X_t)$叫做自协方差。 如果$\\text{Cov}(X_s, X_t) = \\gamma_{|t-s|}$仅依赖于t-s， 则称\n$$\n\\gamma_k = \\text{Cov}(X_{t-k}, X_t), k=0,1,2,\\dots\n$$\n为时间序列$\\{X_t \\}$的自协方差函数。\n\n**弱平稳序列**(宽平稳序列，weakly stationary time series): 如果时间序列$\\{ X_t \\}$存在有限的二阶矩且满足：\n\n (1) $EX_t = \\mu$与$t$无关；\n\n (2) $\\text{Var}(X_t) = \\gamma_0$与$t$无关;\n\n (3) $\\gamma_k = \\text{Cov}(X_{t-k}, X_t), k=1,2,\\dots$与$t$无关，\n\n则称$\\{ X_t \\}$为弱平稳序列。\n\n适当条件下可以用时间序列的样本估计自协方差函数， 这是用一条轨道的信息推断所有实验结果$\\Omega$， 估计公式为\n$$\n\\hat\\gamma_k = \\frac{1}{T} \\sum_{t=k+1}^T (x_{t-k} - \\bar x)(x_t - \\bar x), k=0,1,\\dots, T-1\n$$\n称$\\hat\\gamma_k$为样本自协方差。 注意这里用了$1/T$而不是$1/(T-k)$，用$1/(T-k)$在获得无偏性的同时会造成一些理论上的困难。\n\n\n\n### 1.2 相关系数和自相关函数\n\n#### 1.2.1 相关系数\n\n两个随机变量X和Y的相关系数定义为\n$$\n\\rho(X,Y) = \\rho_{xy} = \\frac{\\text{Cov}(X,Y)}{\\sqrt{\\text{Var}(X) \\text{Var}(Y)}} = \\frac{E[(X-\\mu_x)(Y-\\mu_y)]}{\\sqrt{E(X-\\mu_x)^2 E(Y-\\mu_y)^2}}\n$$\n\n\n如果有$(X,Y)$的独立同分布样本$(x_t, y_t)， t=1,2,\\dots,T$， 可估计相关系数为\n$$\n\\hat\\rho_{xy} = \\frac{\\sum_{t=1}^T (x_t - \\bar x)(y_t - \\bar y)} {\\sqrt{\\sum_{t=1}^T (x_t - \\bar x)^2 \\sum_{t=1}^T (y_t - \\bar y)^2}}\n$$\n#### 1.2.2 自相关函数\n\n设$\\{X_t \\}$为弱平稳序列， $\\{ \\gamma_k \\}$为自协方差函数。 则\n$$\n\\rho(X_{t-k}, X_t)  = \\frac{\\text{Cov}(X_{t-k}, X_t)}{\\sqrt{\\text{Var}(X_{t-k})\\text{Var}(X_{t})}} = \\frac{\\gamma_k}{\\sqrt{\\gamma_0 \\gamma_0}} = \\frac{\\gamma_k}{\\gamma_0}, \\ k=0,1,\\dots, \\ \\forall t\n$$\n记$\\rho_k = \\gamma_k / \\gamma_0$，这是$X_{t-k}$与$X_t$的相关系数且与$t$无关， 称$\\{ \\rho_k, k=0,1,\\dots \\}$为时间序列$\\{ X_t \\}$的自相关函数 （Autocorrelation function, ACF）。\n\n适当条件下$\\rho_k$可以从时间序列样本估计为\n$$\n\\hat\\rho_k = \\frac{\\hat\\gamma_k}{\\hat\\gamma_0},\\  k=0,1,\\dots\n$$\n称$\\hat\\rho_k, k=1,2,\\dots$为样本自相关函数。\n\n#### 1.2.3 用单个自相关系数作白噪声检验\n\n如果$\\{ X_ t \\}$是独立同分布白噪声， 则$\\rho_k(k\\geq 1)$近似$\\text{N}(0, 1/T)$。 若$H_0$是序列为白噪声， 取统计量\n$$\nt = \\sqrt{T} \\hat\\rho_k\n$$\n\n如果$|t| \u003e \\text{qnorm}(1-\\alpha/2)$， 则拒绝白噪声零假设。 实际中常取$\\alpha=0.05, \\text{qnorm}(1-\\alpha/2) \\approx 2$， 当$\\hat\\rho_1$超出$\\pm 2 /\\sqrt{T}$则拒绝$H_0$\n\n#### 1.2.4 Ljung-Box白噪声检验\n\n为了检验时间序列样本是否来自白噪声序列， 可以检验$\\rho_k=0, k=1,2,\\dots$的零假设。 前面检验单个$\\rho_k$的做法如果针对多个进行检验就有多重检验的第一类错误增大的问题。\n\nLjung和Box对此检验方法进行了改进。 统计量改为\n$$\nQ(m) = T(T+2) \\sum_{j=1}^m \\frac{\\hat\\rho_j^2}{T-j}\n$$\n在独立同分布白噪声假设下仍近似服从$\\chi^2(m)$分布。 当\n$$\nQ(m) \u003e \\text{qchisq}(1-\\alpha, m)\n$$\n时拒绝$H_0$， 否定白噪声假设。这个检验称为Ljung-Box白噪声检验。 如果检验的序列是线性时间序列估计的残差序列， 则卡方自由度应改为$m$减去估计的系数个数。\n\nLjung-Box检验受到$m$取值的影响， 建议采用$m \\approx \\ln T$，且序列为季度、月度这样的周期序列时， $m$应取为周期的整数倍。\n\n### 1.3 白噪声和线性时间序列\n\n设$\\{ X_t \\}$是独立同分布的二阶矩有限的随机变量， 称$\\{ X_t \\}$为独立同分布白噪声(white noise)。 最常用的白噪声一般假设均值为零。 如果$\\{ X_t \\}$独立同$\\text{N}(0, \\sigma^2)$分布， 称$\\{ X_t \\}$为高斯(Gaussian)白噪声或正态白噪声。\n\n## 2 自回归模型\n\n### 2.1 AR(1)模型的性质\n\nAR(1)：\n$$\n\\begin{align}\nX_t = \\phi_0 + \\phi_1 X_{t-1} + \\varepsilon_t\n\\end{align}\n$$\n\nAR(1)模型要求$|\\phi_1|\u003c1$，$\\{ X_t \\}$有弱平稳解的充分必要条件。\n\n必要性证明： 如果模型有弱平稳解$X_t$， 因为要求$\\varepsilon_t$与$X_{t-1}, X_{t-2}, \\dots$独立， 在模型两边求方差得\n$$\n\\begin{aligned} \u0026 \\text{Var}(X_t) = \\text{Var}(\\phi_0 + \\phi_1 X_{t-1} + \\varepsilon_t) = \\phi_1^2 \\text{Var}(X_{t-1}) + \\sigma^2, \\\\ \u0026 \\sigma_X^2 = \\phi_1^2 \\sigma_X^2 + \\sigma^2, \\\\ \u0026 \\sigma_X^2 = \\frac{\\sigma^2}{1 - \\phi_1^2} \\end{aligned}\n$$\n因为$\\sigma_X^2\u003e0$,所以$1-\\phi_1^2\u003e0,|\\phi_1|\u003c1$。\n\n上述证明过程也证明了\n$$\n\\mu=EX_t = \\frac{\\phi_0}{1 - \\phi_1}, \\quad \\sigma_X = \\text{Var}(X_t) = \\frac{\\sigma^2}{1 - \\phi_1^2} .\n$$\n\n### 2.2 AR(1)模型的自相关函数\n\nAR(1)模型的平稳解满足$\\epsilon_t$与$X_{t-1}, X_{t-2}, \\dots$独立。 \n$$\n\\begin{align} \\gamma_0 =\u0026 \\sigma_X^2 = \\frac{\\sigma^2}{1 - \\phi_1^2} = \\phi_1 \\gamma_1 + \\sigma^2 \\\\ \\gamma_j =\u0026 \\phi_1 \\gamma_{j-1}, \\ j=1,2,\\dots \\end{align}\n$$\n\n于是ACF为\n$$\n\\rho_j = \\frac{\\gamma_j}{\\gamma_0} = \\phi_1^j, \\ j=1,2,\\dots\n$$\n\n当$0\u003c\\phi_1 \u003c 1$时， ACF为正的单调下降序列， 以负指数速度（几何级数）下降。 当$-1 \u003c \\phi_1 \u003c 0$时， ACF为负正交替的序列， 绝对值以负指数速度下降。\n\n### 2.3 AR(2)模型的性质\n\nAR(2)模型为\n$$\n\\begin{align}\nX_t = \\phi_0 + \\phi_1 X_{t-1} + \\phi_2 X_{t-2} + \\varepsilon_t\n\\end{align}\n$$\n\n其中$\\{\\varepsilon_t \\}$为独立同分布的零均值白噪声,$ \\varepsilon_t$与$X_{t-1}, X_{t-2}, \\dots$独立。 系数满足特征方程的根都在单位圆外。 特征方程为\n\n$$\n\\begin{align}\n1 - \\phi_1 z - \\phi_2 z^2 = 0\n\\tag{4.5}\n\\end{align}\n$$\n\n这个模型有因果线性时间序列形式的弱平稳解。 对(4.4)两边取期望得$\\mu=EX_t$的方程\n$$\n\\mu = \\phi_0 + \\phi_1 \\mu + \\phi_2 \\mu\n$$\n所以\n$$\n\\mu = \\frac{\\phi_0}{1 - \\phi_1 - \\phi_2}\n$$\n\n$X_t$减去$\\mu$， 方程变成\n$$\n\\begin{align}\nX_t - \\mu = \\phi_1 (X_{t-1}-\\mu) + \\phi_2 (X_{t-2}-\\mu) + \\varepsilon_t\n\n\\end{align}\n$$\n两边乘以$X_{t-j}-\\mu$， 并利用$\\varepsilon_t$与$X_{t-1}, X_{t-2}, \\dots$独立的性质，可得\n$$\n\\gamma_j = \\phi_1 \\gamma_{j-1} + \\phi_2 \\gamma_{j-2}, \\ j=1, 2, \\dots\n$$\n\n两边除以$\\gamma_0$得\n$$\n\\begin{align}\n\\rho_j = \\phi_1 \\rho_{j-1} + \\phi_2 \\rho_{j-2}, \\ j=1,2,\\dots\n\n\\end{align}\n$$\n这种形式的递推称为齐次线性差分方程。 可以用滞后算子写成\n$$\n\\begin{align}\n(1 - \\phi_1 B - \\phi_2 B^2) \\rho_j = 0, \\ j=1,2,\\dots\n\n\\end{align}\n$$\n\n特征多项式$1 - \\phi_1 z - \\phi_2 z^2=0$的根的判别式为 $\\Delta = \\phi_1^2 + 4 \\phi_2$， 当$\\phi_2 \\geq -4 \\phi_1^2$时为实根， 当$\\phi_2 \u003c -4 \\phi_1^2$时为复根。 两个特征根都在单位圆外的充分必要条件是\n$$\n|\\phi_1| \u003c 2, \\ |\\phi_2| \u003c 1,\n\\ \\phi_2 \u003c 1 \\pm \\phi_1\n$$\n\n有两个实根时，两个根为\n$$\nz_1, z_2 = \\frac{\\phi_1 \\pm \\sqrt{\\phi_1^2 + 4\\phi_2}}{-2\\phi_2}\n$$\n\n这两个根的绝对值都大于1。 如果两个根都是正的，则$\\rho_j$为正，呈现出负指数速度单调衰减。 如果两个根正负不同，则绝对值仍以负指数速度衰减但是不单调， 当负根绝对值更小时会正负交替衰减。\n\n有共轭复根时，两个根为\n$$\nz_1, z_2 = \\frac{\\phi_1}{-2\\phi_2} \\pm i \\frac{\\sqrt{|\\phi_1^2 + 4\\phi_2}|}{-2\\phi_2}\n$$\n\n复根的模为\n$$\n|z_i| = \\frac{1}{\\sqrt{-\\phi_2}}\n$$\n辐角为\n$$\n\\omega = \\cos^{-1} \\frac{\\phi_1}{2\\sqrt{-\\phi_2}}\n$$\n反过来有\n$$\n\\phi_2 = -\\frac{1}{|z_1|^2},\n\\ \\phi_2 = \\frac{2}{|z_1|} \\cos\\omega\n$$\n$\\omega$这个辐角对应的周期为\n$$\nP = \\frac{2\\pi}{\\omega} = \\frac{2\\pi}{\\cos^{-1} \\frac{\\phi_1}{2\\sqrt{-\\phi_2}}}\n$$\n这样的AR(2)模型会体现出随机地平均以周期P的波动； $\\rho_j$序列呈现出以周期P震荡的幅度负指数衰减的变化。\n\n### 2.4 AR(p)模型的性质\n\n对于一般的AR(p)模型， 其ACF的性质以及序列的随机周期， 也由其特征根决定。 ACF可以是单调衰减、震荡衰减、正负交替衰减、呈周期震荡衰减。 在有复特征根根或者有接近-1的特征根时时间序列呈现出一定的随机周期变化。\n\n由平稳性得\n$$\n\\mu = \\frac{\\phi_0}{1 - \\phi_1 - \\dots - \\phi_p}\n$$\n自相关函数(ACF)满足如下的递推（差分方程）\n$$\n(1 - \\phi_1 B - \\dots - \\phi_p B^p) \\rho_j = 0, \\ j=1,2,\\dots\n$$\nAR(p)模型的平稳解是线性时间序列。\n\n### 2.5 偏自相关函数\n\n实际数据用AR模型建模时，阶数p是未知的， 确定p的问题称为定阶。 一般常用偏自相关函数和AIC准则。\n\n$\\phi_{nn}$实际是$X_t$与$X_{t-n}$在扣除$X_{t-2}, \\dots, X_{t-n+1}$的影响后的偏相关系数。\n$$\n\\begin{array}{l}{\\phi_{11}=\\rho_{1}} \\\\ {\\phi_{22}=\\left(\\rho_{2}-\\rho_{1}^{2}\\right) /\\left(1-\\rho_{1}^{2}\\right)} \\\\ {\\phi_{ss}=\\frac{\\rho_{s}-\\sum_{j=1}^{s-1} \\phi_{s-1, j} \\rho_{s-j}}{1-\\sum_{j=1}^{s-1} \\phi_{s-1, j} \\rho_{j}}, \\quad s=3,4,5, \\ldots}\\\\\\phi_{s j}=\\phi_{s-1, j}-\\phi_{s s} \\phi_{s-1, s-j}, j=1,2,3, \\ldots, s-1\\end{array}\n$$\nAR(p)序列的样本偏自相关函数$\\hat\\phi_{kk}$满足如下性质：\n\n- $T\\to\\infty$时$\\hat\\phi_{pp} \\to \\phi_p \\neq 0$。\n- 对$k\u003ep, \\hat\\phi_{kk} \\to 0(T\\to\\infty)$。\n- 对$k\u003ep,\\hat\\phi_{kk}$渐近方差为$\\frac{1}{T}$。\n\n\n### 2.6 信息准则\n\nAIC准则（Akaike’s Information Criterion）：\n$$\n\\text{AIC} = -\\frac{2}{T}\\ln(\\text{似然函数值}) + \\frac{2}{T} (\\text{参数个数})\n$$\n\n其中似然函数值是在参数最大似然估计处的似然函数值。 当模型为高斯AR(p)，AIC公式为\n$$\n\\text{AIC}(k) = \\ln \\tilde\\sigma_k^2 + \\frac{2k}{T}\n$$\n\n其中$k$是模型的阶， $\\tilde\\sigma_k^2$是阶为$k$的条件下$\\varepsilon_t$的方差的最大似然估计。 $\\ln \\tilde\\sigma_k^2$代表了模型对数据的拟合优劣， 此值越大拟合越差；$ \\frac{2k}{T}$是对模型复杂程度的惩罚，此值越大，模型越复杂，稳定性越差，对未来的情况的适应性也越差。 \n\n另一个常用的信息准则是BIC准则(Bayesian Information Criterion)， 高斯AR模型为：\n$$\n\\text{BIC}(k) = \\ln \\tilde\\sigma_k^2 + \\frac{k \\ln T}{T}\n$$\nBIC倾向于取比AIC更低阶的模型。\n\n大样本时BIC比AIC更准确些。小样本时AIC比BIC更准确些。\n\n\n### 2.7 AR模型参数估计方法\n\nAR模型有多种估计方法， 比如，用普通线性回归的最小二乘法估计， 假设正态分布用最大似然估计， Yule-Walker递推计算， Burg递推计算，等等。\n\nOLS估计的问题：\n\n- 误差序列相关问题、一致性问题\n- OLS无偏性的前提是：线性模型、随机抽样、非完全共线性、外生性\n- 时间序列数据不满足随机抽样\n  - 误差自相关\n  - 外生性出问题：不能满足无偏性\n\n- 比较宽的假设：满足一致性\n  - 线性模型弱相关并满足外生、非完全共线性\n\n### 2.8 AR模型检验\n\n拟合AR模型后， 如果模型是能够准确表示数据的规律的， 则拟合的残差应该近似为白噪声， 应该能通过白噪声检验。 因为残差是从模型估计计算得到的， 自由度有损失。\n\n\n### 2.9 AR模型拟合优度指标\n\n类似于线性回归模型的拟合优度判断， 在线性时间序列建模中，也可以定义如下的拟合优度R^2统计量\n\n比如，拟合了AR(p)模型后，可以计算$R^2$为\n$$\nR^2 = 1 - \\frac{\\sum_{t=p+1}^T e_t^2}{\\sum_{t=p+1}^T (x_t - \\bar x)^2}\n$$\n其中$\\bar x = \\frac{1}{T-p} \\sum_{t=p+1}^T x_t$。$0 \\leq R^2 \\leq 1$。\n\n$R^2$越大， 说明模型对数据拟合越好，残差越小。\n\n调整的$R^2$指标(adjusted $R^2$)，定义为\n$$\nR_{\\text{Adj}}^2 = 1 - \\frac{\\hat\\sigma^2}{\\hat\\sigma_x^2}\n$$\n其中$\\hat\\sigma^2$是新息方差$\\sigma^2$的估计，$\\hat\\sigma_x^2$是$X_t$的样本方差。\n\n### 2.10 用估计的AR模型进行预测\n\n#### 2.10.1 超前一步预测\n\n对$\\ell=1$，因为\n$$\nX_{h+1} = \\phi_0 + \\phi_1 X_{h} + \\dots + \\phi_p X_{h+1-p} + \\varepsilon_{h+1}\n$$\n\n以及$E(\\varepsilon_{h+1}|X_1, \\dots, X_h)=0$，有\n$$\n\\hat x_h(1) = E(X_{h+1} | X_1,\\dots, X_h)\n= \\phi_0 + \\phi_1 X_{h} + \\dots + \\phi_p X_{h+1-p}\n$$\n\n一步预测误差为\n$$\ne_h(1) = x_{h+1} - \\hat x_h(1) = \\varepsilon_{h+1},\n\\ \\text{Var}(e_h(1)) = \\sigma^2\n$$\n\n可见模型中的新息方差$\\sigma^2$也是超前一步预测的均方误差。\n\n如果$\\varepsilon_t$服从正态分布，则$X_{h+1}$的超前一步预测的95%预测区间为$\\hat x_h(1) \\pm 1.96 \\sigma$。\n\n对于时间序列数据， 真实的系数$\\phi_i$是未知的， 只能得到估计量$\\hat\\phi_i$， 当T充分大时可以在预测公式中用$\\hat\\phi_i$代替$\\phi_i$进行预测。这样得到的预测区间是不够准确的。\n\n#### 2.10.2 超前二步预测\n\n预测误差为\n\n$$\ne_h(2) = x_{h+2} - \\hat x_h(2) = \\phi_1 e_h(1) + \\varepsilon_{h+2}\n$$\n\n预测均方误差为\n$$\nE[e_h(2)]^2  = \\text{Var}(e_h(2)) = \\sigma^2(1 + \\phi_1^2)\n$$\n这里用到了$\\varepsilon_{h+2}$与$e_h(1) = x_{h+1} - \\hat x_h(1)$独立。 显然超前两步预测均方误差大于等于超前一步均方误差， 这对一般情况都是合理的， 预测得越远， 我们现有知识的作用就越小。\n\n#### 2.10.3 超前多步预测\n\n对平稳AR(p)模型， 当超前步数$\\ell\\to+\\infty$时， $\\hat x_h(\\ell) \\to \\mu$。 这种性质称为均值回转(mean reversion)。\n\n对AR(1)模型的零均值平稳解$\\{ x_t \\}$， 可以看出\n$$\n\\hat x_h(\\ell) = \\phi_1^\\ell x_h\n$$\n这也是与极限0之间的差距， 而$|\\phi_1|^\\ell$则代表了趋向于极限的速度， 当$|\\phi_1|^\\ell=\\frac12$时趋向于极限0就可以认为极限过程已经到了一半， 这个$\\ell=\\ln(0.5)/\\ln|\\phi_1|$称为均值回转的半衰期。 半衰期越短， 多步预报的作用越差。\n\n#### 2.10.4 样本外预测误差\n\n滚动样本外预测\n\n- 没有明显系统偏差\n- 用观察值对预测值做回归，$H_0:\\alpha=0,\\beta=1$\n- F检验\n\nGranger-Newbold检验\n\n构造$x_t$和$z_t$序列，使得$x_t=e_{1t}+e_{2t}$和$z_t=e_{1t}-e_{2t}$，得到相关系数为$r_{xz}$\n\n构造统计量：\n$$\nt=\\frac{r_{xz}}{\\sqrt{(1-r_{xz}^2)(H-1)}}\n$$\n$H$是保留期内的观测值。\n\n如果统计量不显著，就可以得出两个模型的预测效果无差异。\n\n## 3 移动平均模型\n\n### 3.1 移动平均模型的概念\n\n移动平均模型是具有q步外不相关性质的平稳列的模型； 对于高阶的AR模型， 有些可以用低阶的MA模型更好地描述。 一般的AR模型也可以用高阶MA模型近似。\n\n一般地，若$\\{ \\varepsilon_t \\}$是零均值独立同分布白噪声，方差为$\\sigma^2$，$|\\theta_1| \u003c 1$， 令\n$$\nX_t = \\theta_0 + \\varepsilon_t + \\theta_1 \\varepsilon_{t-1}\n$$\n易见$\\{ X_t \\}$为线性时间序列形式的弱平稳列， 称为MA(1)序列。\n\n类似地，MA(2)序列的模型为\n$$\nX_t = \\theta_0 + \\varepsilon_t + \\theta_1 \\varepsilon_{t-1} + \\theta_2 \\varepsilon_{t-2}\n$$\n\nMA(q)序列的模型为\n$$\nX_t = \\theta_0 + \\varepsilon_t + \\theta_1 \\varepsilon_{t-1} + \\dots + \\theta_2 \\varepsilon_{t-q}\n$$\n\n此模型也有特征多项式\n$$\n1 + \\theta_1 z + \\dots + \\theta_q z^q\n$$\n\n特征方程的根称为特征根，特征根都在单位圆外的条件称为MA模型的可逆条件。\n\n### 3.2 移动平均模型的性质\n\n#### 3.2.1 平稳性与自相关函数性质\n\n以MA(1)为例。$X_t = \\theta_0 + \\varepsilon_t + \\theta_1 \\varepsilon_{t-1}$， 其中$\\{ \\varepsilon_t \\}$是零均值独立同分布白噪声，$\\theta_0, \\theta_1$是任意实数，平稳性不需要特征根的条件。\n\n易见\n$$\nE X_t = \\theta_0, \\ \\forall t ,\n\\quad\n\\text{Var}(X_t) = \\sigma^2(1 + \\theta_1^2)\n$$\n$$\n\\gamma_k = \\begin{cases}\n\\sigma^2(1 + \\theta_1^2), \u0026 k=0 \\\\\n\\sigma^2 \\theta_1, \u0026 k=1, \\\\\n0, \u0026 k\u003e1\n\\end{cases}\n$$\n\n相应地，MA(1)的自相关函数为\n$$\n\\rho_k = \\begin{cases}\n1, \u0026 k=0 \\\\\n\\frac{\\theta_1}{1 + \\theta_1^2}, \u0026 k=1, \\\\\n0, \u0026 k\u003e1\n\\end{cases}\n$$\n这就验证了MA(1)序列是弱平稳列。 MA(1)的自相关函数在k\u003e1后为零的性质叫做MA序列的自相关函数截尾性。\n\n对于MA(q)序列\n$$\nX_t = \\theta_0 + \\varepsilon_t + \\theta_1 \\varepsilon_{t-1} + \\dots + \\theta_q \\varepsilon_{t-q}\n$$\n\n易见\n$$\nEX_t = \\theta_0, \n\\quad\n\\text{Var}(X_t) = \\sigma^2(1 + \\theta_1^2 + \\dots + \\theta_q^2)\n$$\n其自相关函数$\\rho_k$也满足q后截尾性， 即$\\rho_{k}=0, \\forall k \u003e q$。如果$\\theta_q \\neq 0$，则$\\rho_q \\neq 0$。\n\n自相关系数：\n$$\n\\rho_{j}=\\left\\{\\begin{array}{ll}{\\frac{\\theta_{j}+\\sum_{i=1}^{q-j} \\theta_{i} \\theta_{i+j}}{1+\\theta_{1}^{2}+\\cdots+\\theta_{q}^{2}},} \u0026 {j=1,2, \\cdots, q} \\\\ {0,} \u0026 {j\u003eq} \\\\ {\\rho_{-j},} \u0026 {j\u003c0}\\end{array}\\right.\n$$\n\n\n#### 3.2.2 可逆性\n\n对MA(1)模型， 当$|\\theta_1|\u003c1$时， 根据本章开始的推导可得\n$$\n\\varepsilon_t = -\\phi_0 + X_t + \\sum_{j=1}^\\infty (-\\theta_1)^j X_{t-j}\n$$\n\n其中的级数是可以在a.s.意义和均方意义下收敛的。 这表明新息$\\varepsilon_t$可以用当前的观测$X_t$以及历史观测$X_{t-j}, j=1,2,\\dots$的线性组合表示， 而且历史观测$X_{t-j}$所在时刻离$t$时刻越远， 其作用越小。这种性质叫做模型的可逆性。 MA模型的平稳性不需要可逆性条件， 但是从理论讨论的角度，可逆的线性时间序列更合理：$\\{ X_t, X_{t-1}, \\dots \\}$与$\\{\\varepsilon_t, \\varepsilon_{t-1}, \\dots \\}$可以互相线性表示， 对任意$t \\in \\mathbb Z$成立。\n\n### 3.3 移动平均模型定阶\n\nMA(q)序列的理论自相关函数$\\rho_k$在q后截尾，$\\rho_q\\neq 0, \\rho_k=0, k\u003eq$。\n\n在$\\{ X_t \\}$为独立同分布白噪声列的条件下， $k\u003e0$的$\\hat\\rho_k$渐近$\\text{N}(0, \\frac{1}{T})$分布，所以查看ACF图，最后一个显著不等于零的$\\hat\\rho_k$的位置可以暂定为MA模型的阶。\n\n也可以用AIC定阶：\n$$\n\\text{AIC}(k)\n=\\ln \\hat\\sigma_k^2 + \\frac{2k}{T}\n$$\n其中$\\hat\\sigma_k^2$是用MA(k)建模时新息方差的最大似然估计。\n\n### 3.4 移动平均模型的估计\n\nMA模型参数的估计方法有：\n\n矩估计法\n\n逆相关函数法，将MA模型转换为长阶自回归模型，用估计自回归模型的方法估计，能保证可逆性；\n\n新息估计法；\n\n条件最大似然估计法；\n\n精确最大似然估计法。\n\n条件最大似然估计法和完全最大似然估计法都假定$\\{\\varepsilon_t \\}$为高斯白噪声， 计算似然函数。在条件最大似然估计法中， 近似假定$\\varepsilon_t=0, t \\leq 0$， 这样就可以得到\n$$\n\\varepsilon_1 = x_1 - \\theta_0, \\varepsilon_{2} = x_2 - \\theta_0 - \\theta_1 \\varepsilon_1\n$$\n\n等递推表示， 将其代入$\\varepsilon_t, t=1,2,\\dots,T$的独立联合正态分布密度中就得到了条件似然函数， 求其关于$\\sigma^2$和$\\theta_0, \\theta_1, \\dots, \\theta_q$的最大值点。\n\n在精确最大似然估计中，将$\\varepsilon_t, t=1-q, 2-q, \\dots, -1, 0$也作为未知参数， 与其它模型参数一起估计。\n\n\n### 3.5 移动平均模型的预测\n\n因为MA(q)序列在间隔超过q步以后就独立， 所以超前多步预测， 只能预测到q步， 从q+1步开始就只能用均值$\\mu$预测了。\n\n以MA(1)为例，\n$$\nX_t = \\theta_0 + \\varepsilon_t + \\theta_1 \\varepsilon_{t-1}\n$$\n超前一步：\n$$\n\\hat x_h(1) = E(X_{h+1}|x_1, \\dots, x_h)\n= \\theta_0 + \\theta_1 \\varepsilon_{h}\n$$\n\n\n超前两步:\n$$\n\\hat x_h(2) = E(\\theta_0 + \\varepsilon_{h+2} + \\theta_1 \\varepsilon_{h+1} | x_1, \\dots, x_h) = \\theta_0\n$$\n\n\n### 3.6 AR和MA的小结\n\n对MA(q)模型，ACF对定阶有意义，因为其q后截尾；\n\n对AR(p)模型，PACF对定阶有意义，因为其p后截尾；\n\nMA模型的序列不管系数如何总是平稳的， 实际上还是因果线性时间序列， 当特征根都在单位圆外时是可逆的；\n\nAR模型只有当特征根都在单位圆外时才有$\\epsilon_t $与$X_{t-1}, X_{t-2}, \\dots$独立的弱平稳解；\n\n对AR和MA序列，超前多步预测趋于序列的均值， 预测均方误差趋于序列的方差。\n\n\n\n## 4 ARMA模型\n\n### 4.1 ARMA(1,1)\n\n$$\n(1 - \\phi_1 B) X_t = \\phi_0 + (1 + \\theta_1 B) \\varepsilon_t\n$$\n\n形式地，\n$$\n\\begin{aligned} \\frac{1}{1 - \\phi_1 z} =\u0026 \\sum_{j=0}^\\infty \\phi_1^j z^j, \\\\ \\frac{1}{1 - \\phi_1 B} =\u0026 \\sum_{j=0}^\\infty \\phi_1^j B^j, \\\\ \\frac{1 + \\theta_1 z}{1 - \\phi_1 z} =\u0026 1 + (\\phi_1 + \\theta_1) \\sum_{j=1}^\\infty \\phi_1^{j-1} z^j, \\\\ \\frac{1 + \\theta_1 B}{1 - \\phi_1 B} =\u0026 1 + (\\phi_1 + \\theta_1) \\sum_{j=1}^\\infty \\phi_1^{j-1} B^j, \\end{aligned}\n$$\n于是\n$$\n\\begin{align} X_t =\u0026 \\frac{1}{1 - \\phi_1 B} \\left\\{ \\phi_0  + (1 + \\theta_1 B) \\varepsilon_t \\right\\} \\nonumber\\\\ =\u0026 \\frac{\\phi_0}{1 - \\phi_1} + \\frac{1 + \\theta_1 B}{1 - \\phi_1 B}\\varepsilon_t \\nonumber\\\\ =\u0026 \\frac{\\phi_0}{1 - \\phi_1} + \\varepsilon_t  + (\\phi_1 + \\theta_1) \\sum_{j=1}^\\infty \\phi_1^{j-1} \\varepsilon_{t-j}\\end{align}\n$$\n这是因果型线性时间序列，是弱平稳的，满足上述ARMA(1,1)模型方程。\n$$\n\\begin{aligned} E X_t =\u0026  \\frac{\\phi_0}{1 - \\phi_1}, \\\\ \\text{Var}(X_t) =\u0026 \\sigma^2\\left( 1 + (\\phi_1+\\theta_1)^2 \\sum_{j=1}^\\infty (\\phi_1^2)^{j-1} \\right) = \\sigma^2 \\frac{1 + \\theta_1^2 + 2\\phi_1 \\theta_1}{1 - \\phi_1^2} \\end{aligned}\n$$\n\n\n由方差的表达式可知$|\\phi_1|\u003c1$是平稳性的必要条件。\n\nARMA(1,1)的自相关函数为\n$$\n\\rho_k = \\begin{cases} \\dfrac{(\\phi_1 + \\theta_1)(1 + \\phi_1 \\theta_1)}{1 + 2\\phi_1 \\theta_1 + \\theta_1^2}, \u0026 k=1 \\\\ \\phi_1 \\rho_{k-1} = \\phi_1^{k-1} \\rho_1, \u0026 k \\geq 2 \\end{cases}\n$$\n\n\n所以ARMA(1,1)的ACF与AR(1)的ACF很相似， 但是从$k=2$处才开始负指数衰减。 与AR类似， 自相关函数不能有限步截尾。\n\nARMA(1,1)的偏自相关函数与MA(1)的偏自相关函数类似， 但负指数衰减从$k=2$开始， 也不能在有限步截尾。\n\n总之， ARMA(1,1)的平稳性条件与AR(1)相同， 自相关函数与偏自相关函数均不能有限步截尾 (设$\\phi_1\\neq 0, \\theta_1 \\neq 0$)。\n\n### 4.2 一般ARMA模型\n\n一般ARMA模型为\n$$\nX_t = \\phi_0 + \\phi_1 X_{t-1} + \\dots + \\phi_p X_{t-p} + \\varepsilon_t + \\theta_1 \\varepsilon_{t-1} + \\dots + \\theta_q \\varepsilon_{t-q}\n$$\n\n平稳解的均值为：\n$$\nEX_t = \\frac{\\phi_0}{1 - \\phi_1 - \\dots - \\phi_p}\n$$\n\n### 4.3 ARMA模型的三种表示\n设ARMA(p,q)模型的系数满足平稳性条件与可逆性条件。\n\n第一种表示：\n$$\n(1 - \\phi_1 B - \\dots - \\phi_p B^p) X_t\n= \\phi_0 + (1 + \\theta_1 B + \\dots + \\theta_q B^q) \\varepsilon_t\n$$\n\n#### 4.3.1 ARMA模型的MA表示\n\n用滞后算子的性质， 令$P(z) = 1 - \\sum_{j=1}^p \\phi_p z^j, Q(z) = 1 + \\sum_{j=1}^q \\theta_q z^j$， 则\n$$\n\\Psi(z) = \\frac{Q(z)}{P(z)} = \\sum_{j=0}^\\infty \\psi_j z^j\n$$\n其中$\\{ \\psi_j \\}$绝对可和（实际上，$j\\to\\infty$时$c_j$以负指数速度衰减）。 所以\n$$\nX_t = \\mu + \\Psi(B) \\varepsilon_t\n= \\mu + \\sum_{j=0}^\\infty \\psi_j \\varepsilon_{t-j}, \\ t \\in \\mathbb Z\n$$\n这称为ARMA模型的MA表示或者Wold表示。\n\n### 4.3.2 ARMA模型的AR表示\n\n## 5 单位根过程\n\n### 5.1 随机游动\n\n考虑$\\{ p_t \\}$的模型\n$$\n\\begin{align}\np_t = p_{t-1} + \\varepsilon_t,\n\\ t=1,2,\\dots\n\\end{align}\n$$\n其中$\\{ \\varepsilon_t \\}$是零均值独立同分布白噪声列。称$\\{ p_t \\}$是一个随机游动(random walk)。\n\n设$p_0=0$，单位根过程$\\{p_t\\}$有如下特点：\n\n- $p_t$期望值等于0；\n- $p_t$方差等于$\\sigma^2 t$，随$t$线性增长，趋于无穷；\n- 历史的扰动（新息）的影响不衰减；\n- 预测只能用最后一个观测值作为预测， 预测均方误差趋于无穷。\n- 样本ACF表现为基本不衰减，近似等于1。\n\n### 5.2 带漂移的随机游动\n\n模型可以推广为\n$$\np_t = \\mu + p_{t-1} + \\varepsilon_t,\n\\ t=1,2,\\dots\n$$\n\n其中$\\{ \\varepsilon_t \\}$仍为零均值独立同分布白噪声列。 常数$\\mu$并不代表均值， 而是对数价格$p_t$的增长速度，称为模型的漂移(drift)。 设初始价格为$p_0$，则\n$$\n\\begin{aligned}\np_1 =\u0026 p_0 + \\mu +  \\varepsilon_1 \\\\\np_2 =\u0026 p_0 + 2\\mu + \\varepsilon_1 + \\varepsilon_2 \\\\\n\u0026 \\cdots\\cdots \\\\\np_t =\u0026 p_0 + t\\mu + \\varepsilon_1 + \\dots + \\varepsilon_t\n\\end{aligned}\n$$\n\n于是\n$$\nE(p_t | p_0) = p_0 + \\mu t,\n\\quad\n\\text{Var}(p_t | p_0) = \\sigma^2 t\n$$\n所以带漂移的随机游动与不带漂移的随机游动相比，其条件方差不变， 但是条件均值多了一个随t线性增长（若$\\mu\u003e0$）的$\\mu t$项。\n\n### 5.3 固定趋势模型\n\n设$\\{ X_t \\}$为弱平稳时间序列 令\n$$\nY_t = a + b t + X_t\n$$\n则\n$$\nEY_t = (a + \\mu_x) + bt， \\text{Var}(Y_t) = \\text{Var}(X_t) = \\sigma_x^2\n$$\n均值非常数所以$\\{ Y_t \\}$非平稳。 但是， 减去一个固定趋势$a + bt$后$\\{ Y_t \\}$就变成了平稳列， 这样的$\\{ Y_t \\}$与随机游动或者带漂移的随机游动有着本质的区别。\n\n随机游动$p_t = p_{t+1} + \\varepsilon_t$与固定趋势加扰动$Y_t = a + bt + X_t$都能呈现出缓慢的趋势变化。区别在于：\n\n- 随机游动的方差是线性增长的， 固定趋势的观测值方差不变；\n- 随机游动的扰动的影响是永久的， 固定趋势的扰动的影响仅在一个时刻（如果扰动$X_t$是白噪声） 或者很短时间（如果是扰动$X_t$是线性时间序列）；\n- 随机游动的趋势没有固定方向， 固定趋势的变化形状是固定的；\n- 固定趋势模型$Y_t$减去一个固定的回归函数$Y = a + bt$就可以变成平稳列， 随机游动减去任意的非随机函数都不能变平稳， 可以用差分运算变成平稳。\n- 在AR和ARMA模型中， 常数项$\\phi_0$与平稳均值有关。 但是在带漂移的随机游动模型中， 常数项$\\mu$是每一步的平均增量，是固定线性趋势的斜率。 所以时间序列模型中的常数项可能会依模型的不同而具有迥然不同的含义。\n\n### 5.4 ARIMA模型\n\n将带漂移的随机游动模型中的白噪声替换成一个ARMA平稳列， 其主要的性质仍能保留。即\n$$\nY_t = Y_{t-1} + \\mu + X_t\n$$\n其中$\\{ X_t \\}$是零均值平稳可逆ARMA(p,q)平稳列。 这时有\n$$\nY_t = Y_0 + \\mu t + \\sum_{j=1}^t X_j\n$$\n\n于是\n$$\nE(Y_t|Y_0) = Y_0 + \\mu t,\n\\quad\n\\text{Var}(Y_t | Y_0)\n= \\text{随}t\\text{增大而趋于}\\infty\n$$\n\n称$\\{ Y_t \\}$服从ARIMA(p,1,q)模型， 是非平稳的。$ \\{Y_t\\}$不能通过减去任何的非随机趋势变成平稳。 但是， 差分运算\n$$\n\\Delta Y_t = (1-B)Y_t = Y_t - Y_{t-1} = \\mu + X_t\n$$\n将ARIMA(p,1,q)序列$\\{Y_t\\}$转化成平稳可逆的ARMA(p,q)序列。\n\n\n如果$Y_t$本身已经是弱平稳列， 则不应对$Y_t$进行差分。 如果$Y_t$是非随机的线性趋势加平稳列， 虽然差分能将其变成平稳列， 但是也不应该使用差分来做而是应该用回归来做， 用差分来做会在ARMA模型的MA部分引入不必要的单位根。\n\n### 5.5 单位根检验\n\n单位根非平稳列是金融中最常用的非平稳模型， 单位根非平稳列不能使用平稳列的模型来建模。 所以， 要建模的序列应该进行“单位根检验”。\n\n对不带漂移的单位根过程， 考虑如下的基础模型：\n$$\n\\begin{align}\np_t = \\phi_1 p_{t-1} + \\varepsilon_t\n\n\\end{align}\n$$\n其中$\\{\\varepsilon_t\\}$是零均值独立同分布白噪声列。$ |\\phi_1| \\leq 1$。 考虑如下零假设与对立假设：\n$$\nH_0: \\phi_1 = 1\n\\longleftrightarrow\nH_a: \\phi_1 \u003c 1\n$$\n\n这样的检验问题称为单位根检验问题。 基础模型也可以是带有常数项的：\n$$\n\\begin{align}\np_t = \\phi_0 + \\phi_1 p_{t-1} + \\varepsilon_t\n\n\\end{align}\n$$\n\n对模型作最小二乘估计\n$$\n\\hat\\phi_1 = \\frac{\\sum_{t=1}^T p_{t-1}p_t}{\\sum_{t=1}^T p_t^2},\n\\quad\n\\hat\\sigma^2 = \\frac{1}{T-1} \\sum_{t=1}^T (p_t - \\hat\\phi_1 p_{t-1})^2\n$$\n\n其中$p_0=0, T$为样本量。取检验统计量\n$$\n\\text{DF} = \\frac{\\hat\\phi_1 - 1}{\\text{SE}(\\hat\\phi_1)}\n= \\frac{\\sum_{t=1}^T p_{t-1} e_t}{\\hat\\sigma \\sqrt{\\sum_{t=1}^T p_{t-1}^2}}\n$$\n\n当$T$充分大时在$H_0$下有渐近分布， 当DF统计量足够小的时候拒绝$H_0$。 p值一般通过随机模拟计算。 这个检验称为Dicky-Fuller检验。\n\n在使用作为基础模型时， 如果实际上$\\phi_0=0$， 则DF统计量也有非标准的渐近分布， 可以用随机模拟方法计算p值。 如果实际上$\\phi_0\\neq 0$， 则DF统计量渐近正态分布，但是需要很大的样本量。\n\n许多经济和金融序列并不能仅用随机游动来描述， 可能需要用ARIMA。 因为ARMA模型可以看成长阶自回归， 所以检验是否ARIMA模型， 可以用$q=0$的ARIMA作为基础模型。 对序列$\\{ x_t \\}$为了检验其是否有单位根， 考虑如下的基础模型：\n$$\n\\begin{align}\nX_t = c_t + \\beta X_{t-1} + \\sum_{j=1}^{p-1} \\phi_j \\Delta X_{t-j} + e_t\n\n\\end{align}\n$$\n当$\\beta=1$时， 就是$\\Delta X_t的AR(p-1)$模型； 当$\\beta\u003c1$时， 是$X_t$的$AR(p)$模型。$ c_t$是非随机的趋势部分， 可以取0，或常数，或$a + bt$这样的非随机线性趋势。 检验假设\n$$\nH_0: \\beta = 1\n\\longleftrightarrow\nH_a: \\beta \u003c 1\n$$\n\n如果拒绝$H_0$， 就说明没有单位根。 使用统计量\n$$\n\\text{ADF} = \\frac{\\hat\\beta - 1}{\\text{SE}(\\hat\\beta)}\n$$\n当ADF统计量足够小的时候拒绝$H_0$。\n\n基础模型也可以改写成\n$$\n\\Delta X_t = c_t + \\beta_c X_{t-1} + \\sum_{j=1}^{p-1} \\phi_j \\Delta X_{t-j} + e_t\n$$\n\n其中$\\beta_c = \\beta-1$， 检验\n$$\nH_0: \\beta_c = 0\n\\longleftrightarrow\nH_a: \\beta_c \u003c 0\n$$\n这个检验称为ADF检验(Augmented Dicky-Fuller Test)。\n\n注意，单位根DF检验和ADF检验都是在拒绝$H_0$（显著）时否认有单位根， 不显著时承认有单位根。\n\nADF检验倾向于把平稳过程检验为单位根过程的原因在于检验的设定：\n\n- 一般的检验都是在有比较强的证据情况下，才拒绝$H_0$,即拒绝$H_0$难，不拒绝容易\n- 这样规律在ADF检验中，$H_0$是单位根过程。所以倾向单位根\n- 但另一方面，这个偏差（偏向单位根）问题的后果不严重,预测的精度可能更好\n\n关于ADF检验的效率，其它几个特点：\n\n- ADF检验的效率更依赖于数据的时间跨度，而不是观测值的个数。当然观察个数越多效率还是越高。这一点与波动率的估计类似\n- 如果数据产生的本来过程没有常数项和趋势项等，加入它们到ADF检验中，会降低效率，即倾向判断为单位根\n- 如果数据产生的本来过程有常数项和趋势项等，在ADF检验中没有加入，在大样本情况下，检验无效\n\n### 5.5 区分和选择单位根模型\n\n对有结构变化数据的单位根检验\n\n- 比如数据在某一时间前后有跳跃，那么在做回归分析时，显然有时间趋势，这一点与带漂移的单位根相似\n- 显然有非常高的自相关性，即小的观测值接着小的观测值，大的观测值接着大的观测值。自相关性=1就是单位根\n- 因此，有结构变化数据会经常被检验为单位根，即使它本来是有结构变化的平稳过程。因此，要首先检查是否有结构变化。如果有：\n  - 分阶段检验\n  - 或者在检验回归模型中，加入结构变化虚拟变量\n\n数据看，很难区分接近非平稳的平稳过程与非平稳过程。也很难区分确定性趋势与带漂移的单位根。\n\n- 所以，要用经济学直观，经济学传统。传统的宏观经济学中Business Cycle认为宏观变量（比如GDP等）是确定性增长及周期合成，但Nelson and Plosser（1982）认为主要的宏观变量是带漂移的单位根过程\n\n滞后项：\n\n- 每个模型中选取适当的滞后差分项，以使模型的残差项是一个白噪声（主要保证不存在自相关）；可以用回归系数的t-值判定\n  - 这里之所以可以用t检验，因为在用时间系列数据时，如果一个模型中解释变量有平稳的，也有非平稳的，那么平稳解释变量的系数估计是一致的，并且可以用t检验。\n- 还可以用AIC/BIC选择\n\n趋势项：\n\n- 首先看数据图，判断是否应该有趋势项。很多情况下，数据有明显特征\n- Sims, Stock, and Watson (1990)的另一个结论：如果一个时间系列数据的产生过程本来有确定性项（常数项/时间项），而检验模型正确地包含了这些项，那么可以对所有系数用通常的t检验和F检验。这是由于这时的收敛速度等于收敛最慢的那个参数的收敛速度\n\n### 5.6 对时间序列取对数\n\n- 表示增长率；均值和残差是积的关系\n- 如果均值与波动的关系（而不是时间与波动的关系，尽管经常是均值与时间同步）成正比；再看是确定性趋势还是带漂移的随机趋势（看去均值后的波动与时间的关系），可以用ADF检验\n\n## 6 季节模型\n\n### 6.1 季节同比\n\n- 对季节性增长率问题，一种简单的办法是用同比\n  - 中国的CPI有同步和环比，环比CPI有季节性问题，而同比CPI有翘尾问题\n  - “翘尾”因素，(carryover effects)，也称滞后影响，是计算同比价格指数中独有的、上年商品价格上涨对下一年价格指数的影响部分。\n    - 如某一商品1995年前6个月价格均为每公斤0.5元，7月份上涨到1元，一直到1996年12月份均保持同一价格，虽然1996年价格保持稳定，但计算出来的1996年前6个月的同比价格指数却为200%，表明价格上涨一倍，这就是这一商品价格指数中的“翘尾”因素，是上年7月份价格上涨对下一年上半年价格指数的滞后影响。\n  - 同比的问题是，基准点是去年同期，不能准确地反映最近的变化。因此基于同步数据的模型，可能不是最好的。\n\n### 6.2 季节哑变量\n\n确定性季节趋势\n\n- 多由节（假）日安排影响，我们通过有效工作日或控制季节虚拟变量处理：\n  - 加入一个工作日变量：28天等等\n  - 加入四个季节虚拟变量：控制哑变量系数和为1\n\n### 6.3 乘性季节模型\n\n$$\n(1-B)(1 - B^s) x_t = (1 - \\theta B)(1 - \\Theta B^s) \\varepsilon_t\n$$\n\n\n\n### 6.4 X11分解\n\n$$\ny_{t}=T_{t}+C_{t}+S_{t}+u_{t}\n$$\n\n\n\n## 7 资产波动率模型特征\n\n### 7.1 波动率的特征\n\n波动率(volatility)指的是资产价格的波动强弱程度， 类似于概率论中随机变量标准差的概念。 波动率不能直接观测， 可以从资产收益率中看出波动率的一些特征。\n\n- 存在波动率聚集(volatility clustering)\n- 波动率随时间连续变化，一般不出现波动率的跳跃式变动\n- 波动率一般在固定的范围内变化，意味着动态的波动率是平稳的\n- 在资产价格大幅上扬和大幅下跌两种情形下， 波动率的反映不同， 大幅下跌时波动率一般也更大， 这种现象称为杠杆效应（leverage effect）\n\n这些性质对波动率模型的提出、改进有重要意义， 许多新的波动率模型都是诊断原有模型不能反映上面的某型特征而提出的。 例如， EGARCH模型和TGARCH模型可以反映出波动率在价格上扬和下跌时的不对称性。\n\n不同的波动率计算方法使用不同的数据源。例如， 对IBM股票有如下三种数据源：\n\n- 每个交易日的日收益率；\n- 伴随IBM股票的期权数据\n- 盘中交易和报价的分笔数据；\n\n分别可以计算如下三种不同的波动率：\n\n- 作为日收益率的条件标准差（或条件方差），建模计算。\n- 隐含波动率：根据期权的理论公式如BS公式， 从股票价格和期权价格数据反解出模型中的波动率， 这样的得到的波动率称为隐含波动率。 隐含波动率倾向于比用日收益率建模得到的波动率数值要大。 CBOE的VIX指数就是隐含波动率。\n- 实际波动率：利用一天内所有的收益率数据， 如每5分钟的收益率，估计一天收益率的条件标准差。\n\n类似于利率， 度量波动率的时间区间一般也取为一年， 波动率一般是年化波动率。 如果有了日收益率（条件标准差）， 可以将其乘以$\\sqrt{252}$转换成年化的波动率。\n\n估计将来回报的波动率：\n\n- 两步法\n  - 先估计历史上的波动率（第一步），再用一个时间系列模型预测波动率（第二步）。\n  - 历史数据样本标准差就是第一步，ARMA模型经常被用在第二步。业界经常用一个最简单的ARMA模型作为第二步：单位根过程\n  - 这类方法的优点是：简单、直观\n  - 这类方法的缺点是：没有逻辑一致的理论基础：不能保证用来估计波动率的模型与用来预测波动率的模型来自同一个大模型\n- 一步法：用一个模型直接估计历史上的波动率和预测将来的波动率\n  - 直接用一个模型模拟有观测值的回报过程本身，这个模型中回报的条件标准差是一个时变的。我们可以用这个模型计算、预测波动率\n  - 优点: 有严密的理论基础\n  - 缺点: 不够稳健，估计困难、不够稳健、适应性不强\n\n### 7.2 波动率模型的结构\n\n本章的问题就是对$\\hat\\sigma_t$建模， 这种模型叫做条件异方差模型。 条件异方差模型分为两类：\n\n- 用确定函数来刻画$\\hat\\sigma_t$的变化，ARCH和GARCH模型属于这一类；\n- 用随机方程描述$\\hat\\sigma_t$的变化，随机波动率(RV)模型属于这一类。\n\n### 7.3 波动率模型的建立\n\n对资产收益率序列建立波动率模型需要如下四个步骤：\n\n1. 通过检验序列的自相关性建立均值的方程， 必要时还可以引入适当的解释变量；\n2. 对均值方程的残差作白噪声检验， 通过后，对残差检验ARCH效应；\n3. 如果ARCH效应检验结果显著， 则指定一个波动率模型， 对均值方程和波动率方程进行联合估计；\n4. 对得到的模型进行验证， 需要时做改进。\n\n关于均值方程， 资产收益率一般没有自相关（注意，这并不是独立）或者仅有弱的自相关。 如果样本均值显著不等于零， 需要从数据中减去样本均值， 这称为**中心化**。 对某些日收益率或更高频的序列可能需要建立简单的AR模型。 某些情况下可以加入额外的解释变量或者与日期有关的解释变量， 比如反映周末的哑变量， 反映一月份的哑变量，等等。\n\n### 7.4 ARCH效应的检验\n\n为了检验ARCH效应， 先建立均值模型，拟合$\\mu_t$，计算残差$a_t = r_t - \\mu_t$。 用残差序列的平方$\\{ a_t^2 \\}$作ARCH效应检验。\n\n有两种检验方法。 \n\n一种是对$\\{ a_t^2 \\}$作Ljung-Box白噪声检验， 检验不显著时没有ARCH效应， 检验显著时有ARCH效应。\n\n另一种检验方法是Engle提出的。 考虑如下的最小二乘问题：\n$$\na_t^2 = \\alpha_0 + \\alpha_1 a_{t-1}^2 + \\dots + \\alpha_m a_{t-m}^2 + e_t, \\ t=m+1, \\dots, T\n$$\n其中$T$为样本量，$m$是适当的AR阶数，$e_t$为回归残差。 零假设为\n$$\nH_0: \\ \\alpha_1 = \\dots = \\alpha_m = 0\n$$\n拒绝$H_0$时有ARCH效应。 这称为Engle的拉格朗日乘子法检验。\n\n## 8 ARCH模型\n\n### 8.1 ARCH模型公式\n\n基本思想是：\n\n资产收益率的扰动序列$a_t = r_t - E(r_t | F_{t-1})$是前后不相关的， 但是前后不独立。\n\n$a_t$的不独立性， 描述为$\\text{Var}(r_t | F_{t-1}) = \\text{Var}(a_t | F_{t-1})$ 可以用$a_t^2$的滞后值的线性组合表示。\n\n具体地， ARCH(m)模型为\n$$\n\\begin{align}\n\\begin{aligned}\na_t =\u0026 \\sigma_t \\varepsilon_t \\\\\n\\sigma_t^2 =\u0026 \\alpha_0 + \\alpha_1 a_{t-1}^2 + \\dots + \\alpha_m a_{t-m}^2\n\\end{aligned}\n\\tag{17.1}\n\\end{align}\n$$\n\n其中$\\{ \\varepsilon_t \\}$是零均值单位方差的独立同分布白噪声， $\\alpha_0\u003e0， \\alpha_j \\geq 0, j=1,2,\\dots,m$， 另外$\\{ \\alpha_j \\}$还需要满足一些条件使得$\\text{Var}(a_t)$有限， 类似于AR(p)序列的平稳性的特征根条件。\n\n\n### 8.2 ARCH模型的性质\n\n以最简单的ARCH(1)为例讨论模型的性质。 模型为\n$$\na_t = \\sigma_t \\varepsilon_t,\n\\ \\sigma_t^2 = \\alpha_0 + \\alpha_1 a_{t-1}^2\n$$\n其中$\\alpha_0\u003e0, 0 \u003c \\alpha_1 \u003c 1$。\n\n#### 8.2.1 无条件期望和方差\n\n考虑$a_t$的无条件期望和方差。\n$$\n\\begin{align}\nE(a_t)\n=\u0026 E[ E(a_t | F_{t-1})] \\\\\n=\u0026 E[ E(\\sigma_t \\varepsilon_t | F_{t-1})]\n= E[ \\sigma_t E( \\varepsilon_t | F_{t-1})] = 0\n\\end{align}\n$$\n即无条件期望为零。\n$$\n\\begin{align}\n\\text{Var}(a_t)\n=\u0026 E(a_t^2)\n= E[ E(a_t^2 | F_{t-1})] \\\\\n=\u0026 E[ E(\\sigma_t^2 \\varepsilon_t^2 | F_{t-1})]\n= E[ \\sigma_t^2 E(\\varepsilon_t^2 | F_{t-1})]\n= E(\\sigma_t^2) \\\\\n=\u0026 \\alpha_0 + \\alpha_1 E(a_{t-1}^2)\n\\end{align}\n$$\n因为$a_t$是平稳列， 所以$\\text{Var}(a_t)$为常数， 所以\n$$\n\\text{Var}(a_t)\n= E(a_t^2)\n= \\frac{\\alpha_0}{1 - \\alpha_1}\n$$\n这要求$0 \u003c \\alpha_1 \u003c 1$。\n\n高阶的ARCH模型：\n$$\nE \\sigma_t^2=\\frac{\\alpha_0}{1-\\sum_{i=1}^m\\alpha_i}\n$$\n平稳条件是：\n$$\n\\sum_{i=1}^m\\alpha_i\u003c1\n$$\n\n\n#### 8.2.2 高阶矩\n\n有些应用需要利用$a_t$的高阶矩， 例如， 为了研究$a_t$是否厚尾分布， 需要计算峰度， 峰度依赖于四阶矩。\n\n高阶矩的存在要求(17.1)中的$\\varepsilon_t$与$\\{ \\alpha_j \\}$满足一定的约束性条件。 若(17.1)中的$\\varepsilon_t$服从标准正态分布， 则其有任意阶矩， 这时条件四阶矩\n$$\n\\begin{align}\nE(a_t^4 | F_{t-1})\n=\u0026 E(\\sigma_t^4 \\varepsilon_t^4 | F_{t-1})\n= \\sigma_t^4 E(\\varepsilon_t^4 | F_{t-1})\\\\\n=\u0026 3 \\sigma_t^4\n= 3(\\alpha_0 + \\alpha_1 a_{t-1}^2)^2\n\\end{align}\n$$\n从而无条件的四阶矩为\n$$\nE(a_t^4)\n= E[ E(a_t^4|F_{t-1})]\n= 3 E [ (\\alpha_0 + \\alpha_1 a_{t-1}^2)^2 ]\n= 3 \\left[ \\alpha_0^2 + 2\\alpha_0 \\alpha_1 E(a_{t-1}^2) + \\alpha_1^2 E(a_{t-1}^4) \\right]\n$$\n如果$\\{ a_t \\}$为四阶矩有限的严平稳时间序列， 则$Ea_t^4 = Ea_{t-1}^4$，于是\n$$\n(1 - 3 \\alpha_1^2) Ea_t^4\n= 3\\left( \\alpha_0 + 2\\alpha_0 \\alpha_1 \\frac{\\alpha_0}{1 - \\alpha_1} \\right)\n$$\n这要求$1 - 3\\alpha_1^2\u003e0$，即$0\u003c\\alpha_1 \u003c \\frac{\\sqrt{3}}{3}$。 这时\n$$\nEa_t^4 = \\frac{3\\alpha_0^2(1+\\alpha_1)}{(1-\\alpha_1)(1-3\\alpha_1^2)}\n$$\n\n由此可以计算$a_t$的峰度为\n$$\n\\frac{Ea_t^4}{[\\text{Var}(a_t^2)]^2}\n= 3 \\frac{1-\\alpha_1^2}{1 - 3\\alpha_1^2} \u003e 3\n$$\n$a_t$的超额峰度为\n$$\n\\frac{Ea_t^4}{[\\text{Var}(a_t^2)]^2} - 3\n= \\frac{6\\alpha_1^2}{1 - 3\\alpha_1^2} \u003e 0\n$$\n这说明$\\{a_t \\}$序列是厚尾（重尾）分布， 其样本比均值和方差相同的正态序列有更多的离群值（outliers）。 这与实证分析中对资产收益率的分布观察结果一致。\n\n\n### 8.3 ARCH模型的优缺点\n\n优点：\n\n- 可以产生波动率聚集\n- 扰动$a_t$具有厚尾分布。\n\n缺点：\n\n- 因为假定$a_{t-j}$通过$a_{t-j}^2$影响波动率$\\sigma_t$， 所以正的扰动和负的扰动对波动率影响相同， 但是实际的资产收益率中正负扰动对波动率影响不同， 较大的负扰动比正扰动引起的波动更大。\n- ARCH模型对模型参数有较严格的约束条件， 即使是ARCH(1)， 为了能计算峰度，也需要$\\alpha_1 \\in (0, \\frac{\\sqrt{3}}{3})$， 高阶的ARCH(m)的约束条件更为复杂。 这对带高斯新息的ARCH模型通过超额峰度表达厚尾性是一个限制。\n- 只能描述条件方差的变化， 但是不能解释变化的原因。\n- 由模型做的波动率预测会偏高。\n\n### 8.4 ARCH模型的建模步骤\n\n#### 8.4.1 定阶\n\n在ARCH效应检验显著后， 可以通过考察$\\{ a_t^2 \\}$序列的PACF来对ARCH模型定阶。 下面解释理由。\n\n首先， 模型为\n$$\n\\sigma_t^2 = \\alpha_0 + \\alpha_1 a_{t-1}^2 + \\dots + \\alpha_m a_{t-m}^2\n$$\n因为$E(a_t^2 | F_{t-1}) = \\sigma_t^2$， 所以认为近似有\n$$\na_t^2 \\approx \\alpha_0 + \\alpha_1 a_{t-1}^2 + \\dots + \\alpha_m a_{t-m}^2\n$$\n这样可以用$\\{ a_t^2 \\}$序列的PACF的截尾性来估计ARCH阶m。\n\n\n#### 8.4.2 模型估计\n\n## 9 GARCH模型\n\n### 9.1 模型方程\n\n如果$a_t$满足\n$$\n\\begin{align}\na_t = \\sigma_t \\varepsilon_t,\n\\quad\n\\sigma_t^2 = \\alpha_0 + \\sum_{i=1}^m \\alpha_i a_{t-i}^2 + \\sum_{j=1}^s \\beta_j \\sigma_{t-j}^2\n\n\\end{align}\n$$\n其中$\\{ \\varepsilon_t \\}$为零均值单位方差的独立同分布白噪声列， $\\alpha_0\u003e0, \\alpha_i \\geq 0, \\beta_j \\geq 0, 0 \u003c \\sum_{i=1}^m \\alpha_i + \\sum_{j=1}^s \\beta_j \u003c 1$， 这最后一个条件用来保证满足模型的$a_t$的无条件方差有限且不变， 而条件方差$\\sigma_t^2$可以随时间t而变。\n\n\n### 9.2 GARCH模型的性质\n\n下面以最简单的GARCH(1,1)为例研究GARCH模型的性质。 令$F_{t-1}$表示截止到$t-1$时刻的$a_{t-i}$和$\\sigma_{t-j}$所包含的信息。 模型为\n$$\n\\begin{align}\na_t =\u0026 \\sigma_t \\varepsilon_t,\n\\varepsilon_t \\text{ i.i.d. WN} (0,1)\\\\\n\\sigma_t^2 =\u0026 \\alpha_0 + \\alpha_1 a_{t-1}^2 + \\beta_1 \\sigma_{t-1}^2\n\\end{align}\n$$\n为了计算无条件均值$Ea_t$，先计算条件期望\n$$\nE(a_t | F_{t-1})\n= E(\\sigma_t \\varepsilon_t | F_{t-1})\n= \\sigma_t E(\\varepsilon_t | F_{t-1})\n= 0\n$$\n这里用了$\\sigma_t \\in F_{t-1}$而$\\varepsilon_t$与$F_{t-1}$独立。 于是\n$$\nE a_t = E[ E(a_t | F_{t-1})] = 0\n$$\n即GARCH模型的新息$a_t$的无条件期望为零。\n\n来计算$a_t$的无条件方差。 设模型的$\\{ a_t \\}$序列存在严平稳解，则\n$$\n\\begin{aligned}\n\\text{Var}(a_t)\n=\u0026 E(a_t^2)\n= E[ E(a_t^2 | F_{t-1})]\n= E[ E(\\sigma_t^2 \\varepsilon_t^2 | F_{t-1})]\\\\\n=\u0026 E[\\sigma_t^2 E(\\varepsilon_t^2 | F_{t-1})]\n= E[\\sigma_t^2 E(\\varepsilon_t^2)] \\\\\n=\u0026 E[\\sigma_t^2] \n= E[\\alpha_0 + \\alpha_1 a_{t-1}^2 + \\beta_1 \\sigma_{t-1}^2] \\\\\n=\u0026 \\alpha_0 + \\alpha_1 E(a_{t-1}^2) + \\beta_1 E[E(a_{t-1}^2|F_{t-2})]\\\\\n=\u0026 \\alpha_0 + (\\alpha_1 + \\beta_1) E(a_{t-1}^2)\n\\end{aligned}\n$$\n令$E a_t^2 = E a_{t-1}^2$， 解得\n$$\n\\text{Var}(a_t) = E a_t^2\n= \\frac{\\alpha_0}{1 - \\alpha_1 - \\beta_1} .\n$$\nGARCH(1,1)模型的性质：\n\n第一，像ARCH模型一样，$a_t$存在波动率聚集， 一个较大的$a_{t-1}$或$\\sigma_{t-1}$使得1步以后的条件方差变大， 从而倾向于出现较大的对数收益率。\n\n- $\\alpha$捕捉之前的冲击的影响，$\\beta$捕捉之前的波动率的影响。大的$\\beta$说明冲击对波动率的影响需要一段时间才能消失，所以GARCH项更加持久。大的$\\alpha$说明波动率对之前的市场波动更密集，所以波动率更尖锐。在金融实证中，一般的$β_1$大于0.7， $α_1$在0.2左右。\n\n第二，当$\\varepsilon_t$为标准正态分布时， 在如下条件下$a_t$有无条件四阶矩：\n$$\n1 - 2 \\alpha_1^2 - (\\alpha_1 + \\beta_1)^2 \u003e 0\n$$\n这时超额峰度为\n$$\n\\frac{E a_t^4}{(Ea_t^2)^2} - 3\n= \\frac{2\\left[1 - (\\alpha_1 + \\beta_1)^2 + \\alpha_1^2 \\right]}\n{1 - (\\alpha_1 + \\beta_1)^2 - 2\\alpha_1^2}\n\u003e 0\n$$\n\n即$a_t$分布厚尾。\n\n第三，GARCH模型给出了一个比较简单的波动率模型。\n\n问题：纯统计模型，没有解释、预测力度不够好、对称、对参数要求比较严格\n\n### 9.3 估计\n\nMLE估计中$a_0$不知道，有三种解决方法：\n\n- 估计$a_0$\n- 用$a_0^2$的长期均值，$E a_0^2=\\frac{\\alpha_0}{1-\\alpha_1}$\n- 条件MLE：样本比较大时没有什么误差\n\n需要初始波动率，也有三种方案：\n\n- 样本方差\n- 波动率的长期均值\n- 待估计系数\n\n均值部分可以是任何符合经济学原理的模型，比如想要估计股票回报的特质风险，均值部分就是市场模型，甚至再加上市场回报的滞后。\n\n- 波动率部分，一般来说，很少有超过GARCH(2, 2)的。\n- 还有一种导致不收敛的原因是离群值的存在。（偏度和峰度非常大）\n  - 去掉：这样的激烈波动是否还会重演\n  - 如果不能去掉，解决方法：\n    - 改变参数估计的初始值\n    - 改变最大化似然函数的数值方法\n    - 改变模型，用简单些的模型\n- 有明显的峰度：选择学生t分布\n\n\n\n### 9.4 预测\n\n可以用类似ARMA预测的方法预测波动率。 仍以GARCH(1,1)为例， 基于截止到h时刻的观测作超前一步预测：\n$$\n\\sigma_{h+1}^2 = \\alpha_0 + \\alpha_1 a_{h}^2 + \\beta_1 \\sigma_{h}^2 \\in F_{h}\n$$\n所以\n$$\n\\begin{align}\n\\sigma_h^2(1) = E(\\sigma_{h+1}^2 | F_{h})\n= \\sigma_{h+1}^2 = \\alpha_0 + \\alpha_1 a_{h}^2 + \\beta_1 \\sigma_{h}^2 .\n\n\\end{align}\n$$\n对$\\sigma_{h+2}^2$，利用$a_t^2 = \\sigma_t^2 \\varepsilon_t^2$，有\n$$\n\\begin{aligned}\n\\sigma_{h+2}^2 =\u0026 \\alpha_0 + \\alpha_1 a_{h+1}^2 + \\beta_1 \\sigma_{h+1}^2  \\\\\n=\u0026 \\alpha_0 + \\alpha_1 \\sigma_{h+1}^2 \\varepsilon_{h+1}^2 + \\beta_1 \\sigma_{h+1}^2 \\\\\n=\u0026 \\alpha_0 + (\\alpha_1 \\varepsilon_{h+1}^2 + \\beta_1) \\sigma_{h+1}^2\n\\end{aligned}\n$$\n于是\n$$\n\\sigma_h^2(2)\n= E(\\sigma_{h+2}^2 | F_{h})\n= \\alpha_0 + E(\\alpha_1 \\varepsilon_{h+1}^2 + \\beta_1 | F_h) \\sigma_{h+1}^2\n= \\alpha_0 + (\\alpha_1 + \\beta_1) \\sigma_h^2(1)\n$$\n类似地，对$\\ell \\geq 2$有\n$$\n\\sigma_{h+\\ell}^2\n= \\alpha_0 + \\alpha_1 \\varepsilon_{h+\\ell-1}^2 \\sigma_{h+\\ell-1}^2 + \\beta_1 \\sigma_{h+\\ell-1}^2\n= \\alpha_0 + (\\alpha_1 \\varepsilon_{h+\\ell-1}^2 + \\beta_1) \\sigma_{h+\\ell-1}^2\n$$\n于是\n$$\n\\begin{align}\n\\sigma_h^2(\\ell)\n=\u0026 E\\left\\{ \\sigma_{h+\\ell}^2 | F_h \\right\\} \n= \\alpha_0 \n+ E\\left\\{ (\\alpha_1 \\varepsilon_{h+\\ell-1}^2 + \\beta_1) \\sigma_{h+\\ell-1}^2 | F_h \\right\\} \\\\\n=\u0026 \\alpha_0 \n+ E\\left\\{ E\\left[ \n(\\alpha_1 \\varepsilon_{h+\\ell-1}^2 + \\beta_1) \\sigma_{h+\\ell-1}^2 | F_{h+\\ell-2} \n\\right] | F_h  \\right\\} \\\\\n=\u0026 \\alpha_0 \n+ E\\left\\{ \\sigma_{h+\\ell-1}^2 E\\left[ \n\\alpha_1 \\varepsilon_{h+\\ell-1}^2 + \\beta_1 | F_{h+\\ell-2} \\right]\n| F_h \\right\\} \n\\quad(\\text{注意}\\sigma_{h+\\ell-1}^2 \\in F_{h+\\ell-2}) \\\\\n=\u0026 \\alpha_0 \n+ \\left\\{ \\sigma_{h+\\ell-1}^2 (\\alpha_1 + \\beta_1) | F_h \\right\\}  \\\\\n=\u0026 \\alpha_0 + (\\alpha_1 + \\beta_1) \\sigma_h^2(\\ell-1)\n\n\\end{align}\n$$\n预测公式与自回归系数为$(\\alpha_1 + \\beta_1)$的ARMA(1,1)的超前预测公式相同。\n\n从$\\ell=1$迭代计算得\n$$\n\\sigma_h^2(\\ell)\n= \\frac{\\alpha_0[1 - (\\alpha_1 + \\beta_1)^{\\ell-1}]}{1 - (\\alpha_1 + \\beta_1)}\n+ (\\alpha_1 + \\beta_1)^{(\\ell-1)} \\sigma_h^2(1)\n$$\n\n只要$\\alpha_1 + \\beta_1 \u003c 1$就有\n$$\n\\sigma_h^2(\\ell)\n\\to\n\\frac{\\alpha_0}{1 - \\alpha_1 - \\beta_1} \n= \\text{Var}(a_t)\n$$\n即超前多步条件方差预测趋于$a_t$的无条件方差。\n\nGARCH模型有和ARCH模型类似的弱点。 在高频数据研究发现及时使用t分布， 分布厚尾性也不足； 对于收益率的正负不对称性无法反映。\n\n\n\n### 9.5 在险价值\n\n在险价值(Value-at-risk, VaR)是，如果一个资产在一定时期内（h天），损失大于等于V的概率小于a，那么我们说这个资产的对应h和a的VaR等于V。\n\n计算单个资产的VaR\n\n计算一个投资组合的VaR\n\n- 直接考察这个组合的回报数据\n  - 优点：简单\n  - 缺点：\n    - 有时没有足够的数据\n    - 投资组合的结构一般会变化，导致历史回报数据不能很好反应将来\n- 考察组合内的每个资产的风险，根据当前的组合结构加总\n  - 问题在于需要估计资产之间的相关性\n  - 多元GARCH模型是解决这个相关性问题的一个有效模型\n\n\n\n### 9.6 改进的GARCH模型\n\n### 9.6.1 EGARCH\n\nEGARCH(m,s)模型可以用滞后算子的形式写成\n$$\n\\begin{align} a_t = \\sigma_t \\varepsilon_t, \\quad \\ln\\sigma_t^2 = \\alpha_0 + \\frac{1 + \\beta_2B + \\dots \\beta_s B^{s-1}}{1 - \\alpha_1 B - \\dots - \\alpha_m B^m} g(\\varepsilon_{t-1}),\\quad   g(\\varepsilon_t) = \\theta\\varepsilon_t + \\gamma\\left[ |\\varepsilon_t| - E|\\varepsilon_t| \\right] \\end{align}\n$$\n\n$\\alpha_0$为常数， 其中B是滞后算子， 多项式$1 + \\beta_2 z + \\dots + \\beta_s z^{s-1}$和$ 1 - \\alpha_1 z - \\dots - \\alpha_m z^m$的根都在单位圆外且两个多项式没有公因子。\n\nEGARCH(m,s)模型的另一种形式是\n$$\n\\begin{align}\n\\ln\\sigma_t^2\n= \\alpha_0 \n+ \\sum_{i=1}^m \\alpha_i\n\\frac{|a_{t-i}| + \\gamma_i a_{t-i}}{\\sigma_{t-i}}\n+ \\sum_{j=1}^s \\beta_j \\ln\\sigma_{t-j}^2\n\n\\end{align}\n$$\n这时， 正的扰动$a_{t-i}$对于对数波动率$\\ln\\sigma_{t}^2$的贡献为 $\\alpha_i (1 + \\gamma_i) |\\varepsilon_{t-i}|$， 而负的对数波动率的影响为$ \\alpha_i (1 - \\gamma_i) |\\varepsilon_{t-i}|$， 其中$\\varepsilon_{t-i} = a_{t-i}/\\sigma_{t-i}$， 其正负号由扰动$a_{t-i}$的正负号决定。 参数$\\gamma_i$代表了扰动的正负号的不同影响， 称为杠杆效应， 一般期望$\\gamma_i$是负数， 这样负扰动时影响更大（若$\\alpha_i \\geq 0$）。\n\n解决GARCH的问题：\n\n- 过去扰动对将来波动率的影响是对称的，但实际上大跌比大涨带来更大的市场波动\n  - 心理因素\n  - 杠杆效应\n- 参数约束给模型估计带来困难\n\n缺点：\n\n- 参数估计更困难：尽管少了非负约束，但是存在浮点溢出问题\n- 关键在于是否有非对称性\n\n### 9.6.2 IGARCH\n\n- 金融时间序列数据中，波动率一般存在较强的持续性，$\\alpha+\\beta$接近1\n- 波动率几乎是一个单位根过程\n\nIGARCH(1,1)：\n$$\n\\sigma_t^2=\\alpha_0+\\beta_1\\sigma_{t-1}^2+(1-\\beta_1)\\varepsilon_{t-1}^2,0\u003c\\beta_1\u003c1\n$$\n尽管波动率过程非平稳，但依然可以用MLE方法进行一致估计\n\n问题：波动率长期均值不存在，不太适合预测较为长期的波动率\n\n### 9.7 实现波动率\n\n用历史数据计算标准差作为波动率\n\n优点：简单、符合直觉\n\n缺点：\n\n- 隐含假设为结构变化，即在一个月之内的方差相同，而在月末相邻两天（分别属于两个月）却不一样。这个假设没有理论基础。\n- 对月度方差，一般只有 21/22 个数据，这样的样本量对方差估计来说偏少\n- 如果要计算周度、日度回报的方差，问题更大\n  - 样本量问题改进方法之一：用高频数据，比如日内intraday每一分钟的数据。\n  - 但有两个问题：\n    - 微观结构误差\n    - 非交易时段的波动率估计问题：由于回报是一段时期内，用日度回报计算问题不大，时间全覆盖\n  - 样本量问题改进方法之二：用运动窗口，即计算t日的波动率，用从t-m日到t日的日度回报观测值\n    - 一个大问题是'ghosting': 某一个观测值（比较大的波动）对接下来的m天的波动率估计有影响，但突然在m+1天时没有影响\n\n#### 9.7.1 EWMA\n\n$$\n\\begin{align}\\frac{x_{t-1}+\\lambda x_{t-2}+\\lambda^{2} x_{t-3}+\\ldots+\\lambda^{n-1} x_{t-n}}{1+\\lambda+\\lambda^{2}+\\ldots+\\lambda^{n-1}}\n\\\\\n\\hat{\\sigma}_{t}^{2}=(1-\\lambda) \\sum_{i=1}^{\\infty} \\lambda^{i-1} r_{t-i}^{2}\n\\end{align}\n$$\n\n- $\\lambda=1$且$n$有限时，就是通常的样本方差\n- $\\lambda$越大，最近的波动在波动率的估计中越不重要\n- IGARCH(1,1)的$\\alpha_0=0$时，就是EWMA模型\n- 但参数的选取不一样：IGARCH中$\\beta$是用历史数据估计的，EWMA中是使用者主观选取的\n  - 金融市场上，0.75-0.98；短期用小的$\\lambda$，长期用大的$\\lambda$\n- 多长数据来计算EWMA？\n  - 目前业界经常用过去n天的日度回报数据计算波动率（调整时间）用来作为将来n天回报的波动率的预测。比如为一个20天到期的期权定价预测20天股票回报的波动率，就用过去20天的日度回报计算样本标准差，再乘上$\\sqrt{20}$\n  - 但如果n比较小，比如10天，那也会用稍微多些的样本，比如20天\n  - 预测长期波动率而要用长期数据时，有一个问题是过去某个市场有激烈波动的特别时点是否应该加入？这个问题与前面讨论GARCH模型的样本选择一样，完全主观\n  - 一定用日度数据？对比较长期的波动率预测，周度甚至月度数据也经常用\n  - 在VaR的计算上，用GARCH计算的VaR会比正态假定的VaR更大。GARCH和等权方差在VaR计算上捕捉肥尾现象比EWMA更好。\n\n\n## 10 向量自回归模型\n多个资产收益率的联合模型中最常用的是向量自回归 (Vector Autoregression, VAR)模型。 称k元时间序列$\\boldsymbol r_t$服从一个一阶向量自回归模型， 即VAR(1)，若有\n$$\n\\begin{align}\n\\boldsymbol r_t\n= \\boldsymbol\\phi_0 + \\boldsymbol\\Phi \\boldsymbol r_{t-1}\n+ \\boldsymbol a_t\n\n\\end{align}\n$$\n其中$\\boldsymbol\\phi_0$是$k$维常数向量， $\\boldsymbol\\Phi$是$k$阶常数方阵，$ \\{\\boldsymbol a_t\\}$是序列不相关的弱平稳列， $E\\boldsymbol a_t $= $\\boldsymbol 0, \\text{Var}(\\boldsymbol a_t) = \\boldsymbol\\Sigma\u003e0$(对称正定矩阵)。\n\n文献中经常假定$\\{ \\boldsymbol a_t \\}$服从多元正态分布$ N_k(\\boldsymbol 0, \\boldsymbol\\Sigma)$， 则这时$\\boldsymbol a_t$是独立同分布随机向量序列。\n\n记$\\boldsymbol a_t = (a_{1t}, \\dots, a_{kt})^T， \\boldsymbol\\phi_0 = (\\phi_{10}, \\dots, \\phi_{k0})^T, \\boldsymbol\\Phi=(\\phi_{ij})_{k\\times k}$。\n\n### 10.1 定阶\n\n估计VAR(p)和VAR(p-1)，看第$p$阶滞后项的系数是否显著\n$$\n\\begin{aligned}\nM(p) =\u0026 - (T - k -p -\\frac32) \\ln \\frac{|\\hat{\\boldsymbol\\Sigma}_p|}{|\\hat{\\boldsymbol\\Sigma}_{p-1}|}\n\\end{aligned}\n$$\n卡方分布，自由度为$p^2$\n\n### 10.2 模型结构和格兰杰因果性\n\n格兰杰检验：\n\n首先在没有$x$的历史值的时候，确定模型大小：\n$$\n\\begin{array}{c}{y_{t}=a_{10}+\\sum_{i=1}^{m} a_{1 i} y_{t-i}+\\varepsilon_{t}} \\\\ {\\operatorname{FPE}(m)=\\frac{T+m+1}{T-m+1} \\frac{\\operatorname{ESS}(m)}{T}}\\end{array}\n$$\n选择阶数：\n$$\n\\begin{array}{c}{y_{t}=a_{20}+\\sum_{i=1}^{m} a_{2 i} y_{t-i}+\\sum_{j=1}^{k} b_{2 j} x_{t-j}+\\varepsilon_{t}} \\\\ {\\operatorname{FPE}(m, k)=\\frac{T+m+k+1}{T-m-k+1} \\frac{\\operatorname{ESS}(m, k)}{T}}\\end{array}\n$$\n构造F统计量\n$$\nF=\\frac{\\left(\\mathrm{ESS}_{1}-\\mathrm{ESS}_{2}\\right) / k}{\\mathrm{ESS}_{2} /[T-(k+m+1)]}\n$$\n如果统计量大于临界值，拒绝原假设：系数为零。有格兰杰效应。\n\n### 10.3 脉冲反应\n\n用待定系数法：\n\n- 给定VAR：$(I-a_1 L-a_2 L^2-\\dots a_p L^p) y_t=a_0+ε_t$\n- 假设我们有对应的VMA：$y_t=μ+(I+β_1 L+β_2 L^2+⋯)\\varepsilon_t$\n- 把VMA中的$y$代入到VAR中，有$(I-a_1 L-a_2 L^2-⋯a_p L^p) (I+β_1 L+β_2 L^2+⋯) =I$\n- 那么方程左边$L$的系数为0，$L^2$的系数为0……\n- $β_i$可求。\n\n### 10.4 方差分解\n\n\n$$\n\\begin{aligned} \\mathbf{A}=\\mathbf{L D L}^{\\mathrm{T}} \u0026=\\left(\\begin{array}{ccc}{1} \u0026 {0} \u0026 {0} \\\\ {L_{21}} \u0026 {1} \u0026 {0} \\\\ {L_{31}} \u0026 {L_{32}} \u0026 {1}\\end{array}\\right)\\left(\\begin{array}{ccc}{D_{1}} \u0026 {0} \u0026 {0} \\\\ {0} \u0026 {D_{2}} \u0026 {0} \\\\ {0} \u0026 {0} \u0026 {D_{3}}\\end{array}\\right)\\left(\\begin{array}{ccc}{1} \u0026 {L_{21}} \u0026 {L_{31}} \\\\ {0} \u0026 {1} \u0026 {L_{32}} \\\\ {0} \u0026 {0} \u0026 {1}\\end{array}\\right) \\\\ \u0026=\\left(\\begin{array}{ccc}{D_{1}} \u0026 {L_{21}^{2} D_{1}+D_{2}} \\\\ {L_{31} D_{1}} \u0026 {L_{31} L_{21} D_{1}+L_{32} D_{2}} \u0026 {L_{31}^{2} D_{1}+L_{32}^{2} D_{2}+D_{3}}\\end{array}\\right) \\end{aligned}\n$$\n\n",title:"Untitled Page"},"/Futures":{content:"---\nArea: Finance\nSource: Book\nStatus: Done\nType: Notes\n---\n\n## 期货市场的运作机制\n\n### 背景知识\n\nCME集团：芝加哥交易所、芝加哥商业交易所、纽约商品交易所\n\n期货合约的平仓：\n\n大多数期货交易不会导致实物交割，原因是大多数投资人在合约规定的交割期到来之前会选择平仓。对一个合约平仓就是进入一个与初始交易头寸相反的头寸。\n\n### 期货合约的规格\n\n- 合约规模(contract size)定义了在每一份合约中交割资产的数量。\n    - 合约规模太大，希望对冲较小头寸的投资者或希望持有较小头寸的投机者就不可能通过交易所交易\n    - 由于交易成本的存在，合约规模太小时会使交易成本太高\n- 农产品期货合约中交割资产的价值从10000美元到20000美元不等，金融期货合约的规模要大得多。\n- 小型合约可以吸引小额度投资者。(Mini Nasdaq 100)\n\n### 交割安排\n\n- 交割地点必须是交易所指定的地点。\n- 选择其他交割地点时，期货的空头方所收入的价格会随着交割地点的不同而被调整。\n- 具体交割时间由期货的空头方来决定\n- 通常的规则是交易所将交割产品意向书转给持有多头时间最久的投资者，而持有多头的一方必须接受交割通知。但是如果通知是可转让的，多头方投资方会有很短一段时间（半小时）来找到另一个持有多头的投资者来接受交割通知\n- 有些金融期货采用现金形式结算，所有未平仓的合约都在某个预先指定的日子平仓，最后的结算价格等于标的资产在这一天开盘时或收盘时的即期价格\n\n### 交割月份\n\n- 期货合约通常以交割月份命名，交易所必须明确指出在交割月份内的哪一段时间内可以交割。\n- 三个重要日期：第一交割通知日、最后交割通知日、最后交易日\n\n### 交易所\n\n- 是为其会员服务的、非盈利的会员制组织\n- 目标：提供一个公平、公正、公开的期货交易市场\n- 主要业务活动：制定、修改期货交易规则，维护市场的有效运转\n- 收入来源：主要是会员缴纳的会费与交易服务费（含交易费）\n\n#### 会员\n\n- 投资银行、经纪公司、自营商\n- 只有会员才能进场交易，交易所必须对会员的资信负责，非会员的客户必须通过会员代理进行交易\n- 会员是代理交易的主体，对其所代理的交易负全部责任。会员必须控制好所有客户的资金风险，如果因客户违约造成损失而不能履行赔偿责任时，会员必须代为履行赔偿责任并保留追偿的权利\n\n#### 客户\n\n- 普通客户在期货经纪公司建立交易账户以后，下单委托经纪公司进行交易\n- 在接到客户的委托单并确认以后，经纪公司利用在交易所的席位进行交易\n- 管理客户的账户，接受客户的交易委托，有的还提供咨询服务\n\n#### 结算公司\n\n- 非营利机构，通常来说，结算公司的会员集合是交易所会员集合的子集\n- 与期货市场相对应，结算管理体系也是分层次的\n    - 首先是交易所结算机构对会员公司的结算，这是第一级结算\n    - 其次是会员公司对其代理的客户进行结算，称为第二级结算\n    - 最终，将逐笔交易风险分级对应到每个市场参与者身上\n\n### 交易制度\n\n#### 价格波动限制与头寸限制\n\n- 许多交易所都限制期货价格每天的波动幅度与投机商持有的头寸\n- 如果交易所不对投机商的头寸进行限制，那么期货市场有可能演变成为多、空双方比拼资金实力的搏杀，变成一个大赌场，从而严重背离建立期货市场的初衷\n- 交易所限制期货价格每天的波动幅度的出发点是为了控制价格过度波动。但是，对是否能够抑制期货价格的长期波动，理论界与实务界都存在争议。此外，控制价格会扭曲期货的价格发现功能，阻碍信息的传递与扩散\n\n#### 交割\n\n- 对冲平仓、实物交割（1%-3%）、现金交割\n\n### 保证金制度\n\n- 每日交易盈亏计算，计算的结果作为收取交易保证金或追加保证金的依据。每个交易日结束时，保证金账户的金额数量都会得到调整。(daily settlement/marking to market)\n- 投资者的损失会从保证金账户里扣除；当保证金账户余额低于维持保证金水平时，投资人会收到保证金催缴，要追加保证金。\n- 当投资人不提供追加保证金时，经纪人将对合约平仓。\n- 远期合约只有在最后到期时才会进行结算，而期货合约每天都需要结算。相当于期货合约每天都要进行一次平仓，然后又以新价格开仓。\n- 对保证金的要求可能取决于交易员的交易目的：\n    - 对对冲者的保证金要求（2%-4%）可能低于对投机者的保证金要求（5%-7%）\n    - 对短线交易（在同一天平仓，day trade）和差价交易的保证金要求可能低于对冲交易的保证金。\n\n优点和问题\n\n- 优点：\n    - 标准化，提高流动性\n    - 结算程序，避免违约风险\n    - 杠杆效应，以小搏大\n- 问题：\n    - 距离交割日较远的期货合约流动性比较差\n    - 保证金账户的管理带来交易成本\n\n### 场外市场\n\n中央交易对手\n\n- 中央交易对手为标准的场外交易进行结算\n\n双边结算\n\n- 不能通过CCP结算的产品都要双边结算\n- 公司双方要签署主协议，提供抵押品，抵押品的功能类似于交易所清算中心或CCP对其会员要求的保证金\n\n### 结算价格\n\n- 用于计算每天合约的盈亏以及所需要的保证金数量\n\n### 交易量和未平仓合约数量\n\n- 交易数量是在一天内交易的合约总份数。\n- 未结权益(open interest)是尚未平仓合约份数的总量，是所有多头的总和，也是所有空头的总和。\n\n## 远期和期货价格\n\n### 投资资产与消费资产\n\n- 投资资产：投资者为了投资目的而持有的资产\n- 消费资产：持有消费资产的主要目的是消费而不是投资（猪肉、油、铜）\n- 对于投资资产，我们可以从无套利假设出发由即期价格与其他市场变量得出远期和期货价格，但对于消费资产做不到这一点。\n\n### 假设与符号\n\n- 假设：\n    - 市场参与者进行交易时没有手续费\n    - 市场参与者对所有交易净利润都使用同一税率\n    - 市场参与者能够以同样的无风险利率借入和借出资金\n    - 当套利机会出现时，市场参与者会马上利用套利机会\n- 符号：\n    - $T$: 远期或期货合约的期限（年）\n    - $S_0$: 远期或期货合约标的资产的当前价格\n    - $F_0$: 远期或期货的当前价格\n    - $r$: 按连续复利的无风险零息利率，期限对应于合约的交割日\n\n### 远期价值与远期价格\n\n#### 在交割前没有现金流\n\n远期价值：远期合约本身的**价值**。\n\n远期价格：使得远期价值为零的合理\u003cu\u003e交割\u003c/u\u003e价格\n\n远期合约的价值（对于多头方）：\n$$\nf=(F_0-K)e^{-r(T-t)}\n$$\n\n- $K$是以前成交的合约的交割价格，合约的交割日期是在从今日起$T-t$年之后，$F_0$表示目前的远期价格，即假如在今天成交的话，合约的\u003cu\u003e交割\u003c/u\u003e价格。\n- 如果今天恰好是合约的最初成交日，那么交割价格$K$等于远期价格$F_0$，$f$等于0.\n- 随着时间的推移，$K$不变，$F_0$不断变动。\n\n\u003e 证明：构造组合：  \n组合A ：今天花$f$以进入这份交割价格为$K$的旧远期合约的多头  \n组合B ：以无风险利率借入一笔数额为$𝐾𝑒^{−𝑟(𝑇−𝑡)}$ 的现金（在期末还款），同时花了$S_0$购买一单位标的资产  \n期末时两种组合的现金流都等于付出合约设定的价格$K$拥有一单位标的资产，因此今天的现金流也必须相等：\n\u003e$$f=S_0-Ke^{-r(T-t)}$$  \n\n\u003e 构造组合：  \n组合A：今天花$f$以进入这份交割价格为$K$的旧远期合约的多头  \n组合B：今天在市场上进入一个新远期合约的多头（意味着交割价格为$F_0$），同时以无风险利率投资$(F_0-K)e^{r(T-t)}$元  \n期末时两种组合的现金流都等于付出合约设定的价格$K$拥有一单位标的资产，因此今天的现金流也必须相等：\n\u003e$$f=(F_0-K)e^{-r(T-t)}$$\n\n\n### 分派红利的情况\n\n#### 确定时点分派的红利\n\n假设标的资产在合约到期之前产生的收入的\u003cu\u003e现值\u003c/u\u003e为$I$：\n$$\nF_0=(S_0-I)e^{rT}\n$$\n\n#### 连续复利\n\n连续复利（红利再投资），标的资产的数量在增长。假设红利率为$q$：\n$$\nF_0=S_0e^{(r-q)T}\n$$\n\n\u003e 证明：  \n组合A：进入一个远期合约的多头  \n组合B：以无风险利率借入$S_0$，全部用来买一单位标的资产  \n期初时两组合的现金流都是0，所以期末时两组合的价值必须相等。\n\u003e $$\\begin{aligned}\nS_T-F_0\u0026=S_T+Ie^{rT}-S_oe^{rT}\\\\\nF_0\u0026=(S_0-I)e^{rT}\n\\end{aligned}$$  \n\n\u003e 组合A：进入一个远期合约的多头  \n组合B：以无风险利率借入$S_0e^{-qT}$，全部用来买$e^{-qT}$单位的标的资产  \n期初时两组合的现金流都是0，所以期末时两组合的价值必须相等。\n\u003e $$\\begin{aligned}\nS_T-F_0\u0026=S_T-S_0e^{（r-q)T}\\\\\nF_0\u0026=S_0e^{(r-q)T}\n\\end{aligned}$$\n\n\n### 外汇远期合约\n\n- 指交易双方约定在未来某一特定日期，双方按照合约签订时约定的汇率和金额，以一种货币交换对方另一种货币的合同\n\n利率平价关系\n$$\n{F}_0=S_0 e^{\\left(r_{1}-r_{2}\\right){T}}\n$$\n其中，$r_1$与$r_2$分别表示报价货币与基本货币的连续复合无风险利率；$F_0$与$S_0$表示远期汇率与即期汇率，它们都是用报价货币来表示基本货币，即1单位的基本货币相当于多少单位的报价货币。\n\n\u003e 证明：两种方式将基本货币转化为报价货币：  \n方式1：现在将一单位的基本货币换成报价货币，再以无风险利率投资一期  \n方式2：先将一单位的基本货币以无风险利率投资一期，再将其换为报价货币\n\u003e $$S_0e^{r_1T}=F_0e^{r_2T},F_0=S_0e^{(r_1-r_2)T}$$\n\n一份远期汇率合约多头头寸的价值等于：\n$$\nf=S_0e^{-r_2T}-Ke^{-r_1T}\n$$\n\n外汇可以看作提供已知收益率的资产。这里的收益率为外汇的无风险利率。\n\n### 商品期货存在收入和贮存费用时\n\n假定U为期货期限之间所有去掉收入后贮存费用的贴现值，有：\n$$\nF_0=(S_0+U)e^{rT}\n$$\n$$\nF_0=S_0e^{(r+u)T}\n$$\n\n#### 消费商品\n\n用于消费而不是投资的商品往往不提供中间收入，但这些商品可能需要很高的贮存费用。\n\n当持有商品的主要目的不是投资时，个人不愿意在即期市场出售商品并买入期货合约，因为远期和期货合约不能用于消费。\n$$\nF_0\\le (S_0+U)e^{rT}\n$$\n$$\nF_0\\le S_0e^{(r+u)T}\n$$\n\n### 便利收益率\n\n便利收益率（convenience yield）：由于持有商品而带来的好处。\n\n持有商品库存可以确保工厂的正常运作，但持有期货显然不能，或许可从暂时的商品短缺中盈利。\n\n便利收益率反映了市场对将来能够购买商品的可能性的期望。商品短缺的可能性越大，便利收益率越高。\n\n$$\nF_0e^{yT}=(S_0+u)e^{rT}\n$$\n$$\nF_0e^{yT}=S_0e^{(r+u)T}\n$$\n$$\nF_0=S_0e^{(r+u-y)T}\n$$\n\n### 持有成本\n\n持有成本：包括贮存成本加上资产的融资利息减去资产的收益。\n\n### 期货价格与预期未来即期价格\n\n|  标的资产  | 资产收益率期望$k$与无风险利率$r$之间的关系 | 期货价格$F_0$与预期未来即期价格$E(S_T)$之间的关系 |\n| :--------: | :----------------------------------------: | :-----------------------------------------------: |\n| 无系统风险 |                   $k=r$                    |                   $F_0=E(S_T)$                    |\n| 正系统风险 |                   $k\u003er$                    |                   $F_0 \u003c E(S_T)$                    |\n| 负系统风险 |                   $k \u003c r$                    |                   $F_0\u003eE(S_T)$                    |\n\n\n\n\n\n### 正常期货溢价和期货倒价\n\n- 现货溢价（normal backwardation）：期货价格低于将来即期价格期望值\n- 期货溢价（contango）：期货价格高于将来即期价格期望值\n\n## 利用期货的对冲策略\n\n### 空头对冲与多头对冲\n\n- 空头对冲（short hedge）：对冲者已经拥有某种资产并期望在将来某时刻卖出资产，或者当前不知道拥有资产但预计未来会拥有资产。\n- 多头对冲（long hedge）：已知在将来需要买入一定资产并想在今天将价格锁定。\n- 在某些行业里，如果对冲不是常规做法，公司选择与别人都不相同的做法也许没有太大意义。\n- 对冲可能会使结果更糟\n\n### 基差风险\n\n实际中的对冲问题：\n\n- 需要对冲价格风险的资产与期货合约的标的资产可能并不完全一样\n- 对冲者可能无法确定买入或卖出资产的准确时间\n- 对冲者可能需要在期货到期月之前将期货平仓\n\n基差\n\n- 基差（basis）=被对冲资产的即期价格-用于对冲的期货合约价格\n- 基差变大时称为基差增强（strengthening of the basis），基差变小时称为基差减弱（weakening of the basis）\n- 基差增强空头获利，基差减弱多头获利\n\n### 对合约的选择\n\n- 对期货合约标的资产的选择\n- 对交割月份的选择：经常选择在稍后月份交割的期货合约，防止实物交割的风险和花费。\n\n### 交叉对冲\n\n- 交叉对冲（cross hedging）：对冲时所用期货的标的资产和被对冲的资产是不一样的。\n- 对冲比率（hedging ratio）：持有期货合约的头寸数量与资产风险敞口数量的比率。\n\n#### 计算最小方差对冲比率\n\n定义：\n\n$\\triangle S$：在对冲期限内，即期价格$S$的变化；\n\n$\\triangle F$：在对冲期限内，期货价格$F$的变化；\n\n$h^*$：最小方差对冲比率。\n\n最小方差对冲比率是$\\triangle S$对$\\triangle F$进行线性回归时所产生的最优拟合直线的斜率。\n$$\nh^*=\\rho \\frac{\\sigma_S}{\\sigma_F}\n$$\n$\\sigma_S, \\sigma_F$是$\\triangle S, \\triangle F$的标准差，$\\rho$是两者之间相关系数。（通过线性回归公式和相关系数公式可推理得到。）\n\n#### 最优合约数量\n\n定义：\n\n$Q_A$：被对冲头寸的数量\n\n$Q_F$：一份期货合约的规模\n\n$N^*$：用于对冲的最优期货合约数量\n$$\nN^*=\\frac{h^*Q_A}{Q_F}\n$$\n\n#### 尾随对冲\n\n- 期货合约每天结算，考虑每一天百分比变化的标准差\n- 期限为一天的比例为：\n\n$$\\hat{\\rho} \\frac{S \\hat{\\sigma}_{s}}{F \\hat{\\sigma}_{F}}$$\n\n- 为下一天所需持有的最优合约数量：\n\n$$N^{*}=\\hat{\\rho} \\frac{S \\hat{\\sigma}_{s} Q_{A}}{F \\hat{\\sigma}_{F} Q_{F}}$$\n\n### 向前滚动对冲\n\n- 对冲的期限要比所有能够利用的期货期限更长，这时对冲者必须对到期的期货进行平仓，同时再进入具有较晚期限的合约。这种做法被称为向前滚动对冲（stack and roll）。\n- 考虑流动性的潜在问题\n\n## 股指期货\n\n- 是指由交易双方签订的，约定在将来某一特定时间和地点交收“一定点数的股票价格指数”的标准化期货合约，亦即是以股票价格指数 （投资组合）为交易标的物的一种期货合约。\n\n### 合约规格\n\n- 合约价格：\u003cu\u003e指数期货价格\u003c/u\u003e乘以一个指数点的价值\n- 指数期货的面值：\u003cu\u003e股票指数\u003c/u\u003e乘以一个指数点的价值\n\n### 最优合约数量\n\n定义：\n\n$V_A$：股票组合的当前价值。\n\n$V_F$：一份期货的当前价值（定义为期货价格乘以期货规模）。\n$$\nN^*=\\beta\\frac{V_A}{V_F}\n$$\n\n### 对冲股权组合的理由\n\n- 传统的股票市场风险管理只是通过调整股票构成和头寸改变投资组合的系统风险\n    - 缺点：\n        - 交易成本高、调整速度慢、可能不得不降低$\\alpha$\n        - 投资者对市场的整体风险很不确定，但确信组合中的股票收益会高于市场的收益。\n- 对冲者计划在很长一段时间内持有股票组合，但需要在短时间内对市场的不确定性进行保护。\n\n### 改变组合的beta\n\n当将组合的beta从$\\beta$变为$\\beta^*$时，\n\n如果$\\beta\u003e\\beta^*$，所持期货空头的数量应当为：\n$$\n(\\beta-\\beta^*)\\frac{V_A}{V_F}\n$$\n如果$\\beta\u003c\\beta^*$，所持期货多头的数量应当为：\n$$\n(\\beta^*-\\beta)\\frac{V_A}{V_F}\n$$\n\n### 锁定挑选股票的优势\n\n投资者确认自己持有的股票将比市场表现要好，持有的股指期货合约空头数量为：\n$$\n\\beta\\frac{V_A}{V_F}\n$$\n其中$\\beta$为持有的股票的beta值，$V_A$为持有的股票价值，$V_F$为一份股指期货合约的价值。\n\n\n",title:"Untitled Page"},"/Logistics Regression":{content:"## Logistic Regression\n\n### Logit Model\n\n_Model_:\n\n$$\\pi_i=Pr(Y_i=1|X_i=x_i)=\\dfrac{\\text{exp}(\\beta_0+\\beta_1 x_i)}{1+\\text{exp}(\\beta_0+\\beta_1 x_i)}$$\n\nor,\n\n$$\\begin{aligned} \\text{logit}(\\pi_i)\u0026=\\text{log}\\left(\\dfrac{\\pi_i}{1-\\pi_i}\\right)\\\\ \u0026= \\beta_0+\\beta_1 x_i\\\\ \u0026= \\beta_0+\\beta_1 x_{i1} + \\ldots + \\beta_k x_{ik}\\\\ \\end{aligned}$$\n\n-   It uses maximum likelihood estimation (MLE) rather than ordinary least squares (OLS) to estimate the parameters, and thus relies on large-sample approximations.\n\nThe _maximum likelihood estimator_ (MLE) for $(\\beta_0, \\beta_1)$ is obtained by finding $(\\hat{\\beta}_0,\\hat{\\beta}_1)$ that maximizes:\n\n$$L(\\beta_0,\\beta_1)=\\prod\\limits_{i=1}^N \\pi_i^{y_i}(1-\\pi_i)^{n_i-y_i}=\\prod\\limits_{i=1}^N \\dfrac{\\text{exp}\\{y_i(\\beta_0+\\beta_1 x_i)\\}}{1+\\text{exp}(\\beta_0+\\beta_1 x_i)}$$\n\n-   $exp(\\beta_0)$ = the odds that the characteristic is present in an observation _i_ when _Xi_ = 0, i.e., at baseline.\n-   $exp(\\beta_1)$ = for every unit increase in _X_, the odds that the characteristic is present is multiplied by $exp(\\beta_1)$. This is similar to simple linear regression but instead of additive change it is a multiplicative change in rate. This is an estimated _odds ratio_.\n\n$$\\dfrac{\\text{exp}(\\beta_0+\\beta_1(x_{i1}+1))}{\\text{exp}(\\beta_0+\\beta_1 x_{i1})}=\\text{exp}(\\beta_1)$$\n\n### Probit Model\n\nThe _probit_ model\n\n$$\\text{probit}(\\pi(x))=\\beta_0+\\beta x$$\n\nuses _normal_ cdf\n\n$$\\text{probit}(\\pi)=F^{-1}(X \\leq x)$$\n\n### Hypothesis Tests\n\n#### Likelihood ratio tests\n\nThe likelihood for $n$ observations:\n\n$$L=\\prod_{i=1}^{n}\\left(\\frac{\\exp \\left(x_{i}^{\\prime} \\beta\\right)}{1+\\exp \\left(x_{i}^{\\prime} \\beta\\right)}\\right)^{\\sum_{i=1}^{n} Y_{i}}\\left(1-\\frac{\\exp \\left(x_{i}^{\\prime} \\beta\\right)}{1+\\exp \\left(x_{i}^{\\prime} \\beta\\right)}\\right)^{n-\\sum_{i=1}^{n} Y_{i}}$$\n\nLikelihood Ratio\n\n$$LR = −2\n\nl(\\hat\\beta|H_0) − 2l(\\hat\\beta|H_A)\\sim \\chi^2_p $$\n\nneed to fit two models: the full model and the model under $H_0$. Then $l(\\hat\\beta|H_0)$ is the log-likelihood from the model under $H_0$, and $l(\\hat\\beta|H_A)$ is the log-likelihood from the full model.\n\n$$LR=Deviance_A-Deviance_0 $$\n\n#### Wald tests\n\n$$\\frac{\\hat{\\beta}_{j}-\\beta_{j 0}}{\\hat{s e}(\\hat{\\beta})} \\sim N(0,1)$$\n\nLimitation\n\n### Overdispersion\n\nFor the binomial response, if $Y_i \\sim Bin(n_i, \\pi_i)$, the mean is $\\mu_i=n_i\\pi_i$ and the variance is $n_i\\pi_i(1-\\pi_i)$.\n\n-   **_Overdispersion_** means that the data show evidence that the variance of the response is greater than $n_i\\pi_i(1-\\pi_i)$.\n-   Overdispersion can be explained by\n    -   variation among the success probabilities\n    -   correlation between the binary responses\n\nThe most popular method for adjusting for overdispersion comes from the theory of quasi-likelihood.\n\n\n## Reference\n\nIntroduction to Econometrics / James H. Stock \u0026 Mark W. Watson C6-C9 esp. multiple t test\n\nProbability and Statistics / Morris H. DeGroot \u0026 Mark J. Schervish C7-C11 except C10\n\n[Lesson 7: Further Topics on Logistic Regression](https://online.stat.psu.edu/stat504/node/217/)\n\n[极大似然估计和贝叶斯估计](https://zhuanlan.zhihu.com/p/61593112)\n\n[Probability \u0026 Statistics Fundamental](https://nancyyanyu.github.io/posts/c27004a0/)\n\n[Logistic 回归模型的参数估计为什么不能采用最小二乘法？](https://www.zhihu.com/question/23817253)\n\n[在进行 OLS 估计时，为了满足 BLUE 条件，为什么会有 X 取值要在重复抽样时固定的前提？](https://www.zhihu.com/question/25832437)\n\n[](https://www.groups.ma.tum.de/fileadmin/w00ccg/statistics/czado/lec5.pdf)\n\n[](https://courses.washington.edu/b515/l13.pdf)\n\n[逻辑回归是否靠谱，你懂得如何裁判吗？](https://mp.weixin.qq.com/s?subscene=23\u0026__biz=MzAxMDA4NjU3OA==\u0026mid=2652553697\u0026idx=1\u0026sn=09f2a67c9fe3a7081ee8fd76d40150a6\u0026chksm=80bbd03cb7cc592a928c50b7b16518b1837d7a1258fa6d6cad305ff5e09525b98e26b1b147c8\u0026scene=7\u0026key=cc7cc2a0b445493e5a74d4ae079f895dfc0c723c3cff51870eaa2a2a299182d9309998c97eb86ff92300a6f2c05bd4d4f760054842fab5deff7b4ff39f1e151212234c47c80d1d2bf5d2c619ceb025d8a1f838dd7fbcb62c777b6239e637772bdecc698e4c1aadb4a61511031c88bfc27f30af629897d1c218e8cc582ff5a929\u0026ascene=0\u0026uin=MjU1NDk5MDUwOA%3D%3D\u0026devicetype=Windows+10+x64\u0026version=6300002f\u0026lang=zh_CN\u0026exportkey=A5G3CGCLpGJLnOrCZ13ZVHs%3D\u0026pass_ticket=ok4tnaFWS7zPPSCRKPSyUIzrRRcpn0LMaKl%2FkngUWsaWK0ChENo%2FKgwaJH5CCexq\u0026wx_header=0)",title:"Untitled Page"},"/MBS Duration":{content:"---\nArea: Finance\nSource: Book\nStatus: Done\nType: Notes\n---\n\n\n## 久期和凸性的定义\n\n[[Rates#久期和修正久期]]\n\n[[Rates#凸性]]\n\n\n## 有效久期 (Effective Duration)\n\n根据之前提到的[[OAS]]定义，有效久期的计算方法如下：\n\n- 根据市场价格P计算OAS.\n- 将收益率曲线平行向上移动$\\Delta y$，再加上用市场价格计算出的 OAS重新定价$P^{+}$.\n- 将收益率曲线平行向下移动$\\Delta y$，再加上用市场价格计算出的 OAS重新定价$P^{-}$.\n\n\n有效久期为：\n\n$$\nD=\\frac{P^{-}-P^{+}}{2P\\Delta y} \\times 100\n$$\n\n\n### 有效久期没有考虑的风险因素\n\n#### 国债曲线的变化\n\n在使用上述公式用有效久期预测价格变化时，我们认为整条利率曲线是**平行移动**的，并用10年期国债利率的变化代表整条利率曲线的变化。如果国债曲线的形状变得更陡峭或者更平缓，继续使用久期与利率变化的乘积来预测价格变化就会不够准确。\n\n#### 当前票息价差 (Current Coupon Spread)\n\nCurrent Coupon指的是目前市场价格恰好为面值 (par value) 的MBS的coupon（考虑了servicing fee之后），一般由线性插值得出，可以看做是par value MBS pass-through的yield. 大多数新发起的抵押贷款都以接近面值的票面利率证券化，因此current coupon yield可以被认为是新贷款的二级市场利率 (mortgage rate)。\n\nCurrent Coupon Spread是指current coupon和treasury rate之间的差值，相当于par value MBS pass-through的treasury OAS，也相当于mortgage rate和treasury rate之间的差值。\n\n有效久期的计算假设current coupon spread和国债利率之间是线性关系。但实际并非如此。如果current coupon spread增加，则说明相对于国债利率，贷款利率更高了，借款人的再融资动机减弱，所以提前还款的风险降低，久期增加，价格有可能上升。Current coupon spread的partial duration也因此是负的。利率曲线的形状、波动率、提前还款风险都会影响current coupon spread.\n\n\n#### 凸性或不对称价格变动\n\n由于 MBS 存在[[MBS Modelling#早偿情况的分析|提前偿还风险]]，所以利率下降时，再融资比例可能上升，借款人会选择提前偿还手中的贷款。因此对投资者来讲，**这相当于原本很长的久期突然变小了**。所以利率下降时，MBS的久期也有可能变小，其凸性是负的。这意味着，在其他条件相同的情况下，使用有效久期预测价格，将在利率下降时高估价格，而在利率上升时低估价格。\n\n投资于RMBS的机构持有者一般会在多RMBS的同时空国债作为对冲。由于MBS的负凸性性质，**利率上行，MBS久期增加，持有者就要卖空更多的国债以对冲久期，国债利率继续上行**。反之亦然。因此，MBS的负凸性可能是市场利率大幅变动的一个原因。\n\n\n\n#### 利率波动率\n\n利率的波动率可能会随着期限变化而改变，也有可能存在波动率聚集的现象。但使用有效久期预测价格时，认为利率曲线是平行移动的，没有考虑波动率的情况，可能会造成对价格的高估或低估。\n\n## 实际久期 (Empirical Duration)\n\n实际久期是指从市场数据中用回归分析的方式来估计久期。\n\n理论上有\n$$\n\\frac{\\Delta B}{B}=-D\\Delta y\n$$\n\n所以用$\\frac{\\Delta B}{B}$作为因变量，国债利率的变化作为自变量，采用过去一段时间的数据进行回归，回归的斜率估计量$\\beta$就是实际久期。\n\n## 有效久期和实际久期之间的关系\n\n如果其他的风险因素和国债利率变化之间存在相关性，则有效久期和实际久期之间就会有所不同。由线性回归的估计量性质，忽略价格变化的高阶项，有：\n\n$$\nD_{\\text{Empirical Estimate}} = D_{\\text{Current Effective}}+\\mu+D_{s} \\rho_{\\Delta s \\Delta y} \\frac{\\sigma_{\\Delta s}}{\\sigma_{\\Delta y}}+D_{v} \\rho_{\\Delta v \\Delta y} \\frac{\\sigma_{\\Delta v}}{\\sigma_{\\Delta y}}+\\ldots+\\varepsilon\n$$\n\n其中$\\mu$是当前有效久期和实际久期之差的平均值；$\\rho_{\\Delta s \\Delta y}$是相关系数；$\\sigma_{\\Delta s}$是标准差。\n\n如果风险因素的变化（如每日OAS）和国债收益率变化之间呈负相关，那么**实际久期将短于有效久期**。\n\n## 另一种实际久期的计算\n\n实际久期计算中的一个隐含假设是**国债收益率变化会立刻影响到同一天的MBS价格**。然而，流动性不够活跃的MBS不一定满足这个假设。例如，高溢价MBS的流通量很小，大部分交易都在SP进行，而不是TBA市场。因此，高溢价TBA的价格变化通常会滞后于国债收益率的变化，如果用同一天的价格变化进行回归，会导致对实际久期的估计偏低。\n\n为了解决这个问题，可以选用一段时间的MBS价格对国债收益率进行回归 ($ln\\ P =\\alpha + \\beta y+\\varepsilon, \\frac{dP/dy}{P} =−Duration = \\beta$)，斜率就是实际久期的估计量。它描述了**一段时间内**MBS价格和国债收益率水平之间的关系，因此这样计算出的久期可能不利于对冲每天的收益率曲线波动。\n\n## 久期和对冲\n\n有效久期可以对冲收益率曲线平行移动时发生的价格变化。使用有效久期意味着认为其他风险因素不变。\n\n实际久期假设过去的国债收益率变化与其他风险因素变化之间的关系将继续存在且相同。因此，如果风险因素和国债收益率之间的相关性发生了改变，使用实际久期可能会出现错误。\n\n\n\n\n\n\n\n## 参考文献\n\n\nHayre, L. (Ed.). (2001). _Salomon Smith Barney guide to mortgage-backed and asset-backed securities_. John Wiley.\n\n[RMBS随谈录4：RMBS对冲—美国固收市场大幅变动时的尾大摇身现象](https://mp.weixin.qq.com/s/QPGKf8RZiQNxkkNQoj3Rlg)\n\n[Managing Against MBS Indexes: A Duration Perspective](https://www.msci.com/www/blog-posts/managing-against-mbs-indexes-a/02667007821)\n\n[Measuring MBS curve risk with Implied Mortgage Rate Sensitivity (“IMS”) approach](https://research-doc.credit-suisse.com/docView?language=ENG\u0026format=PDF\u0026source_id=csplusresearchcp\u0026document_id=1041260871\u0026serialid=0MH9veO3E0x5Z%2B76qli7rYOAyJDVt7fLdbi2VSkop%2FA%3D\u0026cspId=null)\n\n[Can MBS Duration Turn Negative?](https://www.msci.com/www/blog-posts/can-mbs-duration-turn-negative/02108224451)",title:"Untitled Page"},"/MBS Modelling":{content:"---\nArea: Finance\nSource: Book\nStatus: Done\nType: Notes\n---\n\n\n# 抵押贷款支持证券\n\n资产证券化是指将能够产生可预见的稳定现金流的资产，通过一定的结构安排，对资产中风险与收益要素进行分离与重组，进而转换成为在金融市场上可出售、可流通的证券的过程。\n \n设法剥离主体带来的不确定性，以“物的信用”替代“主体信用”，以基础资产“自动变现”产生现金流为偿付支持发行标准化债务证券，通过引入第三方机构、架设结构化交易安排来拆解、控制道德风险，就是“资产支持证券”的核心理念。\n \n最早出现的资产支持证券是20世纪70年代诞生的以住宅抵押贷款为基础资产的RMBS，之后又陆续诞生了以其他信贷资产为支持的证券。\n\n传统的MBS交易结构中没有分层设计，所发行的证券之间不存在偿付次序、风险等级的区别，这种结构被称为“过手型” (pass-through) 结构。相对而言，将现金流进行分层、增信之后再按先后次序支付给不同等级证券投资人的交易结构叫作“转付型” (pay-through) 结构。\n\n和其他固定收益类产品一样，MBS的价值可以用现金流折现进行评估：\n\n$$\nV=\\sum_{i=1}^N\\frac{CF_i}{(1+d)^i}\n$$\n\n其中$d$为折现率 (discount rate). \n\n折现率和当前抵押贷款挂钩的利率种类的远期利率有关，可以采用随机过程模型对远期利率进行建模。如：\nVasicek Model\n$$\ndR_t=a(b-R_t)dt+\\sigma dW_t\n$$\nCIR Model\n$$\ndR_t=a(b-R_t)dt+\\sigma \\sqrt R_t dW_t\n$$\nHull-White Model\n$$\ndR_t=a(b_t-R_t)dt+\\sigma dW_t\n$$\n\n但不同的是，由于借款人可以选择提前偿还贷款，所以每一期的现金流是不确定的，会受到利率的影响。即：\n$$\nCF_i=f(r)\n$$\n\n市场利率上升会导致抵押贷款支持证券出现延长风险 (extension risk)。收益率上行时，预期中的提前还款速度放缓，导致抵押贷款支持证券投资者收回本金的时机延后。投资人将因为延后收回本金而错过在收益率较高时进行再投资的机会。如果利率继续上升，低票息抵押贷款支持证券的价格下跌，高票息抵押贷款支持证券的表现要好于低票息抵押贷款支持证券。\n\n\n市场利率下降将出现抵押贷款者提前清偿的风险 (prepayment risk)，使抵押贷款支持证券投资人被迫降低仓位，存续期限缩短。\n\n因此，在对MBS进行建模时，既要对每一期的折现情况进行建模，也要估计每一期现金流的情况。\n\n\n## 抵押贷款的现金流\n假设某支抵押贷款的年息票利率为$\\hat C$，到期日为$N$个月。令：\n$$\nc=\\frac{\\hat C}{12}, d=\\frac{1}{1+c}\n$$\n假设名义本金为单位1，每月还款额 (Scheduled monthly payment)为$m$，则应该有\n$$\n1=\\sum_{i=1}^N \\frac{m}{(1+c)^i}\n$$\n解得\n$$\nm=\\frac{c}{1-d^N}\n$$\n\n第$j$个月底，设尚未还款的余额为$B_j$，有\n$$\n\\sum_{i=1}^{j}\\frac{m}{(1+c)^i}+B=(1+c)^j\n$$\n得\n$$\nB_j=\\frac{1-d^{N-j}}{1-d^N}\n$$\n第$j$个月的利息偿还额为\n$$\nI_j = cB_{j−1}=\\frac{c\\left(1-d^{N-j+1}\\right)}{1-d^{N}}\n$$\n第$j$个月的本金偿还额为\n$$\nP_j = m-I_j=m-cB_{j−1}=\\frac{cd^{N-j+1}}{1-d^{N}}\n$$\n\n\n## 早偿情况的分析\n\n利率走低时，借款人更倾向于提前还贷，用更低利率的贷款置换现有贷款；利率走高时，借款人则倾向于放慢还贷速度，更多的享受低息好处。\n\n每月早偿率 (single monthly mortality rate, SMM) 衡量了贷款池中在当月提前偿还的比率：\n\n$$\nSMM=\\frac{Scheduled\\ balance − Ending\\ balance}{Scheduled\\ balance}\n$$\n\n条件早偿率 (Conditional Prepayment Rate, CPR) 是SMM的年化结果：\n$$\nCPR=1-(1-SMM)^{12}\n$$\n\n### PSA模型\n\nPSA模型 (Public Securities Association Model) 是估计早偿率的一种经验方法：第一个月的CPR设为0.2%，此后每个月增加0.2%的CPR，直到第30个月后，始终维持CPR为6%不变。150PSA的假设意味着要将PSA模型乘以150%。\n\n该模型的基本假设是，成立时间越久的抵押贷款，提前还贷的可能性越大，越是新贷款，提前还贷的可能性越小；但是，在贷款成立30个月之后，提前还贷比率将稳定在一个恒定的值而不再变化。\n\n\n### 影响早偿率的因素\n\n#### 主要因素\n\n**借款人再融资的动力 (Incentive to Refinance)**\n- 如果市场抵押贷款利率下降，抵押贷款者将有动力提前偿还贷款然后以较低的利率进行再融资，因此提高了早偿率。\n- 一般用现行市场利率和抵押贷款者的利率的差值来衡量借款人再融资的动力。\n\n**贷款持有时间 (Age of a Mortgage)**\n- 抵押贷款人可能因为工作调动、家庭因素、房屋价格影响而选择置换房屋，为此需要清偿抵押贷款，因此房屋换手情况对早偿率有影响。\n- 类似于PSA模型，将房屋换手率和抵押贷款人的贷款持有时间相关联，一般贷款账龄在30个月时CPR将达到顶峰。\n\n\n**季节因素**\n- 不同的月份和季度，还款人提前偿还的概率不同，主要和家庭因素相关（如为孩子上学而搬家），房屋的销售也有季节性。\n\n**贷款人的倦怠 (Borrower Burnout)**\n- 虽然一般情况下，利率下降会导致借款人有动力进行再融资，但有些时候会发现，即使利率下降，借款人也没有提前偿还。这可能是因为借款人此前已经提前还款过了，或者是这个池中的借款人对利率不敏感，不会进行再融资。\n- Burnout是用来捕捉某个特定的MBS中不同贷款的异质性，关注这个池中借款人之前的提前偿还记录，通过之前的行为来推测之后是否会有提前偿还的动力。\n	- 再融资速度：通过借款人从利率下降到进行再融资的反应时间判断这是一个快速还款人还是一个慢速还款人\n	- 逆向选择：信用条件较好的借款人会比信用条件更差的还款人更快进行再融资   \n$$\n\\text{burnout} = \\text{exp}^{\\beta_1\\times \\text{Loan\\ Age}+\\beta_2\\times \\text{Incentive}}\n$$\n$$\n\\text{where Incentive = Max[(Note rate − Mtg. rate), Start value]}\n$$\n- 其中$\\beta_1,\\beta_2$可以根据经验确定Burnout衡量了某个借款人是否会是快速还款人的先验概率。\n\n#### 其他因素\n\n**房价 (House Price Index, HPI)**\n**信用评分 (FICO)**\n**债务收入比 (Debt-to-Income Ratio, DTI)**\n**贷款价值比 (Loan-to-Value Ratio, LTV)**\n**贷款余额**\n- 由于再融资存在固定费用，对贷款余额较低的借款人来说，固定费用的占比会上升，所以余额较低的借款人需要更高的市场利率和原贷款利率差值才有提前还款再融资的动机。\n\n**贷款期限**\n- 通常，具有更强信用和更大财务灵活性的借款人会选择更短的摊销期限，这意味着 15 年的借款人可能比 30 年的借款人表现出更大的再融资倾向。\n\n**贷款利率类型**\n- 与标准固定利率抵押贷款相比，借款人可以选择可调整利率或混合抵押贷款（初始固定利率随后是可调整利率的抵押贷款），以获得较低的相对起始付款。不断浮动的贷款利率可能会激励借款人再融资。\n\n\n### 生存分析建模\n\nSchwartz和Torous利用1978-1987的美国30年期GNMA MBS数据，建立生存分析(survival analysis)模型，用Cox Proportional-hazards Model来对早偿率进行建模。\n\n设某个抵押贷款从开始到提前偿还的时间为连续随机变量$T$，$t$是其实现。设$\\underline{v}=\\left(v_{1}, v_{1}, \\cdots, v_{s}\\right)$为由影响早偿率的各种变量组成的向量，$\\underline{\\theta}=\\left(\\theta_{1}, \\theta_{2}, \\cdots, \\theta_{k}\\right)$是需要估计的系数值。早偿率函数$\\lambda(t ; \\underline{v}, \\underline{\\theta})$可以写为：\n$$\n\\begin{aligned}\n\\lambda(t ; \\underline{v}, \\underline{\\theta}) \u0026=\\lim _{\\Delta t \\rightarrow 0^{+}} \\frac{P(t \\leq T\u003ct+\\Delta t \\mid T \\geq t)}{\\Delta t} \\\\\n\u0026=\\frac{f(t ; \\underline{v}, \\underline{\\theta})}{F(t ; \\underline{v}, \\underline{\\theta})}\n\\end{aligned}\n$$\n其中$f(t)$是$T$的概率密度函数，$F(t)$是$T$的分布函数。\n$$ \nF(t ; \\underline{v}, \\underline{\\theta})=P(T \\geq t \\mid \\underline{v}, \\underline{\\theta}) \n$$\n\n$$ \nf(t ; \\underline{v}, \\underline{\\theta})=\\lim _{\\Delta t \\rightarrow 0^{+}} \\frac{P(t \\leq T\u003ct+\\Delta t)}{\\Delta t}=-\\frac{dF(t)}{dt}\n$$\n\n使用Cox Proportional-hazards Model对早偿率进行建模：\n\n$$\n\\lambda(t ; \\underline{v}, \\underline{\\theta})=\\lambda_{0}(t ; \\gamma, p) \\exp (\\underline{\\beta} \\underline{v})\n$$\n其中基准风险函数 (base-line hazard function) $\\lambda_{0}(t ; \\gamma, p)$由对数逻辑斯谛函数(log-logistic hazard function)的形式给出\n\n$$\n\\lambda_{0}(t ; \\gamma, p)=\\frac{\\gamma p(\\gamma t)^{p-1}}{1+(\\gamma t)^{p}}\n$$\nBase-line hazard function衡量的是没有考虑其它解释变量时提前偿还的风险： $\\underline{v}=\\underline{0}$. Log-logistic hazard function考虑了早偿率和贷款年龄之间的关系。如果$p\u003e1$, 提前偿还的风险从0逐渐上升到最大值：\n$$\nt^{*}=(p-1)^{1 / p} / \\gamma\n$$\n\n$\\underline{v}$中还包括影响MBS价格的其他因素，包括借款人的还款激励、此前提前还款的情况、季节因素等。\n\n\n## 违约情况的分析\n\n### 影响违约率的因素\n\n**房价 (House Price Index, HPI)**\n**信用评分 (FICO)**\n**债务收入比 (Debt-to-Income Ratio, DTI)**\n**贷款价值比 (Loan-to-Value Ratio, LTV)**\n**贷款金额 (Loan Size) 及其对数**\n**贷款种类**\n	- 固定利率、浮动利率等\n**物业类型**\n	- 独栋、3-4人合并住宅等\n**占有人类型 (Occupancy Type)**\n	- 原所有人占有（owner-occupied）、第二住宅（second home）、非所有人占有（non-owner-occupied）等\n**借款目的 (Loan Purpose)**\n	- 购买住宅 (Purchase)\n	- 再融资 (Refinance)\n	- 将住宅再融资以取得现金 (Cashout)\n\n### 对违约过程建模\n\nMBS的违约过程是一个多状态的过程，可以看作一个连续时间的马尔科夫链：\n$$\nS=\\left[\\begin{array}{l}\nS_{1} \\\\\nS_{2} \\\\\nS_{3} \\\\\nS_{4} \\\\\nS_{5}\n\\end{array}\\right]=\\left[\\begin{array}{c}\n\\text { Current } \\\\\n60+\\text { Days Delinquent } \\\\\n\\text { In Foreclosure } \\\\\n\\text { REO } \\\\\n\\text { Liquidated }\n\\end{array}\\right]\n$$\n\n$$\nD(t)=\\left[\\begin{array}{ccccccc}\n-\\lambda_{1}(t) \u0026 \\lambda_{1}(t) \u0026 0 \u0026 0 \u0026 \\ldots \u0026 0 \u0026 0 \\\\\n0 \u0026 \\lambda_{2}(t) \u0026 -\\lambda_{2}(t) \u0026 0 \u0026 \\cdots \u0026 0 \u0026 0 \\\\\n\\vdots \u0026 \\vdots \u0026 \\vdots \u0026 \\vdots \u0026 \\vdots \u0026 \\vdots \u0026 \\vdots \\\\\n0 \u0026 0 \u0026 0 \u0026 0 \u0026 \\ldots \u0026 -\\lambda_{n-1}(t) \u0026 \\lambda_{n-1}(t) \\\\\n0 \u0026 0 \u0026 0 \u0026 0 \u0026 \\ldots \u0026 0 \u0026 0\n\\end{array}\\right]\n$$\n其中 $\\lambda_{j}(t)$ 是transitions $S_{j} \\rightarrow S_{j+1}$过程的风险函数。\n\n因此可以将MBS的违约步骤分拆成几个生存分析过程，然后再对每个过程进行建模。\n\n## 房价指数分析\n\n房屋价格水平会影响早偿率和违约率。如果房价下跌，借款人违约的可能性升高。对HPI/HPA的建模是一个比较复杂的过程，可以考虑将HPI看作一个随机过程：\n$$\nd HPI =a dt +\\sigma_w dz\n$$\n$\\sigma_w$是波动率，$a$是漂移，$z$是布朗运动。\n\nHPA（房价指数增长率）是HPI的年回报率。白噪声+扩散模型可以用来对HPA进行建模：有：\n$$\nHPA=\\frac{d HPI}{dt} = a+\\sigma_w w\n$$\n\n\n设$\\sigma_d$是HPA扩散的波动率，一阶扩散模型的理论统计量的函数是\n\n$$\n\\begin{gathered}\n\\operatorname{stdev}[H P A(t)]=\\left[\\sigma_{d}^{2} \\frac{1-e^{-2 a t}}{2 a}+\\sigma_{w}^{2}\\right]^{\\frac{1}{2}} \\\\\n\\operatorname{Corr}[\\operatorname{HPA}(T), H P A(t+T)] \\underset{T \\rightarrow \\infty}{\\rightarrow e^{-a t} \\frac{1}{1+2 a \\sigma_{w}^{2} / \\sigma_{d}^{2}}}\n\\end{gathered}\n$$\n\n\n## Reference\n\n[Andrew Lesniewski, Interest Rate and Credit Models: 13. Mortgage Backed Securities](https://mfe.baruch.cuny.edu/wp-content/uploads/2019/12/IRC_Lecture13_2019.pdf)\n\nSchwartz, E. S., and W. N. Torous, 1989, “Prepayment and the Valuation of Mortgage-Backed Securities,” Journal of Finance, 44, 375–392.\n\nDavidson, A., and Levin, A.: Mortgage Valuation Models: Embedded Options, Risk, and Uncertainty, Oxford University Press (2014).\n\nGlenn M. Schultz: Investing in Mortgage-Backed and Asset-Backed Securities, Wiley Finance, 2015\n\n[李力，雕刻现金流：从证券化到项目融资，中信出版集团股份有限公司，2017](https://weread.qq.com/web/reader/78c32f805e10dc78c9981c5kc81322c012c81e728d9d180)\n\n[林华，中国资产证券化产品投资手册，中信出版集团股份有限公司，2017](https://weread.qq.com/web/reader/cab3224071ae93c6cabb193kc81322c012c81e728d9d180)\n\n\n",title:"Untitled Page"},"/MOC":{content:"## Stats\n\n[[Probability and Random Process]]\n\n\n[[Statistics and Machine Learning]]\n\n[[Financial Time Series Analysis]]\n\n## Finance\n\n[[Options]]\n\n[[Futures]]\n\n[[Swap]]\n\n[[Rates]]\n\n[[MBS Modelling]]\n\n[[OAS]]\n\n[[MBS Duration]]\n\n[[TBA Market and Dollar Roll]]\n\n\n## Coding\n\n[[Data Preprocessing and EDA]]\n",title:"Untitled Page"},"/Multiple Linear Regression":{content:"---\nArea: Statistics\nSource: Book\nStatus: Todo\nType: Notes\n---\n\n\n# Multiple Linear Regression\n\nDesign Matrix $\\mathbf{X}$\n\n$$\\mathbf{X}=\\left[\\begin{array}{ccc}x_{10} \u0026 \\cdots \u0026 x_{1 p-1} \\\\x_{20} \u0026 \\cdots \u0026 x_{2 p-1} \\\\\\vdots \u0026 \\ddots \u0026 \\vdots \\\\x_{n0} \u0026 \\cdots \u0026 x_{n p-1}\\end{array}\\right]$$\n\nWe shall also let $\\mathbf{y}$ be the vector of observed values of $Y_1,...,Y_n$, $\\boldsymbol{\\beta}$ be the vector of parameters.\n\n$$\\mathbf{y}=\\left[\\begin{array}{c}y_{1} \\\\ \\vdots \\\\y_{n}\\end{array}\\right]$$\n\n$$\\boldsymbol{\\beta}=\\left[\\begin{array}{c}\\beta_{1} \\\\ \\vdots \\\\\\beta_{p-1}\\end{array}\\right]$$\n\n$$ \\mathbf{Y}_{n \\times 1}=\\mathbf{X}_{n \\times p} \\boldsymbol{\\beta}_{p \\times 1}+\\boldsymbol\\varepsilon_{n \\times 1}$$\n\n## M.L.E of Estimators\n\n$$\n\n\\widehat{\\boldsymbol{\\beta}}=\\left(\\mathbf{X}^{\\prime} \\mathbf{X}\\right)^{-1} \\mathbf{X}^{\\prime} \\mathbf{Y}\n$$\n\n\n\n\n\n\n\n## Mean Vector and Covariance Matrix\n\nThe coordinates $Y_1, . . . , Y_n$ of $\\mathbf{Y}$ are independent.\n\n$$\\mathbf{Y}=\\left[\\begin{array}{c}Y_{1} \\\\ \\vdots \\\\Y_{n}\\end{array}\\right]$$\n\n\n$$\n\n\\varepsilon_{i} \\sim N\\left(0, \\sigma_{i}^{2}\\right),\n\\quad E(\\varepsilon)=\\mathbf{0}\n$$\n\n$$\nE(\\mathbf{Y}) = \\mathbf{X} \\boldsymbol{\\beta}\n$$\n\n$$\n\\quad \\operatorname{Cov}(\\mathbf{Y})=\\operatorname{Cov}(\\varepsilon)=\\sigma^{2} \\mathbf{I}\n$$\n\n\n$$\n\\begin{aligned}\n\\operatorname{Cov}(\\hat{\\boldsymbol{\\beta}}) \u0026=\\left(\\mathbf{X}^{\\prime} \\mathbf{X}\\right)^{-1} \\mathbf{X}^{\\prime} \\operatorname{Cov}(\\boldsymbol{Y}) \\mathbf{X}\\left(\\mathbf{X}^{\\prime} \\mathbf{X}\\right)^{-1} \\\\\n\u0026=\\left(\\mathbf{X}^{\\prime} \\mathbf{Z}\\right)^{-1} \\mathbf{Z}^{\\prime}\\left(\\sigma^{2} \\boldsymbol{I}\\right) \\mathbf{X}\\left(\\mathbf{Z}^{\\prime} \\mathbf{Z}\\right)^{-1} \\\\\n\u0026=\\sigma^{2}\\left(\\mathbf{Z}^{\\prime} \\mathbf{Z}\\right)^{-1}\n\\end{aligned}\n$$\n\n## The Joint Distribution of the Estimators\n\nLet \n\n$$\n\\left( \\mathbf{X}^{\\prime} \\mathbf{X}\\right)^{-1}_{p\\times p}=\\left[\\begin{array}{ccc}\\xi_{00} \u0026 \\cdots \u0026 \\xi_{0 p-1} \\\\\\xi_{1 0} \u0026 \\cdots \u0026 \\xi_{1 p-1} \\\\\\vdots \u0026 \\ddots \u0026 \\vdots \\\\\\xi_{p-1 0} \u0026 \\cdots \u0026 \\xi_{p-1 p-1}\\end{array}\\right]\n\n$$\n\n$$\nE(\\widehat{\\boldsymbol{\\beta}})=\\left(\\mathbf{X}^{\\prime} \\mathbf{X}\\right)^{-1} \\mathbf{X}^{\\prime} E(\\mathbf{Y})=\\left(\\mathbf{X}^{\\prime} \\mathbf{X}\\right)^{-1} \\mathbf{X}^{\\prime} \\mathbf{X} \\boldsymbol{\\beta}=\\boldsymbol{\\beta}\n$$\n\n$$\n\n\\operatorname{Var}(\\widehat{\\boldsymbol{\\beta}})=\\sigma^{2}\\left(\\mathbf{X}^{\\prime} \\mathbf{X}\\right)^{-1}=\\sigma^{2}\\left(\\xi_{i j}\\right)_{i, j=0, \\cdots, k}\n$$\n\n$$\n\\boldsymbol{\\beta}\\sim N_{r}\\left(\\boldsymbol{\\beta},\\sigma^{2}\\left(\\mathbf{X}^{\\prime} \\mathbf{X}\\right)^{-1}\\right)\n$$\n\n\n\n$$\n{{\\sigma}^{\\prime}}^{2}=\\frac{\\widehat{\\varepsilon}^{\\prime} \\widehat{\\varepsilon}}{n-p},\\quad \\frac{(n-p){{\\sigma}^{\\prime}}^{2}}{\\sigma^2}\\sim\\chi^2(n-p) \n$$\n\n$$ \\frac{\\hat\\beta_j-\\beta_j^{\\star}}{\\sqrt{\\xi_{jj}}{{\\sigma}^{\\prime}}^{2}}\\sim t(n-p)\n$$\n\n\n\n## Prediction\n\n$$\n\\widehat{\\mathbf{Y}}=\\mathbf{x}^{\\prime}\\left(\\mathbf{X}^{\\prime} \\mathbf{X}\\right)^{-1} \\mathbf{X}^{\\prime} \\mathbf{Y}\n$$\n\n$$\n\\operatorname{Var}(\\hat{\\mathbf{Y}})=\\mathbf{x}^{\\prime}\\left(\\mathbf{X}^{\\prime}\\mathbf{X}\\right)^{-1}\\mathbf{x}\\sigma^2\n$$\n\n$$\n\\frac{Y-\\hat{Y}}{\\sigma^{\\prime}\\left[1+\\mathbf{x}^{\\prime}\\left(\\mathbf{X}^{\\prime}\\mathbf{X}\\right)^{-1}\\mathbf{x}\\right]^{1 / 2}}\\sim t(n-p)\n$$\n\n\n\n## Tests of Joint Hypotheses\n\nTest for an overall significant relationship between the response variable and all of the explanatory variables.\n\n### F Test\n\n$$F=\\frac{1}{2}\\left(\\frac{t_{1}^{2}+t_{2}^{2}-2 \\hat{\\rho}_{t_{1}, t_{2}} t_{1} t_{2}}{1-\\hat{\\rho}_{t_{1}, t_{2}}^{2}}\\right)$$\n\nThe homoskedasticity-only F-statistic\n\n$$F =\\frac{(SSR_{restricted} - SSR_{unrestricted})/q}{SSR_{unrestricted}/(n - k_{unrestricted} - 1)}$$\n\n$$F =\\frac{(R_{unrestricted}^2 - R_{restricted}^2)/q}{(1 - R_{unrestricted}^2)(n -k_{unrestricted} - 1)} $$\n\n## Multiple R Squared\n\nIn general, $R^2$ never decreases when a regressor is added to the model, regardless of the value of the contribution of that variable. Therefore, it is difficult to judge whether an increase in $R^2$ is really telling us anything important.\n\n$$R^{2}=1-\\frac{\\sum_{i=1}^{n}\\left(y_{i}-\\hat{y}_{i}\\right)^{2}}{\\sum_{i=1}^{n}\\left(y_{i}-\\bar{y}\\right)^{2}}$$\n\n$$R^2_{adj}=1-\\frac{\\hat\\sigma^2}{\\text {SST}/n-1}=1-\\frac{(1-R^2)(n-1)}{n-p}$$\n\n## Hidden Extrapolation\n\nData extrapolating beyond the region containing the original observations. \n\nIn multiple regression it is easy to inadvertently extrapolate, since the levels of the regressors jointly define the region containing the data.\n\nHat Matrix:\n$$\n\\mathbf{H}=\\mathbf{X}\\left(\\mathbf{X}\\right)^{-1} \\mathbf{X}^{\\prime}\n$$\n\nIf $h_{ii}\u003eh{max}$, then points are extrapolation points.\n\n## Multicollinearity\n\n$$\nVIF_j=\\frac{1}{1-R_j^2}\n$$\nwhere $R_j^2$ is the coefficient of multiple determination obtained from regressing $x_j$ on the other regressor variables. \n\nClearly, if $x_j$ is nearly linearly dependent on some of the other regressors, then $R_j^2$ will be near unity and $VIF_j$ will be large. \n\nVIFs larger than 10 imply serious problems with multicollinearity. \n\n",title:"Untitled Page"},"/OAS":{content:"---\nArea: Finance\nSource: Book\nStatus: Done\nType: Notes\n---\n\n## MBS的内嵌期权\n\n当贷款发放之后，借款人存在[[MBS Modelling#早偿情况的分析|提前偿还的权利]]，可以灵活地根据利率水平选择是否提前偿还。\n\n如果利率变低，借款人可以选择再融资，以更低的价格获得同样的贷款。拥有看涨期权 (call option) 意味着可以通过较低的价格来获得标的资产，所以抵押贷款的借款人相当于拥有一个看涨期权；类似地，MBS的投资者则相当于卖出一个看涨期权 (short a call option). 同样，借款人也有选择违约并将抵押物（住房）还给银行的权利，相当于拥有一个看跌期权（房价跌到比贷款的价值还低）；类似地，MBS的投资者则相当于卖出一个看跌期权 (short a put option). \n\n因此，MBS可以看做**内嵌期权**的固定收益产品，可以用**Option-Adjusted Spread**来衡量期权因素对价格的影响。\n\n## OAS的计算方法\n\nOAS是基于不同状态下的利率$r_{t}$使得MBS预期现金流的现值等于该MBS的市场价格所需收益率价差。可以按以下方法倒解出OAS：\n\n设$r_{t}, t=1, \\cdots, T$是利率曲线，给定$r_{j t}, t=1, \\cdots, T$是状态 $j=1, \\cdots, N$下的利率，每个状态下MBS的现金流可以由$C_{j t}, t=1, \\cdots, T$确定，OAS被定义为：\n$$\nV_{M B S}=\\sum_{j=1}^{N} p_{j}\\left[\\sum_{t=1}^{T} \\frac{C_{j t}}{\\left(1+r_{j 1}+O A S\\right) \\times \\cdots\\left(1+r_{j t}+O A S\\right)}\\right]\n$$\n其中 $p_{j}$ 是状态 $j$的概率。\n\n常见的利率模型有以下几种：\n\n**Vasicek Model**\n$$\ndR_t=a(b-R_t)dt+\\sigma dW_t\n$$\n**CIR Model**\n$$\ndR_t=a(b-R_t)dt+\\sigma \\sqrt R_t dW_t\n$$\n**Hull-White Model**\n$$\ndR_t=a(b_t-R_t)dt+\\sigma dW_t\n$$\n\n通过**蒙特卡洛**模拟不同的利率曲线随机变化的情况，可以计算出OAS.\n\n\n## OAS与Z-Spread\n\nZ-Spread是基于目前的即期利率曲线 (spot curve) 计算出的使现金流的现值等于市场价格的价差。\n\n$$\nP=\\sum_{t=1}^{T} \\frac{C_{t}}{\\left(1+r_{t}+Z\\right) ^t}\n$$\n\n其中$r_t$是目前$t$年期的即期利率。\n\n例如，某三年期债券目前的价格为104.90，coupon rate为5%，每年付息一次。相应的一年、两年和三年期零息国债利率（每半年复利一次）分别为2.5%、2.7%和3%。计算Z-Spread的方法为：\n\n$$\n104.9 = \\frac{5}{(1+\\frac{0.025+Z}{2})^2}+\\frac{5}{(1+\\frac{0.027+Z}{2})^4}+\\frac{105}{(1+\\frac{0.03+Z}{2})^6}\n$$\n\n\nZ-Spread和OAS的差值可以衡量投资者由于short an option导致的收益率变化：\n\n$$\nZ-Spread = OAS+Option\\ Cost\n$$\n\n例如，如果现在以下两个MBS的Z-Spread和OAS如下所示：\n\n| | MBS 4.00% | MBS 5.50%|\n|---|---|---|\n|Zero Volatility Spread |1.22% |2.09%|\n|Option-Adjusted Spread |0.49%| 0.19%|\n\n则MBS 4.00%的short option value为0.73%，MBS 5.50%的short option value为1.90%. OAS说明了投资者卖出期权的价值，在这个例子中MBS 5.50%的short option value更高，所以MBS 5.50%的YTM更高。\n\n与静态现金流分析相比，OAS可以更清晰地让投资者理解MBS的模型价格。通过选取不同的利率模型，投资者可以观察不同收益率曲线形状的影响，并对**未来的利率进行了模拟**，研究利率对MBS收益率的影响。但OAS分析受限于利率模型和提前还款模型的选取，不同的模型构建方法会影响OAS的分析结果。\n\n## Reference\n\nGlenn M. Schultz: Investing in Mortgage-Backed and Asset-Backed Securities, Wiley Finance, 2015",title:"Untitled Page"},"/Options":{content:"## Properties of Options\n\n### Factors affecting option prices\n![](Pasted%20image%2020220220232341.png)\n\n### Call-Put Parity\n\nPortfolio A : one European call option plus a zero-coupon bond that provides a payoff of $K$ at time $T$ Portfolio B : one European put option plus one share of the stock.\n\n$$c+Ke^{-rT}=p+S_0$$\n\n### American Options\n\n-   It is **never optimal to exercise an American call option** on a non-dividend-paying stock before the expiration date.\n-   A call option, when held instead of the stock itself, in effect insures the holder against the stock price falling below the strike price. Once the option has been exercised and the strike price has been exchanged for the stock price, this insurance vanishes.\n-   The time value of money. From the perspective of the option holder, the later the strike price is paid out the better.\n-   _What if the investor thinks the stock is currently overpriced and is wondering whether to exercise the option and sell the stock? In this case, the investor is better off selling the option than exercising it._\n\n$$C\\geq c\\geq S_0-Ke^{-rT}\u003eS_0-K$$\n\n-   It can be optimal to exercise an American put option on a non-dividend-paying stock early. Indeed, at any given time during its life, the put option should always be exercised early if it is sufficiently deep in the money.\n\n## Trading Strategies\n\n### Principal-protected notes\n\n-   A 3-year zero-coupon bond with a principal of $1,000\n-   A 3-year at-the-money European call option on the stock portfolio.\n\n### Option and Underlying Asset\n\n-   writing a covered call: the portfolio consists of **a long position in a stock** plus **a short position in a European call option.**\n-   protective put strategy: the investment strategy involves **buying a European put option** on a stock and **the stock itself.**\n\n### Bull Spreads\n\n-   **buying** a European **call** option on a stock with a certain strike price and **selling** a European **call** option on the same stock **with a higher strike price**. Both options have the same expiration date.\n-   The strategy can be described by saying that the investor has a call option with a strike price equal to $K_1$ and has chosen to give up some upside potential by selling a call option with strike price $K_2 (K2 \u003e K1)$.\n\n### Bear Spreads\n\n-   Bear spreads can be created by **buying** a European **put** with one strike price and **selling** a European **put** with another strike price. The strike price of the option purchased is greater than the strike price of the option sold.\n-   The investor has bought a put with a certain strike price and chosen to give up some of the profit potential by selling a put with a lower strike price\n\n### Box Spreads\n\n-   A box spread is a combination of a bull call spread with strike prices $K_1$ and $K_2$ and a bear put spread with the same two strike prices.\n-   The payoff from a box spread is always $K_2-K_1$. The value of a box spread is therefore always the present value of this payoff or $(K_2-K_1)e^{-rT}$ .\n\n### Butterfly Spreads\n\n-   A butterfly spread involves positions in options with three different strike prices.\n-   It can be created by\n    -   buying a European call option with a relatively low strike price $K_1$,\n    -   buying a European call option with a relatively high strike price $K_3$,\n    -   and selling two European call options with a strike price $K_2$ that is halfway between $K_1$ and $K_3$.\n-   Generally, $K_2$ is close to the current stock price.\n\n### Calendar Spreads\n\n-   A calendar spread can be created by **selling a European call option with a certain strike price** and **buying a longer-maturity Eurpean call option with the same strike price.**\n-   The longer the maturity of an option, the more expensive it usually is.\n\n### Straddle\n\n-   buying a European call and put with the same strike price and expiration date.\n\n### Strips\n\n-   A strip consists of a long position in **one European call and two European puts** with the same strike price and expiration date.\n-   In a strip the investor is betting that there will be a big stock price move and considers a decrease in the stock price to be more likely than an increase.\n\n### Straps\n\n-   A strap consists of a long position in **two European calls and one European put** with the same strike price and expiration date.\n-   In a strap the investor is also betting that there will be a big stock price move. However, in this case, an increase in the stock price is considered to be more likely than a decrease.\n\n### Strangles\n\n-   In a strangle, an investor **buys a European put and a European call with the same expiration date and different strike prices**.\n\n## Binomial Tree\n\n### Riskless\n\nWe imagine a portfolio consisting of a long position in $H$ shares and a short position in one option. At the beginning, the value is\n\n$$HS_0+C_0$$\n\nIf there is an up movement in the stock price, the value of the portfolio at the end of the life of the option is\n\n$$HS_u+C_u$$\n\nIf there is a down movement in the stock price, the value becomes\n\n$$HS_d+C_d$$\n\nRiskless:\n\n$$HS_u+C_u=HS_d+C_d=e^{r}(HS_0+C_0)$$\n\nCalculate $C_0$.\n\n### Replicate Portfolios\n\nWe imagine a portfolio consisting of a long position in $H$ shares and $B$ bonds.\n\n$$HS_u+e^{r}B=C_u,\\ HS_d+e^{r}B=C_d$$\n\n$$C_0=HS_0+B$$\n\n### Risk Neutral\n\nThe option pricing formula in equation does not involve the probabilities of the stock price moving up or down.\n\nThe probabilities of future up or down movements are already incorporated into the stock price: we do not need to take them into account again when valuing the option in terms of the stock price.\n\nA risk-neutral world has two features that simplify the pricing of derivatives:\n\n-   The expected return on a stock (or any other investment) is the risk-free rate.\n-   The discount rate used for the expected payoff on an option (or any other instrument) is the risk-free rate.\n\n$$S_0=e^{-r}[qS_u+(1-q)S_d]$$\n\nsolve $q$, and plug in:\n\n$$C_0=e^{-r}[qC_u+(1-q)C_d]$$\n\n### Derivation the BSM Formula from a Binomial Tree\n\n**See John Hull OFD C13 Appendix**\n\n## Continuous Time Finance\n\n### Brownian Motion\n\nA continuous stochastic process $W(t), t \\geq 0,$ is a Brownian motion if\n\n-   $W(0)=0$\n-   The increments of the process $W\\left(t_{1}\\right)-W(0), W\\left(t_{2}\\right)-W\\left(t_{1}\\right), \\cdots, W\\left(t_{n}\\right)-W\\left(t_{n-1}\\right),$$\\forall 0 \\leq t_{1} \\leq t_{2} \\leq \\cdots \\leq t_{n}$ are independent\n-   Each of these increments is normally distributed with distribution $W\\left(t_{i+1}\\right)-W\\left(t_{i}\\right) \\sim N\\left(0, t_{i+1}-t_{i}\\right)$\n\n### Ito Formula\n\n$$d f=\\left(\\frac{\\partial f}{\\partial t}+\\beta(t, X) \\frac{\\partial f}{\\partial x}+\\frac{1}{2} \\gamma^{2}(t, X) \\frac{\\partial^{2} f}{\\partial x^{2}}\\right) d t+\\gamma(t, X) \\frac{\\partial f}{\\partial x} d W(t)$$\n\nfrom Taylor's formula as quadratic variation = $dWdW=dt$\n\n### BSM Formula\n\nAssumptions\n\n1.  The stock price follows $dS_t=\\mu S_t dt+\\sigma S_t dW_t$ with $\\mu$ and $\\sigma$ constant.\n2.  The short selling of securities with full use of proceeds is permitted.\n3.  There are no transaction costs or taxes. All securities are perfectly divisible.\n4.  There are no dividends during the life of the derivative.\n5.  There are no riskless arbitrage opportunities.\n6.  Security trading is continuous.\n7.  The risk-free rate of interest is constant and the same for all maturities.\n\n#### Lognormal Property of Stock Prices\n\nStock Price\n\n$$dS_t=\\mu S_t dt+\\sigma S_t dW_t$$\n\nReturn\n\n$$dR_t=\\mu dt+\\sigma dW_t$$\n\n#### Reallocate the wealth\n\nA self-financing strategy to reallocate the wealth $X_t$:\n\n-   long or short $\\Delta_t$ shares of stocks;\n-   borrow or lend the $X_t-\\Delta_tS_t$ amount of money\n\n$$\\begin{aligned}dX_t\u0026=\\Delta_tdS_t+r(X_t-\\Delta_tS_t)dt\\\\\u0026=\\Delta_t[\\mu S_tdt+\\sigma S_tdW_t]+r(X_t-\\Delta_tS_t)dt\\\\\u0026=[rX_t+\\Delta_t(\\mu-r)S_t]dt+\\Delta_t\\sigma S_tdW_t\\end{aligned}$$\n\n#### Calculate call option's value\n\nSuppose that $c$ is the price of a call option on the stock. The variable $c$ must be some function of $S$ and $t$, i.e. $c(S_t,t)$. Hence, by using Ito formula,\n\n$$\\begin{aligned}\u0026 d c(t, S_t) \\\\=\u0026 c_{t}(t, S_t) d t+c_{x}(t, S_t) d S_t+\\frac{1}{2} c_{x x}(t, S_t) d[S, S](t) \\\\=\u0026\\left[c_{t}(t, S_t)+\\mu S(t) c_{x}(t, S_t)+\\frac{1}{2} \\sigma^{2} S^{2}_t c_{x x}(t, S_t)\\right] d t \\\\\u0026+\\sigma S_t c_{x}(t, S_t) d W_t\\end{aligned}$$\n\n#### $dX_t=dc(t,S_t)$\n\nWe have\n\n$$c_t(t,S_t)+rS_tc_x(t,S_t)+\\frac{1}{2}\\sigma^2S^2_tc_{xx}(t,S_t)-rc(t,S_t)=0$$\n\nthe terminal condition\n\n$$c(T,S_t)=(S_t-K)^{+}$$\n\n#### BSM Formulas\n\n$$\\begin{array}{c} c=S_{0} N\\left(d_{1}\\right)-K e^{-r T} N\\left(d_{2}\\right) \\\\ p=K e^{-r T} N\\left(-d_{2}\\right)-S_{0} N\\left(-d_{1}\\right) \\end{array}$$\n\n$$\\begin{array}{l} d_{1}=\\frac{\\ln \\left(S_{0} / K\\right)+\\left(r+\\sigma^{2} / 2\\right) T}{\\sigma \\sqrt{T}} \\\\ d_{2}=\\frac{\\ln \\left(S_{0} / K\\right)+\\left(r-\\sigma^{2} / 2\\right) T}{\\sigma \\sqrt{T}}=d_{1}-\\sigma \\sqrt{T} \\end{array}$$\n\nThe term $N(d_2)$ is the probability that a call option will be exercised in a risk-neutral world.\n\nThe expression $S_0N(d_1)e^{rT}$ is the expected stock price at time $T$ in a risk-neutral world when stock prices less than the strike price are counted as zero.\n\nSolve the PDE, or connect between stochastic processes and PDEs with **Feynman-Kac Theorem.**\n\n### Martingale Method\n\nLet\n\n$$d \\tilde{W}_{t}=\\frac{\\mu-r}{\\sigma} d t+d W_{t}$$\n\nWe have\n\n$$\\begin{aligned}d S_{t} \u0026=\\mu r S_{t} d t+\\sigma S_{t}\\left(d W_{t}^{Q}-\\frac{\\mu-r}{\\sigma} d t\\right) \\\\\u0026=r S_{t} d t+\\sigma S_{t} d W_{t}^{Q}\\end{aligned}$$\n\nUnder $Q$, we have the following martingales:\n\n-   the discounted underlying asset price $e^{-rt}S_t$\n-   the discounted replicating portfolio value $e^{-rt}X_t$\n-   the discounted option price $e^{-rt}V_t$\n\nThe Q-martingale property leads to\n\n$$\\begin{aligned}c(t,S_t)=V_{t} \u0026=e^{-r(T-t)} E^{Q}\\left[\\left(S_{T}-K\\right) \\cdot \\mathbf{1}_{\\left\\{S_{T} \\geq K\\right\\}} \\mid \\mathcal{F}_{t}\\right] \\\\\u0026=S_{t} Q\\left\\{x \\geq-d_{2}-\\sigma \\sqrt{T-t}\\right\\}-K e^{-r(T-t)} Q\\left\\{x \\geq-d_{2}\\right\\} \\\\\u0026=S_{t} N\\left(d_{1}\\right)-K e^{-r(T-t)} N\\left(d_{2}\\right)\\end{aligned}$$\n\n## Greeks\n\n$$\\text { Delta: } \\Delta=\\frac{\\partial f}{\\partial S} ; \\text { Gamma: } \\Gamma=\\frac{\\partial^{2} f}{\\partial S^{2}} ; \\text { Theta: } \\Theta=\\frac{\\partial f}{\\partial t} ; \\text { Vega: } v=\\frac{\\partial f}{\\partial \\sigma} ; \\text { Rho: } \\rho=\\frac{\\partial f}{\\partial r}$$\n\n### Naked and covered positions\n\n#### naked position\n\n-   One strategy open to the financial institution is to do nothing.\n\n#### covered position\n\n-   This involves buying 100,000 shares as soon as the option has been sold. If the option is exercised, this strategy works well, but in other circumstances it could lead to a significant loss.\n\n### A stop-loss strategy\n\n-   an institution that has written a call option with strike price $K$ to buy one unit of a stock. The hedging procedure involves buying one unit of the stock as soon as its price rises above $K$ and selling it as soon as its price falls below $K$.\n\nProblem\n\n-   The first is that the cash flows to the hedger occur at different times and must be discounted. The second is that purchases and sales cannot be made at exactly the same price K.\n\n### Delta hedging\n\n-   Delta is defined as the rate of change of the option price with respect to the price of the underlying asset.\n\n$$\\Delta(call)=N(d_1),\\ \\Delta(put)=N(d_1)-1$$\n\n#### Dynamic Aspects of Delta Hedging\n\n-   Derivatives dealers usually rebalance their positions once a day to maintain delta neutrality.\n\n### Theta\n\n-   The theta of a portfolio of options is the rate of change of the value of the portfolio with respect to the passage of time with all else remaining the same.\n-   **time decay**\n-   As time passes with all else remaining the same, the option tends to become less valuable.\n-   When the stock price is very low, theta is close to zero.\n-   For an at-the-money call option, theta is large and negative.\n\n### Gamma\n\nThe gamma of a portfolio of options on an underlying asset is the rate of change of the portfolio’s delta with respect to the price of the underlying asset.\n\n$$\\Delta \\Pi=\\Theta \\Delta t+\\frac{1}{2} \\Gamma \\Delta S^{2}$$\n\n#### Making a Portfolio Gamma Neutral\n\n-   Delta neutrality provides protection against relatively small stock price moves between rebalancing.\n-   Gamma neutrality provides protection against larger movements in this stock price between hedge rebalancing.\n\n$$w_{T}=-\\Gamma/\\Gamma_T$$\n\n### Relationship between Delta, Theta, and Gamma\n\n$$\\Theta+rS\\Delta+\\frac{1}{2}\\sigma^2 S^2\\Gamma=r\\Pi$$\n\n-   theta can to some extent be regarded as a proxy for gamma in a delta-neutral portfolio.\n\n### Vega\n\n-   the rate of change of the value of the portfolio with respect to the volatility of the underlying asset.\n-   If a hedger requires a portfolio to be both gamma and vega neutral, **at least two traded derivatives** dependent on the underlying asset must usually be used.\n-   When volatilities change, the implied volatilities of short-dated options tend to change by more than the implied volatilities of long-dated options. The vega of a portfolio is therefore often calculated by changing the volatilities of long-dated options by less than that of short-dated options.\n\n### Rho\n\n-   The rho of a portfolio of options is the rate of change of the value of the portfolio with respect to the interest rate.\n\n![https://s3-us-west-2.amazonaws.com/secure.notion-static.com/1c65c777-465e-42c5-9d70-53f782174b16/Untitled.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/1c65c777-465e-42c5-9d70-53f782174b16/Untitled.png)\n\n## Volatility Smile\n\n-   The volatility smile defines the relationship between the implied volatility of an option and its strike price.\n-   For equity options, the volatility smile tends to be downward sloping.\n    -   This means that **out of-the-money puts** and **in-the-money calls** tend to have high implied volatilities whereas **out-of-the-money calls** and **in-the-money puts** tend to have low implied volatilities.\n-   For foreign currency options, the volatility smile is U-shaped.\n    -   Both out-of-the-money and in-the-money options have higher implied volatilities than at-the-money options.\n-   A refinement of this is to calculate the volatility smile as the relationship between the implied volatility and $K/S_0$ or $K/F_0$, where $F_0$ is the forward price of the asset for a contract maturing at the same time as the options that are considered.\n-   Yet another approach to defining the volatility smile is as the relationship between the implied volatility and the delta of the option.\n\n## Exotic Options\n\n### Perpetual American Options\n\nA perpetual derivative has $T=\\infty$.\n\nRecall Black-Scholes equation:\n\n$$c_t(t,S_t)+rS_tc_x(t,S_t)+\\frac{1}{2}\\sigma^2S^2_tc_{xx}(t,S_t)-rc(t,S_t)=0$$\n\nThe term $c_t(t,S_t)$ disappears from the equation due to time-homogeneity, and we get an **ODE instead of a PDE.**\n\n### Bermudan Options\n\nEarly exercise may be restricted to **certain dates**.\n\n### Gap Options\n\nA gap call option is a European call options that pays off $S_T-K_1$ when $S_T \u003e K_2$.\n\nThe difference between a gap call option and a regular call option with a strike price of $K_2$ is that the payoff when $S_T \u003e K_2$ is increased by $K_2-K_1$.\n\n### Forward Start Options\n\nForward start options are options that will **start at some time in the future**. Sometimes employee stock options can be viewed as forward start options.\n\n### Compound Options\n\nCompound options are options on options. Compound options have two strike prices and two exercise dates.\n\nConsider, for example, a call on a call. On the first exercise date, $T_1$, the holder of the compound option is entitled to pay the first strike price, $K_1$, and receive a call option.\n\nThe call option gives the holder the right to buy the underlying asset for the second strike price, $K_2$, on the second exercise date, $T_2$. The compound option will be exercised on the first exercise date only if the value of the option on that date is greater than the first strike price.\n\n### Barrier Options\n\nBarrier options are options where the payoff depends on whether the underlying asset’s price reaches a certain level during a certain period of time.\n\nA **knock-out option** ceases to exist when the underlying asset price reaches a certain barrier; **a knock-in option** comes into existence only when the underlying asset price reaches a barrier.\n\n### Binary Options\n\nBinary options are options with discontinuous payoffs.\n\nA simple example of a binary option is a **cash-or-nothing call**. This pays off nothing if the asset price ends up below the strike price at time $T$ and pays a fixed amount, $Q$, if it ends up above the strike price.\n\n### Lookback Options\n\nThe payoffs from lookback options depend on the maximum or minimum asset price reached during the life of the option.\n\nThe payoff from a floating lookback call is the amount that the final asset price exceeds the minimum asset price achieved during the life of the option.\n\nThe payoff from a floating lookback put is the amount by which the maximum asset price achieved during the life of the option exceeds the final asset price.\n\n### Shout Options\n\nA shout option is a European option where the holder can ‘‘shout’’ to the writer at one time during its life.\n\nAt the end of the life of the option, the option holder receives **either the usual payoff from a European option or the intrinsic value at the time of the shout, whichever is greater**.\n\n### Asian Options\n\nAsian options are options where the payoff depends on the **arithmetic average** of the price of the underlying asset during the life of the option.\n\n### Exchange Options\n\nAn option to buy yen with Australian dollars is, from the point of view of a US investor, an option to exchange one foreign currency asset for another foreign currency asset.\n\nA stock tender offer is an option to exchange shares in one stock for shares in another stock.\n\n### Options Involving Several Options\n\nRainbow options. European basket option.\n\n### Volatility Swap\n\nA volatility swap is an agreement to exchange the realized volatility of an asset between time $0$ and time $T$ for a prespecifed fixed volatility.\n\n## Real Options\n\n### Extension of the Risk Neutral Valuation Method\n\nthe market price of risk for a variable $\\theta$ was defined as\n\n$$\\lambda=\\frac{\\mu-r}{\\sigma}$$\n\nwhere $r$ is the risk-free rate, $\\mu$ is the return on a traded security dependent only on $\\theta$, and $\\sigma$ is its volatility. Suppose that a real asset depends on several variables $\\theta_i$. Let $m_i$ and $s_i$ be the expected growth rate and volatility of $\\theta_i$\n\n$$d\\theta_i/\\theta=m_idt+s_idW_t$$\n\nwhere $W_t$ is a Brownian Motion.\n\nDefine $\\lambda_i$ as the market price of risk of $\\theta_i$. Risk-neutral valuation can be extended to show that any asset dependent on the i can be valued by\n\n-   Reducing the expected growth rate of each $\\theta_i$ from $m_i$ to $m_i-\\lambda_is_i$ (because $(m_i-r)/s_i=\\lambda_i$.)\n-   Discounting cash flows at the risk-free rate.\n\n### Estimating the Market Price of Risk\n\n$\\rho$: Instantaneous correlation between the percentage changes in the variable and returns on a broad index of stock market prices\n\n$\\mu_m$: Expected return on broad index of stock market prices\n\n$\\sigma_m$: Volatility of return on the broad index of stock market prices\n\nFrom a continuous-time version of the capital asset pricing model\n\n$$\\mu-r=\\frac{\\rho\\sigma}{\\sigma_m}(\\mu_m-r)$$\n\nAnother expression\n\n$$\\mu-r=\\lambda\\sigma$$\n\nThus\n\n$$\\lambda=\\frac{\\rho}{\\sigma_m}(\\mu_m-r)$$\n\n### Examples of Options Embedded in Projects\n\n-   **Abandonment options**: It is an American put option on the project’s value.\n-   **Expansion options**: It is an American call option on the value of additional capacity. The strike price of the call option is the cost of creating this additional capacity discounted to the time of option exercise.\n-   **Contraction options**: It is an American put option on the value of the lost capacity. The strike price is the present value of the future expenditures saved as seen at the time of exercise of the option.\n-   **Options to defer**: This is an American call option on the value of the project.\n-   **Options to extend life**: This is a European call option on the asset’s future value.\n\n## Reference\n\nOFD / John Hull\n\n《金融经济学二十五讲》/ 徐高\n\n《金融经济学十讲》/ 史树中\n\nFinancial Calculus: An Introduction to Derivative Pricing / Martin Baxter\n\n[布朗运动、伊藤引理、BS公式（前篇）](https://mp.weixin.qq.com/s?__biz=MzIyMDEwNDk1Mg==\u0026mid=2650876491\u0026idx=1\u0026sn=2ccfdfbaf250228974e984c5e7168366\u0026chksm=8c249bdcbb5312ca46b0261df16109ad8e19d559ab919dd95f8097b46b36eaf81e85b4eef76c\u0026scene=126\u0026sessionid=1605256784\u0026key=409586cdc8db5733d89744fef149cbd55e0825fce39bb62d733d518ddf15b3e1ecd31bb2ba4e18d5c4853db53d9fb1cba066bb33110f8740f658772187889b75c666cbb2a0fd6f016e9b0079f7403eadcb884f6a5bd1c6e957edbebba629f17c26a5c2f9489f0820c2cabc44aa656224da99bcf28ba4bf2f4170c17b3f255ca9\u0026ascene=1\u0026uin=MjU1NDk5MDUwOA%3D%3D\u0026devicetype=Windows+10+x64\u0026version=6300002f\u0026lang=zh_CN\u0026exportkey=A0Tn4xOWv3Nl%2BjMxJtPWumI%3D\u0026pass_ticket=ok4tnaFWS7zPPSCRKPSyUIzrRRcpn0LMaKl%2FkngUWsaWK0ChENo%2FKgwaJH5CCexq\u0026wx_header=0)\n\n[布朗运动、伊藤引理、BS公式（后篇）](https://mp.weixin.qq.com/s?__biz=MzIyMDEwNDk1Mg==\u0026mid=2650876561\u0026idx=1\u0026sn=ee4ecb91b0c95e7d539375ef35efdf4a\u0026chksm=8c249b06bb53121043a58a2163779774ef0f054659bee3033ff2cb3b7af7996bd75a3a862e31\u0026scene=126\u0026sessionid=1605256784\u0026key=cc7cc2a0b445493e06dbff52441567153cc0ac0f70486c51768cc951d0871d265c6e19ab75a980bbef7f1864f8f6bd16dcf347cfa2628abb7b13727fcbdf5188cc98f354b29144935c3aecd91ad2f0011ef56f23448f8df115987ca174fac91babc728e21455cb515b27820ee01203a772cb23c4a69a797b16820bb2213c58c5\u0026ascene=1\u0026uin=MjU1NDk5MDUwOA%3D%3D\u0026devicetype=Windows+10+x64\u0026version=6300002f\u0026lang=zh_CN\u0026exportkey=A7l3K9ytHaVtOJYXPnoJ8Sw%3D\u0026pass_ticket=ok4tnaFWS7zPPSCRKPSyUIzrRRcpn0LMaKl%2FkngUWsaWK0ChENo%2FKgwaJH5CCexq\u0026wx_header=0)\n\n[《期权交易随笔》题记](https://mp.weixin.qq.com/s?__biz=MzIyMTE5OTE5Mg==\u0026mid=409677815\u0026idx=2\u0026sn=491afd3a6f32dea8d3282ea1fb5aa02b\u0026chksm=0a5fe1c03d2868d60ed449598bbe5d72e6281f8a038a0e4a52876768d50edc248a8c49210cb1\u0026scene=126\u0026sessionid=1605759166\u0026key=e17ad8edb8d975168ae4132b815fac2689bbcfcb92f93d58076345765d5cd2a91167cdafb664797fcd8a9b664459656a6ac0dde4490e389de04932454612f3f59527447cbbe69dc1483225420a515553eb0e30f7b9fd915c34f1346e29564da1e2ef8a0053d40ee27f65c3c3c790be526070ec2cfbc98e942b7d9fca74a663fd\u0026ascene=1\u0026uin=MjU1NDk5MDUwOA%3D%3D\u0026devicetype=Windows+10+x64\u0026version=6300002f\u0026lang=zh_CN\u0026exportkey=A1eyaqvaIFoWdFTokV4gWNI%3D\u0026pass_ticket=6X9rN0ahWibDlXeT0QKsoq3d9UL3kop49HI7%2F%2Ba%2B30zMh6TprHofEq9FsxXicYqb\u0026wx_header=0)\n\n[BS公式--鞅定价推导法](https://zhuanlan.zhihu.com/p/95538708)\n\n[American Options](https://people.kth.se/~armerin/FinInsMathRwanda/Lecture18.pdf)",title:"Untitled Page"},"/PCA Analysis":{content:"https://zhuanlan.zhihu.com/p/37609917\nhttps://zhuanlan.zhihu.com/p/84946694\nhttps://janakiev.com/blog/covariance-matrix/\n",title:"Untitled Page"},"/Pasted image 20220220232341.png":{content:"",title:"Untitled Page"},"/Probability and Random Process":{content:"[probability_cheatsheet.pdf](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/646bd1d9-a58f-469a-b20b-fc2e2ff9efc9/probability_cheatsheet.pdf)\n\n## Counting\n\n### Sampling Table\n\nThe sampling table gives the number of possible samples of size $k$ out of a population of size $n$, under various assumptions about how the sample is collected\n\n$$ \\begin{array}{r|cc} \u0026 \\textbf{Order Matters} \u0026 \\textbf{Not Matter} \\\\ \\hline \\textbf{With Replacement} \u0026 \\displaystyle n^k \u0026 \\displaystyle{n+k-1 \\choose k} \\\\ \\textbf{Without Replacement} \u0026 \\displaystyle\\frac{n!}{(n - k)!} \u0026 \\displaystyle{n \\choose k} \\end{array}$$\n\n-   Experiments/Outcomes - An experiment generates an outcome from a pre-determined list. For example, a dice roll generates outcomes in the set $\\{1, 2, 3, 4, 5, 6\\}$\n-   Sample Space - The sample space, denoted $\\Omega$, is the set of possible outcomes. Note that the probability of this event is 1, since something in the sample space will always occur.\n-   Event - An event is a subset of the sample space, or a collection of possible outcomes of an experiment. We say that the event has occurred if any of the outcomes in the event have happened.\n\n## Conditional\n\n### Law of Total Probability (LOTP)\n\nLet ${ B}_1, { B}_2, { B}_3, ... { B}_n$ be a _partition_ of the sample space (i.e., they are disjoint and their union is the entire sample space).\n\n$$ \\begin{aligned} P({ A}) \u0026= P({ A} | { B}_1)P({ B}_1) + P({ A} | { B}_2)P({ B}_2) + \\dots + P({ A} | { B}_n)P({ B}_n)\\\\ P({ A}) \u0026= P({ A} \\cap { B}_1)+ P({ A} \\cap { B}_2)+ \\dots + P({ A} \\cap { B}_n) \\end{aligned} $$\n\n$$ \\begin{aligned} P({ A}| { C}) \u0026= P({ A} | { B}_1, { C})P({ B}_1 | { C}) + \\dots + P({ A} | { B}_n, { C})P({ B}_n | { C})\\\\ P({ A}| { C}) \u0026= P({ A} \\cap { B}_1 | { C})+ P({ A} \\cap { B}_2 | { C})+ \\dots + P({ A} \\cap { B}_n | { C})\\end{aligned} $$\n\nSpecial case of LOTP with ${ B}$ and ${ B^c}$ as partition:\n\n$$ \\begin{aligned} P({ A}) \u0026= P({ A} | { B})P({ B}) + P({ A} | { B^c})P({ B^c}) \\\\ P({ A}) \u0026= P({ A} \\cap { B})+ P({ A} \\cap { B^c}) \\\\ \\end{aligned} $$\n\n### Bayes' Rule\n\n$$ P({ A}|{ B}) = \\frac{P({ B}|{ A})P({ A})}{P({ B})}, P({ A}|{ B}, { C}) = \\frac{P({ B}|{ A}, { C})P({ A} | { C})}{P({ B} | { C})} $$\n\nWe can also write\n\n$$ P(A|B,C) = \\frac{P(A,B,C)}{P(B,C)} = \\frac{P(B,C|A)P(A)}{P(B,C)} $$\n\n**Odds Form of Bayes' Rule**\n\n$$ \\frac{P({ A}| { B})}{P({ A^c}| { B})} = \\frac{P({ B}|{ A})}{P({ B}| { A^c})}\\frac{P({ A})}{P({ A^c})}$$\n\nThe _posterior odds_ of $A$ are the _likelihood ratio_ times the _prior odds_.\n\n## Expected Value and Variance\n\nExpected Value\n\n$$E(X) = \\sum\\limits_{i}x_iP(X=x_i)$$\n\nFor any r.v.s $X$ and $Y$, and constants $a,b,c,$\n\n$$E(aX + bY + c) = aE(X) + bE(Y) + c$$\n\nSame distribution implies same mean - If $X$ and $Y$ have the same distribution, then $E(X)=E(Y)$ and, more generally,\n\n$$E(g(X)) = E(g(Y))$$\n\nConditional Expected Value is defined like expectation, only conditioned on any event $A$.\n\n$$ E(X | A) = \\sum\\limits_{x}xP(X=x | A)$$\n\nVariance and Standard Deviation\n\n$${Var}(X) = E \\left(X - E(X)\\right)^2 = E(X^2) - (E(X))^2$$\n\n## Continuous RVs\n\n### Continuous Random Variables (CRVs)\n\nA continuous random variable can take on any possible value within a certain interval (for example, [0, 1]), whereas a discrete random variable can only take on variables in a list of countable values.\n\nThe probability that a continuous random variable takes on any specific value is 0.\n\n$$F'(x) = f(x)$$\n\n$$E(X) = \\int^\\infty_{-\\infty}xf(x)dx $$\n\n### LOTUS\n\n-   The expected value of $X$ is defined this way:\n\n$$E(X) = \\sum_x xP(X=x) \\textnormal{ (for discrete $X$)}$$\n\n$$E(X) = \\int^\\infty_{-\\infty}xf(x)dx \\textnormal{ (for continuous $X$)}$$\n\n-   The Law of the Unconscious Statistician (LOTUS) states that you can find the expected value of a function of a random variable, $g(X)$, in a similar way, by replacing the $x$ in front of the PMF/PDF by $g(x)$ but still working with the PMF/PDF of $X$:\n\n$$ E(g(X)) = \\sum_x g(x)P(X=x) \\textnormal{ (for discrete $X$)} $$\n\n$$E(g(X)) = \\int^\\infty_{-\\infty}g(x)f(x)dx \\textnormal{ (for continuous $X$)}$$\n\n-   _What's a function of a random variable? A function of a random variable is also a random variable. For example, if $X$ is the number of bikes you see in an hour, then $g(X) = 2X$ is the number of bike wheels you see in that hour and $h(X) = {X \\choose 2} = \\frac{X(X-1)}{2}$ is the number of pairs of bikes such that you see both of those bikes in that hour._\n\n### Universality of Uniform (UoU)\n\nWhen you plug any CRV into its own CDF, you get a Uniform(0,1) random variable. When you plug a Uniform(0,1) r.v.~into an inverse CDF, you get an r.v.~with that CDF. For example, let's say that a random variable $X$ has CDF\n\n$$F(x) = 1 - e^{-x}, \\textrm{ for $x\u003e0$} $$\n\nBy UoU, if we plug $X$ into this function then we get a uniformly distributed random variable.\n\n$$F(X) = 1 - e^{-X} \\sim \\textrm{Unif}(0,1)$$\n\nSimilarly, if $U \\sim \\textrm{Unif}(0,1)$ then $F^{-1}(U)$ has CDF $F$. The key point is that for any continuous random variable, we can transform it into a Uniform random variable and back by using its CDF.\n\n## Moments\n\nMoments describe the shape of a distribution.\n\nLet $X$ have mean $\\mu$ and standard deviation $\\sigma$, and $Z=(X-\\mu)/\\sigma$ be the _standardized_ version of $X$. The $k$th moment of $X$ is $\\mu_k = E(X^k)$ and the $k$th standardized moment of $X$ is $m_k =E (Z^k)$.\n\nThe mean, variance, skewness, and kurtosis are important summaries of the shape of a distribution.\n\n### Moment Generating Functions\n\nFor any random variable $X$, the function\n\n$$ M_X(t) = E(e^{tX}) $$\n\nis the **moment generating function (MGF)** of $X$, if it exists for all $t$ in some open interval containing $0$.\n\nMGF of linear functions: If we have $Y = aX + b$, then\n\n$$M_Y(t) = E(e^{t(aX + b)}) = e^{bt}E(e^{(at)X}) = e^{bt}M_X(at)$$\n\nUniqueness: If it exists, the MGF uniquely determines the distribution. This means that for any two random variables $X$ and $Y$, they are distributed the same (their PMFs/PDFs are equal) if and only if their MGFs are equal.\n\nSumming Independent RVs by Multiplying MGFs: If $X$ and $Y$ are independent, then\n\n$$M_{X+Y}(t) = E(e^{t(X + Y)}) = E(e^{tX})E(e^{tY}) = M_X(t) \\cdot M_Y(t) $$\n\nThe MGF of the sum of two random variables is the product of the MGFs of those two random variables.\n\n## Joint PDFs and CDFs\n\n### Joint Distributions\n\nThe joint CDF of $X$ and $Y$\n\n$$F(x,y)=P(X \\leq x, Y \\leq y) $$\n\nIn the discrete case, $X$ and $Y$ have a **joint PMF**\n\n$$p_{X,Y}(x,y) = P(X=x,Y=y)$$\n\nIn the continuous case, they have a **joint PDF**\n\n$$f_{X,Y}(x,y) = \\frac{\\partial^2}{\\partial x \\partial y} F_{X,Y}(x,y).$$\n\nThe joint PMF/PDF must be nonnegative and sum/integrate to 1.\n\n### Conditional Distributions\n\nConditioning and Bayes' rule for discrete r.v.s\n\n$$ P(Y=y|X=x) = \\frac{P(X=x, Y=y)}{P(X=x)} = \\frac{P(X=x|Y=y)P(Y=y)}{P(X=x)}$$\n\nConditioning and Bayes' rule for continuous r.v.s\n\n$$f_{Y|X}(y|x) = \\frac{f_{X,Y}(x, y)}{f_X(x)} = \\frac{f_{X|Y}(x|y)f_Y(y)}{f_X(x)}$$\n\nHybrid Bayes' rule\n\n$$f_X(x|A) = \\frac{P(A | X = x)f_X(x)}{P(A)}$$\n\n### Marginal Distributions\n\nTo find the distribution of one (or more) random variables from a joint PMF/PDF, sum/integrate over the unwanted random variables.\n\nMarginal PMF from joint PMF\n\n$$P(X = x) = \\sum_y P(X=x, Y=y)$$\n\nMarginal PDF from joint PDF\n\n$$f_X(x) = \\int_{-\\infty}^\\infty f_{X, Y}(x, y) dy$$",title:"Untitled Page"},"/Published/MOC":{content:"Please see [[MOC]].",title:"Untitled Page"},"/Rates":{content:"---\nArea: Finance\nSource: Book\nStatus: Done\nType: Notes\n---\n\n## 利率的种类\n\n### 国债收益率\n\n### LIBOR\n\n-   银行之间短期无抵押拆借利率\n\n### 联邦基金利率\n\n-   隔夜拆借利率被称为联邦基金利率（federal funds rate）\n-   借入和借出资金交易往往通过经纪商达成，由经纪商达成交易的利率加权平均（权重与交易规模有关）被称为有效联邦基金利率（effective federal funds rate）\n\n### 再回购利率\n\n-   是有抵押借贷利率\n-   拥有证券的金融机构同意将证券出售给合约的另一方，并在将来以稍高价格将证券买回\n    -   隔夜回购（overnight repo）\n    -   期限回购（term repo）\n\n### 零息利率\n\n-   $n$年的零息利率是指在今天投入资金并连续保持n年后所得的收益率\n-   也叫$n$年期的即期利率（spot rate），或者$n$年期零息率（zero rate）\n\n### 天数计量\n\n天数计算定义了一段时间内利息累积的方式\n\n-   三种报价方式：\n    -   实际天数/实际天数（期限内）\n    -   30/360\n    -   实际天数/360\n-   “实际天数/实际天数（期限内）”惯例适用于美国长期国债；“30/360”惯例适用于美国的企业及市政债券；“实际天数/360”惯例适用于美国短期国债及其他货币市场产品。\n\n## 债券定价\n\n### 债券收益率(YTM)\n\n### 平价收益率\n\n-   平价收益率（par yield）是使债券价格等于面值的券息率（coupon rate）\n-   $d$为债券到期时收到1美元的贴现值，$A$为年金现金流的当前价值（年金：annuity，在每个券息日支付1美元），$m$是每年券息支付的次数：\n\n$$100=A\\frac{c}{m}+100d$$\n\n### 确定国库券零息利率\n\n-   票息剥离方法（bootstrap method）\n-   Zero curve不是一条水平线的原因在于市场预期现在和1年后的1年期即期利率不一样\n\n### 久期和修正久期\n\n（麦考利）久期\n\n$$D=\\sum_{i=1}^{n} t_{i}\\left[\\frac{c_{i} \\mathrm{e}^{-y t_{i}}}{B}\\right] $$\n\n**YTM以连续复利计时**，麦考利久期乘以到期收益率的变动为债券价格变动的百分比\n\n$$ \\begin{aligned} \\Delta B\u0026=-\\Delta y \\sum_{i=1}^{n} c_{i} t_{i} \\mathrm{e}^{-yt_i}\\\\ \\frac{\\Delta B}{B}\u0026=-D\\Delta y \\end{aligned}\n\n$$\n\n修正久期\n\n修正了连续复利情况下的上述推导。\n\n$y$为一年$m$次复利的情形：\n\n$$\\begin{aligned}{\\Delta B=-\\frac{B D \\Delta y}{1+y / m}} \\\\ {D^{*}=-\\frac{D}{1+y / m}}\\end{aligned} $$\n\n美元久期：修正久期和债券价格的乘积\n\n### 债券组合的久期\n\n-   债券组合的久期可以被定义为构成债券的组合中每一个债券的久期的加权平均，其权重与相应债券价格成正比。\n\n### 凸性\n\n$$C=\\frac{1}{B} \\frac{\\mathrm{d}^{2} B}{\\mathrm{d} y^{2}}=\\frac{\\sum_{i=1}^{n} c_{i} t_{i}^{2} \\mathrm{e}^{-y t}}{B}$$\n\n$$\\begin{aligned}\\Delta B=\\frac{\\mathrm{d} B}{\\mathrm{d} y} \\Delta y+\\frac{1}{2} \\frac{\\mathrm{d}^{2} B}{\\mathrm{d} y^{2}} \\Delta y^{2} \\\\\\frac{\\Delta B}{B}=-D \\Delta y+\\frac{1}{2} C(\\Delta y)^{2}\\end{aligned}$$\n\n## 远期利率\n\n$$R_F=\\frac{R_2T_2-R_1T_1}{T_2-T_1}=R_2+(R_2-R_1)\\frac{T_1}{T_2-T_1}$$\n\n-   如果零息利率曲线向上倾斜，则在$T_2$结束的时间段上的远期利率大于期限为$T_2$的零息利率。反之亦然。\n\n$$R_F=R+T\\frac{\\partial R}{\\partial T}=-\\frac{\\partial}{\\partial T}lnP(0,T)$$\n\n-   瞬时远期利率$R_F$\n-   $P(0,T)$为$T$时刻到期的零息债券价格：\n\n$$P(0,T)=e^{-RT}$$\n\n-   远期利率代表了市场对即期利率的预期，如果投资者的看法与其不同，可以做收益率赌博\n\n### 远期利率合约（FRA）\n\n-   远期利率合约（FRA）是一种场外交易，目的是锁定在将来一段时间借入或借出一定数量资金时的利率，常常设为LIBOR.\n-   名义贷款，但不交割本金，只交割协议利率和参考利率的利差\n-   目的：规避未来利率风险或利用未来利率波动进行投机\n-   如果合约中约定的固定利率大于对应于同一时段的LIBOR利率，借入方要支付借出方固定利率和LIBOR利率的差乘以面值。\n-   如果合约中约定的固定利率小于对应于同一时段的LIBOR利率，借出方要支付借入方固定利率和LIBOR利率的差乘以面值。\n\n定义\n\nFRA 6×9意味着6个月对9个月，即从交易日$T_0$起6个月末T_1为起息日，而交易日后的9个月末为到期日$T_2$，协议利率的期限为3个月期。 在$T_0$时刻X同意在$T_1$和$T_2$之间将资金借给公司Y。则递延期限：$T_1-T_0$，协议期限：$T_2-T_1$.\n\n交割额是$T_1$时刻双方资金的转移。\n\n$R_K$：FRA中的约定利率\n\n$R_F$：由今天$T_0$时刻计算的介于时间$T_1$和$T_2$之间的LIBOR利率\n\n$R_M$：在时间$T_1$观察到的$T_1$和$T_2$之间的真正LIBOR利率\n\n$L$：合约的本金\n\n交割额的计算：\n\n-   取基准日的参考利率与协议利率之差，乘以协议金额，乘以协议期限，得到名义贷款的利息差\n-   以\u003cu\u003e参考利率\u003c/u\u003e作为贴现率，对上一步计算得到的利息差进行贴现，计算出利息差在交割日的现值，即交割额\n\n则对X，$T_1$时刻的收益为： $$ \\frac{L(R_K-R_M)(T_2-T_1)}{1+R_M(T_2-T_1)} $$ 对Y，$T_1$时刻的收益为： $$ \\frac{L(R_M-R_K)(T_2-T_1)}{1+R_M(T_2-T_1)} $$\n\n\u003e 注意：名义贷款在期初交割而不是期末，所以要贴现回来。交割额的贴现不采用连续复利的假设。贴现的利率是参考利率：例如当天的LIBOR，而不是无风险利率\n\n### 定价\n\nFRA的定价是今天$T_0$时刻FRA的价值。\n\n今天我们不知道$T_1$时真正的LIBOR利率会是多少，但我们可以用远期利率公式计算出$R_F$：由今天$T_0$时刻计算的介于时间$T_1$和$T_2$之间的LIBOR利率。\n\n定价过程：\n\n-   用远期利率代替实际利率计算收益\n-   将收益用\u003cu\u003e无风险利率\u003c/u\u003e贴现\n\n$$ V_{FRA}=L(R_F-R_K)(T_2-T_1)e^{-r_{f,T_2}T_2} $$\n\n## 短期利率期货\n\n### 欧洲美元期货\n\n-   以债务工具为标的，管理利率风险\n-   以芝加哥商品交易所(CME)交易的欧洲美元期货为例介绍短期利率期货，标的资产是在将来某三个月里按欧洲美元利率借款100万美元上所付的利息\n-   （多头）买入一份期货合约相当于承诺在未来以约定的利率水平存入100万美元（贷款）\n    -   如果担心利率下降导致在三个月内存款所获得的利息减少，应该进入多头，因为利率下降意味着报价上升\n-   （空头）卖出一份合约则相当于在未来以约定的利率水平借入100万美元（借款）\n    -   如果担心利率上升导致在三个月内贷款需要付出的利率增加，应该进入空头，因为利率上升意味着报价下降\n-   对一个持有欧洲美元期货的人来说，**利率下降时对多头有利，利率上升时对空头有利**\n-   欧洲美元期货相当于试图将未来某3个月的利率提前锁定在某个值\n-   但对冲不总是完美的，因为期货的结算在合约到期日，而利率支付在3个月之后\n\n### 欧洲美元期货的报价\n\n-   在合约的最后一个结算日之前，按通常的方式每天以市值定价，100-$R$\n-   其中，$R$为3个月每季度复利的欧洲美元利率\n-   无论3个月的实际天数是多少，名义存款的期限都规定为1/4年。\n-   标的利率变动0.01%=期货报价变动1个基点=25美元的收益或亏损\n\n### 远期利率和期货利率\n\n-   欧洲美元期货和FRA都能暂时锁定一段时间的利率，因为每日结算和到期日结算的不同，导致期货利率和远期利率有所不同\n-   从每天结算变为只在期末结算会降低事先约定的未来某一段时间的利率\n-   远期利率=期货利率-$\\frac{1}{2}\\sigma^2T_1T_2$\n-   $T_1$是期货的期限，$T_2$是期货的到期时间，$\\sigma^2$是短期利率一年的标准差\n\n## 中长期国债期货\n\n### 美国国债期货\n\n-   从交割月份的第1天算起，任何期限介于15年与25年之间的债券均可以用于交割。\n-   将整个投资收益人为分为利息收入和资本利得\n    -   便于税收管理\n    -   便于财务核算\n\n### 报价\n\n-   超级国债和长期国债期货合约均是以美元和美元的1/32为单位报出的。\n\n### 困难\n\n-   空头没有办法买入某种特定的现货交割\n-   解决办法：指定一种虚拟国债：10年期美国国债期货\n\n### 转换因子\n\n-   每交割100美元面值的债券所收入的现金价格为\u003cu\u003e（最新的期货报价×转换因子）+累计利息\u003c/u\u003e（发票价）\n-   在假定所有期限的利率均为每年6%（按半年复利）的前提下，转换因子等于\u003cu\u003e按交割月份第1天的债券报价所对应1美元面值的债券价格。\u003c/u\u003e\n-   对于息票利率大于6%的可交割国债来说，在其他条件相同的情况下，期限越长，转换因子越大；反之亦然。\n\n\u003e 20年的债券，coupon rate为10%，半年付息。转换因子： $$ CF=\\sum_{i=1}^{40}\\frac{100\\times5\\%}{(1+0.03)^i}+\\frac{100}{(1+0.03)^{40}} $$\n\n### 最便宜可交割债券\n\n-   设计转换因子体系的目的是减少采用不同期限、不同息票利率的可交割国债进行交割的差异，降低交割品种选择权的价值\n    -   由于债券价值与收益率、期限的关系是非线性的，而转换因子体系是线性的，所以转换因子体系不能完全消除交割品种选择权的价值\n    -   考虑到期货运作机制的要求，交易所规定把交割国债品种的选择权赋予卖方\n-   空头方收到的现金量为：\u003cu\u003e（期货的最新报价×转换因子）+累计利息\u003c/u\u003e\n-   买入债券费用为：\u003cu\u003e债券报价+累计利息\u003c/u\u003e\n-   最便宜交割债券是使得：\u003cu\u003e债券报价-（期货的最新报价×转换因子）\u003c/u\u003e达到最小的债券。\n-   空头提供债券，多头提供钱。\n-   在市场上有一些因素决定了最便宜可交割债券。\n    -   当市场收益率大于6%时，转换因子系统倾向于息票率较\u003cu\u003e低\u003c/u\u003e同时期限较\u003cu\u003e长\u003c/u\u003e的债券。\n    -   当市场收益率小于6%时，系统倾向于息票率较\u003cu\u003e高\u003c/u\u003e同时期限较\u003cu\u003e短\u003c/u\u003e的债券。\n    -   当收益率曲线为上坡形时，系统倾向于交割期限较\u003cu\u003e长\u003c/u\u003e的债券。\n    -   当收益率曲线为下坡形时，系统倾向于交割期限较\u003cu\u003e短\u003c/u\u003e的债券。\n\n### 确定期货价格\n\n如果假定已知最便宜可交割债券及交割日期，长期国债期货等价于一个为持有人提供中间收入的证券上期货合约。 $$ F_0=(S_0-I)e^{rT} $$ $I$为期货期限内券息的贴现值，$S_0$要加上累计利息；计算出的$F_0$要减去从计算到交割这段时间的累积利息，然后要根据转换因子折回报价。\n\n\u003e 假定对于某一国债期货已知最便宜可交割的债券的息票利率为12%，转换因子为1.6。假定期货交割日期为270天以后。券息的支付为每半年一次。上一次券息支付为60天以前，下一次券息支付为122天以后，再下一次券息支付为305天以后。利率期限结构为水平，利率为年率10%（连续复利）。假定债券的当前报价为115美元。债券的现金价格等于报价加上从上一次付息至今的累计利息。债券现金价格为： $$ 115+\\frac{60}{60+122} \\times 6=116.978 $$ 在122天（0.3342年）后，债券持有者将收到6美元的利息。该利息的贴现值为： $$ 6e^{-0.1×0.3342}=5.803 $$ 期货合约将持续270天（0.7397年）。如果期货合约是关于券息率为12%的债券，期货的现金价格为： $$ （116.978-5.803)e^{0.1\\times 0.7397}=119.711 $$ 在债券交割时，会产生148天的累计利息。如果期货合约是有关于券息率为12%的债券，期货的报价为： $$ 119.711-6 \\times \\frac{148}{148+35}=114.859 $$ 由转换因子定义得出，1.60倍的标准债券等价于一个12%的债券。因此，期货的报价应为： $$ \\frac{114.859}{1.60}=71.79 $$\n\n## 久期套期保值\n\n### 对于资产及负债组合的对冲\n\n-   久期匹配不能使得证券组合免疫于收益率曲线的非平行移动（即其价格不受平行移动的影响），这是该对冲策略的不足之处。\n-   在实践中，短期利率的变化幅度较大，并且与长期利率没有完美的相关性，有时甚至短期利率及长期利率会朝两个相反的方向变动。\n\n### 采用期货来实现基于久期的对冲\n\n$V_F$：利率期货合约的价格\n\n$D_F$：期货标的资产在期货到期日的久期值\n\n$P$：被对冲的债券组合在对冲到期日的远期价格\n\n$D_F$：被对冲的证券组合在对冲到期日的久期 $$ N^*=\\frac{PD_P}{V_FD_F} $$\n\n-   当采用国债期货来进行对冲时，对于交割某个特定的债券，对冲者一定以$D_F$为假设前提。$D_F$h和最便宜交割债券的久期相等。这意味着对冲者在实施对冲时，必须估计哪一个债券可能是最便宜可交割债券。如果利率环境发生了变化，以至于其他债券变为了最便宜可交割债券，对冲者必须将对冲头寸进行调节，因此对冲效果也许比预期的要差。\n-   利用利率期货来进行对冲时，对冲者应注意利率与期货价格呈相反方向变动。当利率上升时，利率期货价格下降；当利率下降时，利率期货价格上升。因此，在利率下降时会承受损失的公司应进入期货的多头头寸。类似地，在利率上升时会承受损失的公司应进入期货的空头头寸。\n\n---\n\n## 常见问题\n\n### 给出两支不同期限和票息的债券，计算某一时期的spot rate\n\n### 给出两支债券，在无套利的情况下为第三支定价\n\n分别待定系数，列二元一次方程，使得每一期的现金流都相等\n\n### 计算某个债券的dirty price和clean price\n\ndirty price: 其实就是现金流折现时下面用的系数不再是$(1+r)^t$，而是$(1+r)^{t-d}$，$d$意味着过去了多久。\n\nclean price\n\n=dirty price-accured interest\n\n=dirty price-coupon×days since last payment date/days between coupon payments\n\n### 远期利率的计算\n\n### 计算某方在FRA中的收入\n\n注意折现时使用的是由今天计算的远期LIBOR利率而不是约定的利率\n\n### FRA的定价和计算\n\n先由zero curve计算market implied forward rate，再用面值乘以利率差乘以时间长度，再用结束时的无风险利率贴现\n\n### 寻找某个债券是CTD\n\n计算cost=债券报价-期货settlement×CF，最小的那个\n\n### 投资人担心利率未来上涨，应该进入期货的多头还是空头\n\n担心利率上涨，进入空头，因为利率上涨时对空头有利\n\n### 根据曲率调整公式计算远期利率和期货利率之间的关系\n\n注意要把从欧洲美元期货报价中看到的利率转换成连续复利\n\n具体而言，欧洲美元期货报价是94，意味着3个月复利的年化利率是6%（实际天数/360），每90天的利率是1.5%\n\n按照连续复利，有$e^{r\\times 90/365}=1+1.5\\%,r=6.038\\%$.\n\n然后再用公式减去0.5×标准差的平方×期限×（期限+0.25）\n\n---\n\n首先针对每种金融产品相关的数字，应该想明白**哪些是交易出来的，哪些是合约中人为设定的**。所谓交易出来，就是这个数字是（理论上）由市场的供需决定的，而不是人为决定的。然后，捋清事物发展的脉络。\n\n由相对价值的想法，我们从市场上已有的债券价格入手，通过票息剥离法画出了zero curve；然后用曲线来（试图）计算其他产品的价格。这条曲线说明市场上所有的交易者对利率水平有一个自己的预期，而这些预期通过债券（和其他产品）的价格反映出来。\n\n当我们得到zero curve之后，很容易想到如何衡量交易者对市场未来利率的预期，因此我们定义了远期利率。\n\n如果投资者自己的认知和市场上反映出来的认知不同，那么他就有很多获利的机会。比如通过远期利率合约，交易者可以锁定自己未来一段时间的利率。\n\n短期利率期货如欧洲美元期货也可以锁定未来的某三个月存款利率，甚至可以到未来十年以后的三个月。远期利率合约中的约定利率$R_K$和欧洲美元期货的报价，都相当于在一定程度上反映着不同投资者对未来的预期。\n\n由于我们被要求学会很多计算（理论）定价的方法，这很容易让人以为债券或者其他衍生品的价格都是严格算出来的。倒不如说是市场上的交易者通过买卖各种证券的方式，将自己的看法price in至金融产品中。\n\n最后但最重要的是，思考每种金融产品的出现可能的原因和解决的问题，并且在解决问题的同时，又生发出哪些值得注意的问题。这或许能更好记忆每个条件存在的意义。",title:"Untitled Page"},"/SVMs and Kernel Methods":{content:"Awkward issue with logistic regression is that it fails if the training data are linearly separable. What this means is that, in the feature space, one can separate the two classes by a linear boundary. In cases such as this, maximum likelihood fails and some parameters march off to infinity. \n\n## Optimal Separating Hyperplane\nFinding an **optimal separating hyperplane** was in fact the launching point for SVMs.\n\nWe define a two-class linear classifier via a function $f(x)=\\beta_0+x^{\\prime}\\beta$, with the convention that we classify a point $x_0$ as $+1$ if $f(x_0)\u003e0$, and as $-1$ if $f(x_0)\u003c0$(on the fence we flip a coin). Hence the classifier itself is $C(x)=sign[ f(x)]$ .\n\nThe decision boundary is the set $\\{x|f(x)=0\\}$.\n\nThe (signed) Euclidean distance from a point $x_0$ to the linear decision boundary defined by $f$ is given by \n$$\n\\frac{1}{||\\beta||_2}f(x_0)\n$$\n\nWith this in mind, for a separating hyperplane the quantity $\\frac{1}{||\\beta||_2}y_if(x_i)$is the distance of xi from the decision boundary. \nThis leads to an optimization problem for creating the optimal margin classifier:\n\n$$\\underset{\\beta_{0}, \\beta}{\\operatorname{maximize}} M, {\\operatorname{s.t.}} \\frac{1}{\\|\\beta\\|_{2}} y_{i}\\left(\\beta_{0}+x^{\\prime} \\beta\\right) \\geq M, i=1, \\ldots, n$$\n\n\n\nA rescaling argument reduces this to the simpler form\n$$\n\\begin{aligned}\n\u0026\\underset{\\beta_{0}, \\beta}{\\operatorname{minimize}}\\|\\beta\\|_{2} \\\\\n\u0026\\text { subject to } y_{i}\\left(\\beta_{0}+x^{\\prime} \\beta\\right) \\geq 1, i=1, \\ldots, n\n\\end{aligned}\n$$\n\nOne noteworthy property of the solution is that\n$$\n\\hat\\beta=\\sum_{i\\in S}\\hat\\alpha_i x_i\n$$\nwhere $S$ is the support set.\n\n\n## Soft-Margin Classifier\n\nThe generalization to a soft margin allows points to violate their margin. Each of the violators has a line segment connecting it to its margin, showing the extent of the violation. The soft-margin classifier solves \n\n$$\n\\begin{aligned}\n\u0026\\underset{\\beta_{0}, \\beta}{\\operatorname{minimize}}\\|\\beta\\|_{2} \\\\\n\u0026\\text { subject to } y_{i}\\left(\\beta_{0}+x^{\\prime} \\beta\\right) \\geq 1-\\epsilon_i, i=1, \\ldots, n\\\\\n\u0026\\epsilon_i\u003e0, \\sum_{i=1}^N \\epsilon_i\\leq B, i=1, \\ldots, n\n\\end{aligned}\n$$\n\nHere $B$ is the budget for the total amount of overlap.\n\n## SVM Criterion as Loss Plus Penalty\n\n## Kernel Trick\n\n## Reference\n\nEfron, B., \u0026 Hastie, T. (2016). _Computer Age Statistical Inference: Algorithms, Evidence, and Data Science_ (1st ed.). Cambridge University Press. [https://doi.org/10.1017/CBO9781316576533](https://doi.org/10.1017/CBO9781316576533)",title:"Untitled Page"},"/Simple Linear Regression":{content:"---\nArea: Statistics\nSource: Book\nStatus: Done\nType: Notes\n---\n\n\n# Simple Linear Regression Model\n\n$$E(Y |x) = \\beta_0 + \\beta_1x$$\n\n$$Y=\\beta_0+\\beta_1x+\\varepsilon,\\varepsilon\\sim N(0,\\sigma^2)$$\n\n## Least-Squares Estimation\n\nWe shall minimize $Q$ with respect to $\\beta_0$ and $\\beta_1$ by taking the partial derivatives and setting them to 0. We have\n\n$$\\frac{\\partial Q}{\\partial \\beta_{0}}=-2 \\sum_{i=1}^{n}\\left(y_{i}-\\beta_{0}-\\beta_{1} x_{i}\\right) =0 $$\n\n$$ \\frac{\\partial Q}{\\partial \\beta_{1}}=-2\\sum_{i=1}^{n}\\left(y_{i}-\\beta_{0}-\\beta_{1} x_{i}\\right) x_{i}=0$$\n\nNormal Equation\n\n$$\\begin{aligned}\\beta_{0} n+\\beta_{1} \\sum_{i=1}^{n} x_{i} \u0026=\\sum_{i=1}^{n} y_{i} \\\\\\beta_{0} \\sum_{i=1}^{n} x_{i}+\\beta_{1} \\sum_{i=1}^{n} x_{i}^{2} \u0026=\\sum_{i=1}^{n} x_{i} y_{i} .\\end{aligned}$$\n\n\n\n## Assumptions\n\n-   Normality. For $i = 1, . . . , n,$ the conditional distribution of $Y_i$ given the values $x_1, . . . , x_n$ is a normal distribution.\n\n-   Linear Mean. There are parameters $\\beta_0$ and $\\beta_1$ such that the conditional mean of $Y_i$ given the values $x_1, . . . , x_n$ has the form $\\beta_0 + \\beta_1x_i$ for $i = 1, . . . , n$.\n\n-   Common Variance. There is a parameter $\\sigma^2$ such that the conditional variance of $Y_i$ given the values $x_1, . . . , x_n$ is $\\sigma^2$ for $i = 1, . . . , n.$ This assumption is often called **homoscedasticity**. Random variables with different variances are called **heteroscedastic**.\n    -   The error term is homoskedastic if the variance of the conditional distribution of $\\varepsilon_i$ given $X_i$ is constant for $i = 1,\\cdots, n$ and in particular does not depend on $X_i$. Otherwise, the error term is heteroskedastic.\n-   Independence. The random variables $Y_1, . . . , Y_n$ are independent given the observed $x_1, . . . , x_n$.\n-   Predictor is known.\n\nWe can now find the M.L.E.\n\n## M.L.E. of Estimators\n\n$$\\hat{\\beta}_{1}=\\frac{\\sum_{i=1}^{n} x_{i} Y_{i}-n \\bar{x}_{n} \\bar{Y}_{n}}{\\sum_{i=1}^{n} x_{i}^{2}-n \\bar{x}_{n}^{2}}=\\frac{\\sum_{i=1}^{n}\\left(x_{i}-\\bar{x}_{n}\\right)\\left(Y_{i}-\\bar{Y}_{n}\\right)}{\\sum_{i=1}^{n}\\left(x_{i}-\\bar{x}_{n}\\right)^{2}}$$\n\n$$\n\n\\hat{\\beta}_{0}=\\bar{Y}_{n}-\\hat{\\beta}_{1} \\bar{x}_{n}$$\n\nThe M.L.E.’s of the regression coefficients $\\beta_0$ and $\\beta_1$ are precisely the same as the least-squares estimates.\n\n### The Distribution of the Least-Squares Estimators\n\nLet us introduce the symbol\n\n$$\n\ns_{x}=\\left(\\sum_{i=1}^{n}\\left(x_{i}-\\bar{x}\\right)^{2}\\right)^{1 / 2}$$\n\nThus\n\n$$\n\\operatorname{E}[\\hat\\beta_1]=\\beta_1,\\operatorname{E}[\\hat\\beta_0]=\\beta_0\n$$\n\n$$\n\\operatorname{Var}\\left(\\hat{\\beta}_{1}\\right)=\\frac{\\sum_{i=1}^{n}\\left(x_{i}-\\bar{x}\\right)^{2} \\operatorname{Var}\\left(Y_{i}\\right)}{s_{x}^{4}}=\\frac{\\sigma^{2}}{s_{x}^{2}}\n$$\n\n$$\n  \n\\begin{aligned} \\operatorname{Var}(\\hat{\\beta_{0}})\u0026=\\operatorname{Var}(\\bar{Y}-\\hat{\\beta_{1}} \\bar{x})\\\\\u0026=\\operatorname{Var}(\\bar{Y})+\\bar{x}^{2}-2 \\bar{x} \\operatorname{Cov}(\\bar{Y}, \\hat{\\beta_{1}})\\\\\u0026=\\frac{\\sigma^{2}}{n}+\\frac{\\sigma^{2}}{s_{x}^{2}} \\bar{{x}}^{2}-0 \\\\\u0026=\\left(\\frac{1}{n}+\\frac{\\bar{x}^{2}}{s_{x}^{2}}\\right) \\sigma^{2} \\end{aligned}\n$$\n\n\n$$\n\\begin{aligned} \\operatorname{Cov}(\\hat{\\beta_{0}},\\hat{\\beta_{1}})\u0026=\\operatorname{Cov}(\\bar{Y}-\\hat{\\beta_{1}} \\bar{x},\\hat{\\beta_{1}})\\\\\u0026=\\operatorname{Cov}(\\bar{Y}, \\hat{\\beta_{1}})-\\bar{x} \\operatorname{Cov}(\\hat{\\beta_{1}}, \\hat{\\beta_{1}})\\\\\u0026=-\\bar{x} \\operatorname{Var}(\\bar{\\beta_{1}}) \\\\\u0026=-\\frac{\\bar{x} \\sigma^{2}}{s_{x}^{2}}\\end{aligned}\n$$\n\nSo we can calculate the expectations and variances of the linear combinations of $\\beta_0$ and $\\beta_1$.\n\n### The Properties of the Least-Squares Estimators\n\nThe **sum of the residuals** in any regression model that contains an intercept  $\\beta_0$ is always zero.\n\nThe **sum of the observed values** $y_i$ equals the **sum of the fitted values** $\\hat y_i$. \n\nThe least-squares regression line always passes through the centroid of the data. \n\nThe **sum of the residuals weighted by the corresponding value of the regressor variable** always equals zero, that is,\n$$\n\\sum_i=1 ^n x_i\\left[y_i-(\\hat\\beta_0+\\hat\\beta_1x_i)\\right]=0\n$$\n\nThe sum of the residuals weighted by the corresponding fitted value always equals zero, that is, \n$$\n\\sum_i=1 ^n \\hat y_i\\left[y_i-(\\hat\\beta_0+\\hat\\beta_1x_i)\\right]=0\n$$\n\n\n## Prediction\n\n### M.S.E. of Prediction\n\n$$\n\\begin{aligned}E\\left[(\\hat{Y}-Y)^{2}\\right] \u0026=E\\left\\{[(\\hat{Y}-\\mu)-(Y-\\mu)]^{2}\\right\\} \\\\\u0026=\\operatorname{Var}(\\hat{Y})+\\operatorname{Var}(Y)-2 \\operatorname{Cov}(\\hat{Y}, Y)\\\\\u0026=\\operatorname{Var}(\\hat{Y})+\\operatorname{Var}(Y)\\\\\u0026=\\sigma^{2}\\left[1+\\frac{1}{n}+\\frac{(x-\\bar{x})^{2}}{s_{x}^{2}}\\right]\\end{aligned}\n$$\n\nThe random variables $\\hat Y$ and $Y$ are independent, because $\\hat Y$ is a function of the first $n$ pairs of observations and $Y$ is an independent observation. Therefore,$\\operatorname{Cov}(\\hat{Y}, Y)=0$.\n\nSince\n\n$$\n\\operatorname{Var}(\\hat{Y}) = \\operatorname{Var}(\\hat{\\beta_0}+\\hat{\\beta_1} x) = \\operatorname{Var}(\\hat\\beta_0) + x \\operatorname{Var}(\\hat\\beta_1) + 2x \\operatorname{Cov}(\\hat\\beta_0,\\hat\\beta_1)\n$$\n\nThus,\n$$\nE\\left[(\\hat{Y}-Y)^{2}\\right] =\\sigma^{2}\\left[1+\\frac{1}{n}+\\frac{(x-\\bar{x})^{2}}{s_{x}^{2}}\\right]\n$$\n\n\n\n\n\n## Statistical Inference in Simple Linear Regression\n\n### M.L.E. for $\\sigma^2$\n\n$$\n\\hat \\sigma^2=\\frac{1}{n}\\sum_{i=1}^n\\left[Y_i-(\\hat\\beta_0+\\hat\\beta_1x_i)\\right]^2\n$$\n\nThe distribution of $n\\hat\\sigma^2/\\sigma^2$ is the $\\chi^2$ distribution with $n-2$ degrees of freedom.\n\n### Unbiased Estimator of $\\sigma^2$\n\n$$ \n\\sigma^{\\prime}=\\left(\\frac{S^{2}}{n-2}\\right)^{1 / 2}, \\text{where}\\ \\ S^{2}=\\sum_{i=1}^{n}\\left(Y_{i}-\\hat{\\beta}_{0}-\\hat{\\beta}_{1} x_{i}\\right)^{2}\n$$\n\nNote that it is different from the M.L.E.\n\n### Linear Combination of $\\beta_0$ and $\\beta_1$\n\n$$\n\\left[\\frac{c_{0}^{2}}{n}+\\frac{\\left(c_{0} \\bar{x}-c_{1}\\right)^{2}}{s_{x}^{2}}\\right]^{-1 / 2} \\frac{c_{0} \\hat{\\beta}_{0}+c_{1} \\hat{\\beta}_{1}-\\left(c_{0} \\beta_{0}+c_{1} \\beta_{1}\\right)}{\\sigma^{\\prime}}\n$$\n\nhas the $t$ distribution with $n-2$ degrees of freedom under the assumptions of simple linear regression.\n\nWe can use this random variable to test hypotheses about or to construct confidence intervals.\n\nPlug $\\sigma^{\\prime}$ into $\\operatorname{Var}\\left(\\hat{\\beta}{1}\\right)=\\frac{\\sigma^{2}}{s_{x}^{2}}$ and get the equation.\n\n### Confidence Intervals\n\nThe open interval is a coefficient $1-\\alpha_0$ confidence interval for $c_0\\beta_0+c_1\\beta_1$.\n\n$$c_{0} \\hat{\\beta}_{0}+c_{1} \\hat{\\beta}_{1} \\pm \\sigma^{\\prime}\\left[\\frac{c_{0}^{2}}{n}+\\frac{\\left(c_{0} \\bar{x}-c_{1}\\right)^{2}}{s_{x}^{2}}\\right]^{1 / 2} T_{n-2}^{-1}\\left(1-\\frac{\\alpha_{0}}{2}\\right)$$\n\n### Prediction Interval\n\n$$\\hat{Y} \\pm T_{n-2}^{-1}\\left(1-\\frac{\\alpha_{0}}{2}\\right) \\sigma^{\\prime}\\left[1+\\frac{1}{n}+\\frac{(x-\\bar{x})^{2}}{s_{x}^{2}}\\right]^{1 / 2}$$\n\n### Coefficient of Determination\n\nSST: Total sum of squares\nSSE: Explained sum of squares / Regression sum of squares\nSSR: Residual sum of squares\n$$\n\\begin{array}{l}{\\mathrm{SST} \\equiv \\sum_{i=1}^{n}\\left(y_{i}-\\overline{y}\\right)^{2}} \\\\ {\\mathrm{SSE} \\equiv \\sum_{i=1}^{n}\\left(\\hat{y}_{i}-\\overline{y}\\right)^{2}} \\\\ {\\mathrm{SSR} \\equiv \\sum_{i=1}^{n} \\left(y_{i}-\\hat{y}_{i}\\right)^{2}}\\\\ \\mathrm{SST}=\\mathrm{SSE}+\\mathrm{SSR}\\end{array}\n$$\n\n\n$$R^2=1-\\frac{SSE}{SST}=1-\\frac{\\sum_{i=1}^{n}\\left(y_{i}-\\hat{y}_{i}\\right)^{2}}{\\sum\\left(y_{i}-\\bar{y}_{n}\\right)^{2}}$$",title:"Untitled Page"},"/Statistical Inference":{content:"## Estimation\n\n### Prior and Posterior Distributions\n\n-   Suppose that one has a statistical model with parameter $\\theta$. If one treats $\\theta$ as random, then the distribution that one assigns to $\\theta$ before observing the other random variables of interest is called its prior distribution.\n-   Consider a statistical inference problem with parameter $\\theta$ and random variables $X_1, . . . , X_n$ to be observed. The conditional distribution of $\\theta$ given $X_1, . . . , X_n$ is called the posterior distribution of $\\theta$.\n-   Suppose that the $n$ random variables $X_1, . . . , X_n$ form a random sample from a distribution for which the p.d.f. or the p.f. is $f (x|\\theta)$. Suppose also that the value of the parameter $\\theta$ is unknown and the prior p.d.f. or p.f. of $\\theta$ is $\\xi(\\theta)$. Then the posterior p.d.f. or p.f. of $\\theta$ is\n\n$$\\xi(\\theta \\mid \\boldsymbol{x})=\\frac{f\\left(x_{1} \\mid \\theta\\right) \\cdots f\\left(x_{n} \\mid \\theta\\right) \\xi(\\theta)}{g_{n}(\\boldsymbol{x})} \\quad \\text { for } \\theta \\in \\Omega$$\n\n-   where $g_n$ is the marginal joint p.d.f. or p.f. of $X_1, . . . , X_n$.\n\n$$g_{n}(\\boldsymbol{x})=\\int_{\\Omega} f_{n}(\\boldsymbol{x} \\mid \\theta) \\xi(\\theta) d \\theta$$\n\n### Conjugate Prior Distributions\n\n### Bayes Estimators\n\n-   A Bayes estimator is an estimator that is chosen to minimize the posterior mean of some measure of how far the estimator is from the parameter, such as squared error or absolute error.\n-   expected loss：\n\n$$E[L(\\theta, a) \\mid \\boldsymbol{x}]=\\int_{\\Omega} L(\\theta, a) \\xi(\\theta \\mid \\boldsymbol{x}) d \\theta$$\n\n-   For each possible value $x$ of $X$, let $\\delta^\\star(\\boldsymbol x)$ be a value of a such that $E[L(\\theta, a)|x]$ is minimized. Then $\\delta^\\star$ is called a Bayes estimator of $\\theta$.\n-   Suppose that the squared error loss function is used and that the posterior mean of $\\theta, E(\\theta \\mid \\boldsymbol{X}),$ is finite. Then, a Bayes estimator of $\\theta$ is $\\delta^{*}(\\boldsymbol{X})=E(\\theta \\mid \\boldsymbol{X})$.\n-   To apply the theory, it is necessary to specify a particular loss function, such as the squared error or absolute error function, and also a prior distribution for the parameter. Meaningful specifications may exist, in principle, but it may be very difficult and time-consuming to determine them.\n\n### Maximum Likelihood Estimators\n\n-   When the joint p.d.f. $f_n(\\boldsymbol{x}|\\theta)$ of the observations in a random sample is regarded as a function of $\\theta$ for given values of $x_1, . . . , x_n$, it is called the likelihood function.\n-   If we plug the observed values of the data into the conditional p.f. or p.d.f. of the data given the parameter, the result is a function of the parameter alone, which is called the likelihood function.\n-   Maximum Likelihood Estimator/Estimate. For each possible observed vector $\\boldsymbol{x},$ let $\\delta(\\boldsymbol{x}) \\in \\Omega$ denote a value of $\\theta \\in \\Omega$ for which the likelihood function $f_{n}(\\boldsymbol{x} \\mid \\theta)$ is a maximum, and let $\\hat{\\theta}=\\delta(\\boldsymbol{X})$ be the estimator of $\\theta$ defined in this way. The estimator $\\hat{\\theta}$ is called a maximum likelihood estimator of $\\theta .$ After $\\boldsymbol{X}=\\boldsymbol{x}$ is observed, the value $\\delta(\\boldsymbol{x})$ is called a maximum likelihood estimate of $\\theta$.\n\n#### Limitations of Maximum Likelihood Estimation\n\nNonexistence of an M.L.E.\n\n$$f(x \\mid \\theta)=\\left\\{\\begin{array}{ll}\\frac{1}{\\theta} \u0026 \\text { for } 0\u003cx\u003c\\theta \\\\0 \u0026 \\text { otherwise }\\end{array}\\right.$$\n\nNon-uniqueness of an M.L.E.\n\n$$f_{n}(\\boldsymbol{x} \\mid \\theta)=\\left\\{\\begin{array}{ll}1 \u0026 \\text { for } \\theta \\leq x_{i} \\leq \\theta+1,(i=1, \\ldots, n) \\\\0 \u0026 \\text { otherwise }\\end{array}\\right.$$\n\nThus, it is possible to select as an M.L.E. any value of $\\theta$ in the interval\n\n$$ \\max \\left\\{x_{1}, \\ldots, x_{n}\\right\\}-1 \\leq \\theta \\leq \\min \\left\\{x_{1}, \\ldots, x_{n}\\right\\} $$\n\nSampling from a Mixture of Two Distributions\n\n### Properties of Maximum Likelihood Estimators\n\n-   Invariance: Let $\\hat\\theta$ be an M.L.E. of $\\theta$, and let $g(\\theta)$ be a function of $\\theta$. Then an M.L.E. of $g(\\theta)$ is $g(\\hat\\theta)$.\n-   Consistency: the sequence of M.L.E.’s converges in probability to the unknown value of $\\theta$ as $n \\rightarrow \\infty$.\n\n## Sampling Distributions of Estimators\n\n### Joint Distribution of the Sample Mean and Sample Variance\n\n-   Let $X_{1}, \\ldots, X_{n}$ be a random sample from the normal distribution with mean $\\mu$ and variance $\\sigma^{2}$. Then the sample mean $\\hat{\\mu}=\\bar{X}{n}=\\frac{1}{n} \\sum{i=1}^{n} X_{i}$ and sample variance $\\widehat{\\sigma^{2}}=\\frac{1}{n} \\sum_{i=1}^{n}\\left(X_{i}-\\bar{X}_{n}\\right)^{2}$ are independent random variables. Furthermore, $\\hat{\\mu}$ has the normal distribution with mean $\\mu$ and variance $\\sigma^{2} / n,$ and $n \\widehat{\\sigma}^{2} / \\sigma^{2}$ has a chi-square distribution with $n-1$ degrees of freedom.\n\n### Confidence Intervals\n\n-   We can find an interval $(A, B)$ that we think has high probability of containing $θ$. The length of such an interval gives us an idea of how closely we can estimate $θ$.\n-   Let $X = (X_1, . . . , X_n)$ be a random sample from a distribution that depends on a parameter (or parameter vector) $\\theta$. Let $g(\\theta)$ be a real-valued function of $\\theta$. Let $A \\leq B$ be two statistics that have the property that for all values of $\\theta$,\n\n$$Pr(A \u003c g(\\theta) \u003c B) ≥ \\gamma$$\n\n-   Then the random interval $(A, B)$ is called a coefficient $\\gamma$ confidence interval for $g(θ)$.\n\n### Unbiased Estimators\n\n-   Let $\\delta$ be an estimator of a function $g$ of a parameter $\\theta$. We say that $\\delta$ is unbiased if $E_{\\theta}[\\delta(X)] = g(\\theta)$ for all values of $\\theta$.\n-   The quality of an unbiased estimator must be evaluated in terms of its variance or its M.S.E.\n-   Limitations:\n    -   Nonexistence of an Unbiased Estimator\n        -   suppose that $X_1, . . . , X_n$ form n Bernoulli trials for which the parameter $p$ is unknown. It can be shown that there will be no unbiased estimator of $p^{1/2}$.\n    -   Inappropriate Unbiased Estimators\n        -   Consider an infinite sequence of Bernoulli trials for which the parameter $p$ is unknown $(0 \u003c p \u003c 1)$, and let $X$ denote the number of failures that occur before the first success is obtained.\n\n## Testing Hypotheses\n\n### Problems of Testing Hypotheses\n\nConcepts:\n\n-   Because of focusing on type I error instead of type II error, we usually regard type I error as having more serious consequences than type II error.\n    \n-   Hence, in formulating null and alternative hypotheses, we use the more conservative hypothesis as the null hypothesis, and will only reject it when the data provide statistically significant evidence against it.\n    \n-   Type I \u0026 II Error\n    \n    $$\\begin{array}{r|cc} \u0026\\text{Actually $H_0$ is True}\u0026\\text{Actually $H_1$ is True}\\\\ \\hline\\text{Do not reject $H_0$}\u0026 \\text{Correct} \u0026\\text{Type II Error} \\\\ \\text{Reject $H_0$} \u0026 \\text{Type I Error} \u0026\\text{Correct} \\\\ \\end{array}$$\n    \n-   Size\n    \n    -   Loosely, the size $\\alpha(\\delta)$ of a given test $\\delta$ is the maximum probability of type I error.\n-   Level\n    \n    -   $\\delta$ is a level $\\alpha_0$ test if and only if $\\alpha(\\delta)\\leq\\alpha_0$.\n-   $p$-value\n    \n    -   A $p$-value is a probability that provides a measure of the evidence against the null hypothesis provided by the sample.\n    -   In general, the $p$-value is the smallest level $\\alpha_0$ such that we would reject the null hypothesis at level $\\alpha_0$ with the observed data.\n    -   For each $x$, let $\\delta_x$ be the test that rejects $H_0$ if $X\\geq x$. Then the $p$-value equals:\n    \n    $$ \\sup _{\\theta \\in \\Omega_{0}} \\pi\\left(\\theta | \\delta_{x}\\right)=\\sup _{\\theta \\in \\Omega_{0}} \\operatorname{Pr}(X \\geq x | \\theta)\n    \n    $$\n    \n-   Critical Value\n    \n    -   The critical values are the boundaries of the acceptance region of the test.\n    -   The critical value will be a quantile of a certain distribution.\n\n### The t Test\n\n### Comparing the Means of Two Normal Distributions\n\n### The F Distributions\n\n## Categorical Data and Nonparametric Methods\n\n### Tests of Goodness-of-Fit\n\n### Goodness-of-Fit for Composite Hypotheses\n\n### Contingency Tables\n\n### Tests of Homogeneity\n\n### Simpson’s Paradox\n\n## Four Steps to Hypothesis Testing\n\n### Compute the test statistic\n\n| Situation                                                | Null Hypothesis | Test Statistic                                               | Critical Region     |\n| :------------------------------------------------------- | --------------- | ------------------------------------------------------------ | --------------------------------- |\n| Mean of a Population (known $\\sigma$) | $\\mu=\\mu_0$ | $U=\\frac{\\bar x-\\mu_0}{\\sigma/\\sqrt{n}}$ | $\\{\\lvert U\\rvert\\geq U_{1-\\alpha/2}\\}$ |\n| Mean of a Population (unknown $\\sigma$) |      $\\mu=\\mu_0$            | $T=\\frac{\\bar x-\\mu_0}{s/\\sqrt{n}}$                          | $\\{\\lvert T\\rvert\\geq t_{1-\\alpha/2}(n-1)\\}$ |\n| Proportion of a Population | $p= p_0$ | $U=\\frac{\\hat{p}-p_{0}}{\\sqrt{\\frac{p_{0}\\left(1-p_{0}\\right)}{n}}}$ | $\\{\\lvert U\\rvert\\geq U_{1-\\alpha/2}\\}$ |\n| Means of Two Populations (known $\\sigma$) | $\\mu_1=\\mu_2$ | $U=\\frac{(\\bar x-\\bar{y})}{\\sqrt{\\frac{\\sigma_{1}^{2}}{m}+\\frac{\\sigma_{2}^{2}}{n}}}$ |   $\\{\\lvert U\\rvert\\geq U_{1-\\alpha/2}\\}$   |\n| Means of Two Populations (unknown $\\sigma$ and $\\sigma_1=\\sigma_2$ ) | $\\mu_1=\\mu_2$ | $T=\\frac{\\bar x-\\bar y}{s_p\\sqrt{\\frac{1}{m}+\\frac{1}{n}}},\\\\ s_{p}^{2}=\\frac{(m-1) s_{x}^{2}+(n-1) s_{y}^{2}}{m+n-2}$ | $\\{\\lvert T\\rvert\\geq t_{1-\\alpha/2(m+n-2)}\\}$ |\n| Means of Two Populations (unknown $\\sigma_1,\\sigma_2,\\sigma_1\\neq\\sigma_2$ and large sample) | $\\mu_1=\\mu_2$ | $U=\\frac{\\bar x-\\bar y}{\\sqrt{\\frac{s_x^2}{m}+\\frac{s_y^2}{n}}}$ | $\\{\\lvert U \\rvert\\geq U_{1-\\alpha/2}\\}$ |\n| Means of Two Populations (unknown $\\sigma_1,\\sigma_2,\\sigma_1\\neq\\sigma_2$ and small sample)[Do not need to know] | $\\mu_1=\\mu_2$ | $T=\\frac{\\bar x-\\bar y}{\\sqrt{\\frac{s_x^2}{m}+\\frac{s_y^2}{n}}}$ | $\\{\\lvert T\\rvert\\geq t_{1-\\alpha/2}(l-1)\\},\\\\l=\\frac{s^{4}}{\\frac{s_{x}^{4}}{m^{2}(m-1)}+\\frac{s_{y}^{4}}{n^{2}(n-1)}},s_{0}^{2}=\\frac{s_{x}^{2}}{m}+\\frac{s_{y}^{2}}{n}$ |\n| Proportion of Two Populations | $p_1=p_2$ | $U=\\frac{\\hat{p}_{1}-\\hat{p}_{2}}{\\sqrt{\\hat{p}(1-\\hat{p})\\left(\\frac{1}{n_{1}}+\\frac{1}{n_{2}}\\right)}}, \\hat{p}=\\frac{n_{1} \\hat{p}_{1}+n_{2} \\hat{p}_{2}}{n_{1}+n_{2}}$ | $\\{\\lvert U\\rvert\\geq U_{1-\\alpha/2}\\}$ |\n| Matched Pairs | $\\delta=\\mu_1-\\mu_2,\\delta=\\mu_0$ | $T=\\frac{\\delta-\\mu_0}{s_{\\delta}/\\sqrt{n}}$ | $\\{\\lvert T\\rvert \\geq t_{1-\\alpha/2}(n-1)\\}$ |\n| Variance of Two Populations | $\\sigma_1^2=\\sigma_2^2$ | $F=\\frac{s_x}{s_y}$ | $\\left\\{F \\leq F_{\\alpha/2}(m-1, n-1) \\text { or } F \\geq F_{1-\\alpha / 2}(m-1, n-1)\\right\\}$ |\n| Coefficient | $\\hat\\beta_j=\\beta_j^{\\star}$ | $T=\\frac{\\hat\\beta_j-\\beta_j^{\\star}}{SE(\\hat \\beta_j)}$ | $\\{\\lvert T\\rvert \\geq t_{1-\\alpha/2}(n-k-1)\\}$ |\n| Goodness of Fit (known $p_i$) | $P(A_i)=p_i$ | $Q=\\sum_{i=1}^{k} \\frac{\\left(N_{i}-n p_{i}\\right)^{2}}{n p_{i}}$ | $\\{Q\\geq \\chi^2_{1-\\alpha}(k-1)\\}$ |\n| Goodness of Fit (unknown $p_i$) | $P(A_i)=p_i$ | $Q=\\sum_{i=1}^{k} \\frac{\\left[N_{i}-n \\pi_{i}(\\hat{\\theta})\\right]^{2}}{n \\pi_{i}(\\hat{\\theta})}$ | $\\{Q\\geq \\chi^2_{1-\\alpha}(k-s-1)\\}$ |\n| Independence in Contingency Tables | $p_i, p_j\\ independent$ | $Q=\\sum_{i=1}^{R} \\sum_{j=1}^{c} \\frac{\\left(N_{i j}-\\hat{E}_{i j}\\right)^{2}}{\\hat{E}_{i j}}$ | $\\{Q\\geq \\chi^2_{1-\\alpha}((R-1)(C-1))\\}$ |\n\n**Note:** $\\bar x,\\bar y$ is the sample mean. $s,s_x,s_y$ is the standard deviation of sample. i.e. $s=\\sqrt{\\frac{\\sum\\left(X_{i}-\\bar{X}\\right)^{2}}{n-1}}$. ",title:"Untitled Page"},"/Statistics and Machine Learning":{content:"## Statistical Inference\n\n[[Statistical Inference]]\n\n## Regression\n\n[[Simple Linear Regression]]\n\n[[Multiple Linear Regression]]\n\n[[ANOVA]]\n\n\n\n## Classification\n\n[[Logistics Regression]]\n\n[[SVMs and Kernel Methods]]\n\n## Dimensionality Reduction\n\n[[PCA Analysis]]\n\n\n## Cluster\n\n## Survival Analysis\n[[Survival Analysis]]\n\n## Time Series\n\n[[Financial Time Series Analysis]]\n\n## Bagging and Boosting\n\n## Model Diagnostics and Feature Selection\n\n",title:"Untitled Page"},"/Survival Analysis":{content:"## Hazard Function\n$$\n\\lambda(t)=\\lim _{h \\rightarrow 0^{+}} \\frac{P(t \\leq T\u003ct+h \\mid T \\geq t)}{h}\n\n$$\n\n$$\n\\lambda(t)=\\frac{f(t)}{S(t)}=-\\frac{d}{dt}\\text{log}(S(t))\n$$\n\n$f(t)$ is the pdf of $T$, $F(t)$ is the cdf of $T$. $S(t)=1-F(t)$ is the survival function.\n\n## Kaplan-Meier Estimator\n\n$$\n\\hat\\lambda_j=\\frac{d_j}{n_j}\n$$\n\n$$\n\\hat S(t)=\\prod_{t_j\\leq t}(1-\\hat \\lambda_j)=\\prod_{t_j\\leq t}\\frac{n_j-d_j}{n_j}\n$$\n\n$$\nn_{j+1}=n_j-d_j-c_j\n$$\n\n## Log-Rank Test\n\n## Cox Proportional Hazard Model\n$$\n\\lambda_i(t)=\\lambda_0(t)\\text{exp}(x_i^T\\beta)\n$$\n[[MBS Modelling]]\n\n### Testing\nWald\n$$\n\\hat\\beta\\sim N(\\beta,(X^TWX)^{-1})\n$$\n\nLikelihood Ratio\n\n## Reference\n\n[生存分析科普](https://zhuanlan.zhihu.com/c_1189624821506506752)\n[Cox Regression Model vs Logistics Regression Model](http://courses.washington.edu/b513/Spring%202010/Discussion/Discussion10.pdf)\n\n\n\n",title:"Untitled Page"},"/Swap":{content:"## 利率互换\n\n- 互换利率是互换交易中的固定利率（息票利率）\n- 互换利差=互换利率-同期国债利率\n- 对于美国市场的标准互换合约，互换利率=（Bid+Offer）/2\n    - Bid: pay fixed receive LIBOR\n    - Ask: pay LIBOR receive fixed\n\n### 利用互换转变负债的性态\n\n- 利率互换可将其浮动利率贷款转换为固定利率贷款。\n    - 支付给外部贷款人的利率为LIBOR+0.1%\n    - 在互换合约中收入LIBOR\n    - 在互换合约中付出5%。\n- 利率互换可将其固定利率贷款转换为浮动利率贷款。\n    - 支付给外部贷款人的利率为5.2%\n    - 在互换合约中付出LIBOR\n    - 在互换合约中收入5%。\n\n### 利用互换转变资产的性态\n\n- 将收入为固定利率的资产转换为收入为浮动利率的资产\n\n- 将其浮动利率资产转换为固定利率资产\n\n### 做市商\n\n- 金融机构在进入利率互换的同时，不一定要进入与其他交易对手之间的互换交易。\n\n- 买入和卖出利率的平均值被称为互换利率。\n\n- 如果合约中的固定利率等于当前的互换利率，可以合理地假设这一互换的价值为0.\n\n$$B_{fix}=B_{float}$$\n\n### 确定LIBOR/互换零息利率\n\n- “连续更新”的LIBOR利率\n- 新发行的券息为LIBOR的浮动息债券价格将总会等于本金价格（平价）\n- 而对于一个**新成交**的互换交易，**当固定利率等于互换利率时**，固定利率的价格等于浮动利率的价格也就是**本金**，互换利率定义了一组平价债券\n- LIBOR和固定息互换利率定义了一系列平价债券\n- 用票息剥离法来确定并**延长**LIBOR/互换零息曲线\n\n$$\\begin{aligned}\n\n\u00260.5\\times swap\\ rate \\times e^{-LIBOR_{6m}\\times 0.5}\\\\\u0026+0.5\\times swap\\ rate \\times e^{-LIBOR_{12m}\\times 1}\\\\\u0026+0.5\\times swap\\ rate \\times e^{-LIBOR_{18m}\\times 1.5}\\\\\u0026+(100+0.5\\times swap\\ rate )\\times e^{-LIBOR_{24m}\\times 2}=100\n\n\\end{aligned}$$\n\n### OIS利率\n\n- 联邦基金利率（Fed funds rate）是美国金融机构之间的无抵押隔夜拆借利率，由经纪商所促成交易的加权平均利率为有效联邦基金利率（Effective federal funds rate）\n- OIS是将一段时间内的固定利率和隔夜利率的几何平均值进行交换的合约，其中的固定利率被称为隔夜指数互换利率（OIS rate）\n- OIS利率是对于无风险利率的一个好的近似估计\n\n### 确定OIS零息利率\n\n- 需要长期的OIS零息利率时，可以假设OIS利率和相应的LIBOR/互换利率的溢差在一定期限之外是一样的\n\n### 利率互换的定价\n\n横向分解\n\n- 浮动利率债券多头＋固定利率债券空头\n- 浮动利率债券空头＋固定利率债券多头\n- 浮动利率债券：相当于第一期初买一个平价债券，持有一期；在第二期期初收回本息，再买一个平价债券……一直到第n期\n- 在每一个付息日（在支付利息之后），浮动利率债券的价格等于面值\n- the value of the floating-rate bond today is $(L+k^{\\star})e^{-r^{\\star}t^{\\star}}$, where $r^{\\star}$ is the LIBOR/swap zero rate for a maturity of $t^{\\star}$.\n- 注意利息支付是否是复利的：一期本金+利息再折现\n\n纵向分解：看成是后付的FRA\n\n- 利率互换中的每一次支付交换就是一个远期利率合约\n- 定价过程：\n    - 计算用于决定互换现金流的LIBOR远期利率\n    - 假定LIBOR利率等于远期利率，并计算互换的现金流\n    - 用无风险利率对现金流进行贴现。\n- 注意要用利率期限结构估计出LIBOR的远期利率再代入FRA的计算中\n\n## 货币互换\n\n定义$V_{swap}$为收入美元并支付外币的货币互换的美元价值，那么：\n\n$$\nV_{swap}=B_D-S_0B_F$$\n\n其中$B_F$为互换中外汇现金流所对应的债券以外币计价的价值，$B_D$为互换中本国货币现金流所对应的债券以美元计价的价值，$S_0$为即期汇率（1单位外币所对应的美元数量）。\n\n\n## 信用风险\n\n- 在对手违约时，如果互换对于金融机构具有正价值，金融机构将蒙受损失；但如果互换对于金融机构具有负价值，则违约不会产生影响。\n\n- 市场风险来源于利率、汇率等市场变量，可以通过进入相互抵消的合约来进行对冲，但信用风险不能简单地对冲。\n\n## 其他互换\n\n- 本金数量在互换期限内可能有变化：amortizing swap, step-up swap\n- 在未来的某一时刻才开始利息交换：deferred swap, forward swap\n- 固定期限互换：LIBOR与某种互换利率交换\n- Diff互换/Quanto\n- 股权互换：某个股指的总收益与某固定或浮动利率互换\n- 可延期互换、可赎回互换\n- 商品互换、波动率互换\n",title:"Untitled Page"},"/TBA Market and Dollar Roll":{content:"---\nArea: Finance\nSource: Paper\nStatus: Done\nType: Notes\n---\n\n\n\n本文综述了Song and Zhu两位教授发表于RFS的文章“Mortgage Dollar Roll”，并辅以其他文献整理总结 Agency MBS、TBA 市场及 Dollar Roll 的融资机制。\n\n## 机构 MBS (Agency MBS)\n\nAgency MBS 是指由 Ginnie Mae (GNMA)、Fannie Mae (FNMA) 和 Freddie Mac (FHLM) 担保的抵押贷款支持证券 (MBS)，是美国固定收益市场的主要组成部分。其重要性主要体现在以下特点：\n\n- **规模大**：根据 SIFMA 的数据，截至 2017 年第二季度，机构抵押贷款支持证券（MBS）的流通量约为 9.2 万亿美元，仅次于美国国债市场的流通量 14.0 万亿美元。\n- **货币政策传导作用**：美联储自 2009 年以来进行了多轮量化宽松（QE），累计面值为 1.74 万亿美元。\n- **住房抵押贷款作用**：RMBS 满足了居民的购房需要，而机构 MBS 市场对抵押贷款市场的健康发展至关重要。\n\n## TBA市场 (To-be-announced market, TBA market)\n\nTBA 合约本质上是MBS的远期买卖合约。在 TBA 交易中，买卖双方只约定六个参数：发行人 (Agency)、到期日 (Maturity)、票息 (Coupon)、面值 (Par Amount)、价格 (Price)、结算日 (Settlement Date)。与其他远期合约不同，TBA 合约每月只有一个结算日，由 SIFMA 设定。\n\nTBA 交易的独特之处在于，在结算日交付的交易双方并未在交易日指定具体的需要买卖的 MBS CUSIP，而是仅指定几个关键的 MBS 特征。这种交易设计显著增加了可交付 MBS 的数量并提高了市场流动性。 \n\nTBA 市场可以为抵押贷款发起人提供风险对冲和融资作用。贷款机构通常会给予优质申请人30天到90天的利率锁定期，允许申请人在锁定期内决定是否按照特定的固定利率借入款项，这实质上相当于给予贷款申请人一个30天到90天的“固定利率期权”。贷款发起人将面临市场利率变动所引发的利率风险。通过TBA市场，抵押贷款发起人可以在发放贷款之前就锁定MBS的转售价格，比较直接地实现了对贷款利率风险的对冲目的。因此，即使是小规模贷款机构也可以发放贷款，使购房者获得更低廉的利率。\n\n## 美元滚动交易 (Dollar Roll)\n\n美元滚动交易由两笔 TBA 交易组成。卖家 (roll seller, MBS持有者，即融入资金方）出售一张MBS，承诺在近月 (front month) 交付这张券给对方，同时承诺在远月 (future month) 再把同类同面值的券买回来。这两个 MBS 不需要完全相同，只要它们具有相同的 TBA 特征即可。 \n\n\n美元滚动交易的“下跌” (dollar roll drop) 是近月和远月 TBA 合约之间的价差，一般来说是正的，原因有二。 \n\n- 由于没有规定两次交易时交付的券是一致的，所以在逆向选择的前提下，卖家在远月会收到较差的券，所以 MBS 的价值也较低。\n- 其次，卖家在近月卖出了这张 MBS 后，也放弃了这期间的本金和利息收入，所以会存在dollar roll drop.\n\n这两个特征将 dollar roll 与 MBS 回购交易区分开来。在 MBS 回购交易中，融出资金方必须归还相同的 MBS pool，并且原始所有者在回购期间会收取本金和利息。\n\n## 美元滚动交易的特殊性 (Dollar Roll Specialness)\n\n如果通过 dollar roll 融资时的隐含融资利率低于现行利率（例如 MBS 回购利率），就称这个 dollar roll 为“特殊 (on special)”。可以通过计算回购利率与隐含融资利率之间的差值衡量一个 dollar roll 的“特殊”程度 (specialness).\n\n- 因为不指定两次交易时需要同样的个券，所以当资金融入方回购 MBS 时，融出资金方可以选更便宜的券交付，通常更便宜的券对应更高的“提前偿付风险”。正的 specialness 是对卖方承担再交付风险的补偿。\n    \n- 持有稀缺的 MBS 可以在回购市场和证券借贷市场中融到更多的钱。如果不进入回购市场而是进行 dollar roll，卖方不仅放弃了利息和本金支付，而且放弃了与更便宜的融资利率和贷款费用。因此，dollar roll中的均衡隐含融资利率必然下降，从而导致更高的specialness. 特定类别 MBS 的稀缺性可能受到交易商和贷款发行人的做空和对冲以及新发行的 MBS 数量的推动。\n\n\n\n### Dollar Roll Specialness 的决定因素\n\n#### 再交付风险和逆向选择\n\n相对于回购融资，dollar roll 的一个关键特征是融出资金方（借出现金并接收 MBS）可以选择在滚动合约的远月交付基本相似但不同的 MBS. 所以由于逆向选择，buyer 会选择交付一个最差的 MBS. 因为 Agency MBS 不存在违约风险，所以更差的券一般意味着更大的提前偿还风险。所以可交付的 MBS 范围内，**提前偿还风险的分散度 (dispersion) 越大，specialness 越高。**\n\n\n除了类似于回购市场中供应量对融资利率的影响机制，dollar roll还有一个特殊之处：由于逆向选择的存在，市场参与人对于交付最差证券的行为具有充分的理性预期，**MBS 的流动将缩小到最便宜可交付券 (CTD, Cheapest-to-deliver)**。这进一步导致了可流动的 MBS 供应量的减少。**即使 MBS 总供应不变，更高的逆向选择可以缩小 MBS 的有效供应，使其 specialness 增加**。这种逆向选择和供应之间的内生反馈是 dollar roll 独有的。\n\n随着可交付 MBS 的分散度变大，卖家因为会想到买家一定会交付回更差的 MBS，所以一开始就不愿意在 dollar roll 中交易高质量的 MBS。所以高质量的 MBS 将在指定池市场 (specified pool market) 交易。因此，**提前偿还风险的分散度 (dispersion) 越大，specified pool market 交易应该越活跃**。 所以 **specialness 和 specified pool market 的交易量正相关**。\n\n#### MBS 所有权的交换 (Ownership Exchange)\n\n**杠杆率的影响：**\n\n- 基于 Dollar roll 的融资可以被看做表外业务，而通过回购融资更可能被看做表内业务。所以使用 dollar roll 融资（相对于回购）可以更节约表空间。所以 **specialness 与金融机构的杠杆负相关**。\n  \n**提前偿付风险的转移：**\n\n- 在融资期间，dollar roll 中MBS的利息和本金偿还均直接给到资金融出方，而回购中，抵押品的一切利息和本金收益均由资金融入方获得。因此，买方承担提前还款风险。如果持有的是 premium MBS，提前还款会造成损失，如果持有的是 discount MBS，提前还款会带来收益。所以如果提前还款风险比预期更高，则买方如果收到了 premium MBS，则期待更高的融资利率；如果收到了 discount MBS，则会期待更低的融资利率。**Specialness 正向（负向）依赖于premium（discount）MBS 抵押品在融资期间的提前还款速度**。\n\n\n### Dollar Roll Specialness 与 MBS 回报之间的关系\n\n**Dollar roll specialness 与预期 MBS 回报呈负相关。**\n\nMBS 回报率越高，dollar roll 相对于 MBS 回购放弃掉的回报率就越大，市场参与者会更青睐回购，回购利率上升，specialness 下降。Specialness 较高的 MBS 为其持有者在融资市场上提供了“便利收益 (convenience yield)”，所以这些持有者愿意接受较低的预期回报。\n\n\n## 实证研究\n\n### 再交付风险\n\n作者建立了如下的模型进行面板数据回归：\n\n$$\nSpecialness_{i t}=\\sum_{t} \\alpha_{t} D_{t}+\\sum_{i} \\gamma_{i} D_{i}+\\beta Disp_{it}^{CPR}+\\varepsilon_{i t}\n$$\n\n\n$Specialness_{it}$: dollar roll specialness, dollar roll financing rates 和一个月的 MBS 回购利率的差值。\n\n$D_{t}, D_{i}$分别是息票利率和时间的哑变量。\n\n$Disp_{it}^{CPR}$: 用提前偿还率的分散度作为 value dispersion 的代理变量。剔除至少具有以下特征之一的 MBS CUSIP：剩余本金余额低于 150,000 美元，再融资份额大于 75%，平均 LTV 比率高于 85%，平均 FICO 分数低于 680。这些特征使提前还款的可能性降低，因此不太可能成为 CTD. 基于可能交易的 MBS 的 SMM数据，根据SMM计算CPR，再计算CPR的范围，即相同息票$i$和时间$t$下，各个CUSIP的CPR从高到低排序，计算最高CPR与最低CPR的差。\n\n结论是$Disp_{it}^{CPR}$增加 1个标准差，dollar roll specialness 将提高约 41 个bp. \n\n另一种衡量 value dispersion 的方法是利用 specified pool 数据，计算$Payup_{it}$和$Trade^{SP}$. Specified pool 指定了可交割的 MBS，不存在再交付风险，因此对寻求融资优质MBS的市场参与者更具吸引力。因此$Payup_{it}$定义为 SP 和 TBA 的价格差异，也是 value dispersion 的代表。计算方法为相同息票$i$和时间$t$下按交易量加权平均的 SP 和 TBA 的价格差。$Trade^{SP}$是相同息票$i$和时间$t$下 SP 的交易量。回归后结论都是和 specialness 呈正相关。\n\n$$\nSpecialness_{i t}=\\sum_{t} \\alpha_{t} D_{t}+\\sum_{i} \\gamma_{i} D_{i}+\\beta Payup_{it}+\\varepsilon_{i t}\n$$\n\n$$\nSpecialness_{i t}=\\sum_{t} \\alpha_{t} D_{t}+\\sum_{i} \\gamma_{i} D_{i}+\\beta Trade_{it}^{SP}+\\varepsilon_{i t}\n$$\n\n\n\n\n\n### 所有权交换\n\n作者建立了以下模型研究杠杆率对 specialness 的影响：\n\n$$\nSpecialness_{it}=\\sum_{i} \\gamma_{i} D_{i}+\\beta Leverage_{t-1}+\\varepsilon_{i t}\n$$\n\n$Leveraget_{t-1}$: 上一期 primary dealer 的 asset/equity ratio 的平方和，用以衡量是否有出表的需求，越大说明资产比例越高，越不需要出表。\n\n结论是$Leverage$增加 1个标准差，dollar roll specialness 将降低约 11 个bp. \n\n作者定义$CPR^{Signed,Change}$为：如果是 premium MBS则是$\\Delta CPR$，如果是 discount MBS则是$-\\Delta CPR$，以便进行回归分析。作者建立下面的模型来观察提前偿还风险的变化（超出预期）是否会对买家对 MBS 的优劣产生影响进而对 specialness 有影响。\n\n$$\nSpecialness_{it}=\\sum_{i} \\gamma_{i} D_{i}+\\beta CPR^{Signed,Change}+\\varepsilon_{i t}\n$$\n\n结论是$CPR^{Signed,Change}$增加 1个标准差，dollar roll specialness 将降低约 21 个bp. \n\n\n### Dollar Roll Specialness 和 MBS 回报率\n\n作者建立了如下的模型进行面板数据回归：\n\n$$\nOAS_{i t}=\\sum_{t} \\alpha_{t} D_{t}+\\sum_{i} \\gamma_{i} D_{i}+\\beta Specialness_{i t}+\\varepsilon_{i t}\n$$\n\n$$\nRet_{i t}=\\sum_{t} \\alpha_{t} D_{t}+\\sum_{i} \\gamma_{i} D_{i}+\\beta Specialness_{i t}+\\varepsilon_{i t}\n$$\n\n其中 [[OAS]] 是基于利率 $r_{t}$ 上使得 MBS 预期现金流的现值等于该 MBS 的市场价格所需收益率价差。可以按以下方法倒解出 OAS：\n\n设$r_{t}, t=1, \\cdots, T$是利率曲线，给定$r_{j t}, t=1, \\cdots, T$是状态 $j=1, \\cdots, N$下的利率，每个状态下 MBS 的现金流可以$C_{j t}, t=1, \\cdots, T$确定，OAS被定义为：\n$$\nV_{M B S}=\\sum_{j=1}^{N} p_{j}\\left[\\sum_{t=1}^{T} \\frac{C_{j t}}{\\left(1+r_{j 1}+O A S\\right) \\times \\cdots\\left(1+r_{j t}+O A S\\right)}\\right]\n$$\n其中 $p_{j}$ 是状态 $j$的概率。\n\nRet是FNMA 30YR TBA 合约的月度回报率。可以避免使用OAS带来的内生性问题。\n\n**结论是 dollar roll specialness 和 MBS 回报率负相关。**\n\n\n\n\n## 美联储在量化宽松期间使用 dollar roll\n\n\n美联储在金融危机之中采用了量化宽松政策，大量购买了 Agency MBS 和 Treasury，以达成维持就业水平与稳定物价的双重目标。**这将推升近月合约的价格，造成 drop 数值高于合理值，借压低长期利率，支持抵押贷款市场，让资金状况更为宽松。**\n\n金融机构因此担忧大量的 MBS 购买是否会造成 MBS 的市场扭曲，新发行 MBS 的速度是否能美联储购买的速度。\n\n\n美联储可以通过 dollar roll 把交割日移到下个月, 等于推迟了 MBS 交割。为了研究美联储的 dollar roll sale 是否意在对市场 specialness 的关注，是否减轻了 MBS 市场的资金扭曲，作者比较了 specialness 在美联储 dollar roll sale 之后的变化。\n\n$$\n\\Delta Specialness_{it}=\\sum_{t}\\alpha_t D_t+ \\beta_1 d^{Roll}_{it}+ \\epsilon_{it}\n$$\n\n$d_{Roll}$是哑变量，判断美联储是否实行了 dollar roll sales. \n\n$\\beta_1$的估计结果为负值，意味着在美联储 dollar roll sales后，specialness 会下降。\n\n## 结论\n\nDollar roll 可以看做以 MBS 为抵押品的融资，但在以下方面又与 MBS 回购不同。\n  \n- 再交付风险：资金融出者可以选择在贷款到期时归还不同的 MBS 抵押品。\n\n- 所有权交换：MBS 的所有权在融资期间有所转移。\n  \n因此造成了通过 dollar roll 融资的成本比回购更低，也即 dollar roll specialness.\n\n美联储可以通过 dollar roll sale 推迟交割，缓解由量化宽松购买 MBS 造成的供应短缺。\n\n\n## Reference\n\nSong, Z., \u0026 Zhu, H. (2019). Mortgage Dollar Roll. _The Review of Financial Studies_, _32_(8), 2955–2996. [https://doi.org/10.1093/rfs/hhy117](https://doi.org/10.1093/rfs/hhy117)\n\n[美元滚动策略即dollar roll是什么，能直白的解释下吗？ - 知乎](https://www.zhihu.com/question/67960832/answer/2331550109)\n\n\n[李力，雕刻现金流：从证券化到项目融资，中信出版集团股份有限公司，2017](https://weread.qq.com/web/reader/78c32f805e10dc78c9981c5kc81322c012c81e728d9d180)\n\n[林华，中国资产证券化产品投资手册，中信出版集团股份有限公司，2017](https://weread.qq.com/web/reader/cab3224071ae93c6cabb193kc81322c012c81e728d9d180)\n\n",title:"Untitled Page"},"/templates/post":{content:'---\ntitle: "{{title}}"\n---\n',title:"{{title}}"}};for(const[a,b]of Object.entries(scrapedContent))contentIndex.add(a,b.content);const stopwords=['i','me','my','myself','we','our','ours','ourselves','you','your','yours','yourself','yourselves','he','him','his','himself','she','her','hers','herself','it','its','itself','they','them','their','theirs','themselves','what','which','who','whom','this','that','these','those','am','is','are','was','were','be','been','being','have','has','had','having','do','does','did','doing','a','an','the','and','but','if','or','because','as','until','while','of','at','by','for','with','about','against','between','into','through','during','before','after','above','below','to','from','up','down','in','out','on','off','over','under','again','further','then','once','here','there','when','where','why','how','all','any','both','each','few','more','most','other','some','such','no','nor','not','only','own','same','so','than','too','very','s','t','can','will','just','don','should','now'],highlight=(i,j)=>{const a=15,k=j.split(/\s+/).filter(a=>a!==""),b=i.split(/\s+/).filter(a=>a!==""),f=a=>k.some(b=>a.toLowerCase().includes(b.toLowerCase())),d=b.map(f);let e=0,g=0;for(let b=0;b<Math.max(d.length-a,0);b++){const f=d.slice(b,b+a),c=f.reduce((a,b)=>a+b,0);c>e&&(e=c,g=b)}const c=Math.max(g-a,0),h=Math.min(c+2*a,b.length),l=b.slice(c,h).map(a=>{return f(a)?`<span class="search-highlight">${a}</span>`:a}).join(" ").replaceAll('</span> <span class="search-highlight">'," ");return`${c===0?"":"..."}${l}${h===b.length?"":"..."}`},resultToHTML=({url:b,title:c,content:d,term:a})=>{const e=d.split("---")[2],f=removeMarkdown(e),g=highlight(c,a),h=highlight(f,a);return`<div class="result-card" id="${b}">
        <h3>${g}</h3>
        <p>${h}</p>
    </div>`},source=document.getElementById('search-bar'),results=document.getElementById("results-container");source.addEventListener('input',b=>{const a=b.target.value;contentIndex.search(a,{limit:5,depth:3,suggest:!0}).then(c=>{const d=[...new Set(c)],b=d.map(a=>({url:a,title:scrapedContent[a].title,content:scrapedContent[a].content}));if(b.length===0)results.innerHTML=`<div class="result-card">
            <p>No results.</p>
        </div>`;else{results.innerHTML=b.map(b=>resultToHTML({...b,term:a})).join("\n");const c=document.getElementsByClassName("result-card");[...c].forEach(b=>{b.onclick=()=>{window.location.href=`${b.id}#:~:text=${encodeURIComponent(a)}`}})}})});const searchContainer=document.getElementById("search-container");function openSearch(){searchContainer.style.display==="none"||searchContainer.style.display===""?(source.value="",results.innerHTML="",searchContainer.style.display="block",source.focus()):searchContainer.style.display="none"}function closeSearch(){searchContainer.style.display="none"}document.addEventListener('keydown',a=>{a.key==="/"&&(a.preventDefault(),openSearch()),a.key==="Escape"&&(a.preventDefault(),closeSearch())}),window.addEventListener('DOMContentLoaded',()=>{const a=document.getElementById("search-icon");a.addEventListener('click',a=>{openSearch()}),a.addEventListener('keydown',a=>{openSearch()})})</script><div class=singlePage><header><svg tabindex="0" id="search-icon" aria-labelledby="title desc" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 19.9 19.7"><title id="title">Search Icon</title><desc id="desc">Icon to open search</desc><g class="search-path" fill="none"><path stroke-linecap="square" d="M18.5 18.3l-5.4-5.4"/><circle cx="8" cy="8" r="7"/></g></svg><div class=spacer></div><div class=darkmode><input class=toggle id=darkmode-toggle type=checkbox tabindex=-1>
<label id=toggle-label-light for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="dayIcon" viewBox="0 0 35 35" style="enable-background:new 0 0 35 35"><title>Light Mode</title><path d="M6 17.5C6 16.672 5.328 16 4.5 16h-3C.672 16 0 16.672.0 17.5S.672 19 1.5 19h3C5.328 19 6 18.328 6 17.5zM7.5 26c-.414.0-.789.168-1.061.439l-2 2C4.168 28.711 4 29.086 4 29.5 4 30.328 4.671 31 5.5 31c.414.0.789-.168 1.06-.44l2-2C8.832 28.289 9 27.914 9 27.5 9 26.672 8.329 26 7.5 26zm10-20C18.329 6 19 5.328 19 4.5v-3C19 .672 18.329.0 17.5.0S16 .672 16 1.5v3C16 5.328 16.671 6 17.5 6zm10 3c.414.0.789-.168 1.06-.439l2-2C30.832 6.289 31 5.914 31 5.5 31 4.672 30.329 4 29.5 4c-.414.0-.789.168-1.061.44l-2 2C26.168 6.711 26 7.086 26 7.5 26 8.328 26.671 9 27.5 9zM6.439 8.561C6.711 8.832 7.086 9 7.5 9 8.328 9 9 8.328 9 7.5c0-.414-.168-.789-.439-1.061l-2-2C6.289 4.168 5.914 4 5.5 4 4.672 4 4 4.672 4 5.5c0 .414.168.789.439 1.06l2 2.001zM33.5 16h-3c-.828.0-1.5.672-1.5 1.5s.672 1.5 1.5 1.5h3c.828.0 1.5-.672 1.5-1.5S34.328 16 33.5 16zM28.561 26.439C28.289 26.168 27.914 26 27.5 26c-.828.0-1.5.672-1.5 1.5.0.414.168.789.439 1.06l2 2C28.711 30.832 29.086 31 29.5 31c.828.0 1.5-.672 1.5-1.5.0-.414-.168-.789-.439-1.061l-2-2zM17.5 29c-.829.0-1.5.672-1.5 1.5v3c0 .828.671 1.5 1.5 1.5s1.5-.672 1.5-1.5v-3C19 29.672 18.329 29 17.5 29zm0-22C11.71 7 7 11.71 7 17.5S11.71 28 17.5 28 28 23.29 28 17.5 23.29 7 17.5 7zm0 18c-4.136.0-7.5-3.364-7.5-7.5s3.364-7.5 7.5-7.5 7.5 3.364 7.5 7.5S21.636 25 17.5 25z"/></svg></label><label id=toggle-label-dark for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="nightIcon" viewBox="0 0 100 100" style="enable-background='new 0 0 100 100'"><title>Dark Mode</title><path d="M96.76 66.458c-.853-.852-2.15-1.064-3.23-.534-6.063 2.991-12.858 4.571-19.655 4.571C62.022 70.495 50.88 65.88 42.5 57.5 29.043 44.043 25.658 23.536 34.076 6.47c.532-1.08.318-2.379-.534-3.23-.851-.852-2.15-1.064-3.23-.534-4.918 2.427-9.375 5.619-13.246 9.491-9.447 9.447-14.65 22.008-14.65 35.369.0 13.36 5.203 25.921 14.65 35.368s22.008 14.65 35.368 14.65c13.361.0 25.921-5.203 35.369-14.65 3.872-3.871 7.064-8.328 9.491-13.246C97.826 68.608 97.611 67.309 96.76 66.458z"/></svg></label></div></header><article><aside class=mainTOC><h3>Table of Contents</h3><nav id=TableOfContents><ol><li><a href=#mle-of-estimators>M.L.E of Estimators</a></li><li><a href=#mean-vector-and-covariance-matrix>Mean Vector and Covariance Matrix</a></li><li><a href=#the-joint-distribution-of-the-estimators>The Joint Distribution of the Estimators</a></li><li><a href=#prediction>Prediction</a></li><li><a href=#tests-of-joint-hypotheses>Tests of Joint Hypotheses</a><ol><li><a href=#f-test>F Test</a></li></ol></li><li><a href=#multiple-r-squared>Multiple R Squared</a></li><li><a href=#hidden-extrapolation>Hidden Extrapolation</a></li><li><a href=#multicollinearity>Multicollinearity</a></li></ol></nav></aside><h1 id=multiple-linear-regression>Multiple Linear Regression</h1><p>Design Matrix $\mathbf{X}$</p><p>$$\mathbf{X}=\left[\begin{array}{ccc}x_{10} & \cdots & x_{1 p-1} \x_{20} & \cdots & x_{2 p-1} \\vdots & \ddots & \vdots \x_{n0} & \cdots & x_{n p-1}\end{array}\right]$$</p><p>We shall also let $\mathbf{y}$ be the vector of observed values of $Y_1,&mldr;,Y_n$, $\boldsymbol{\beta}$ be the vector of parameters.</p><p>$$\mathbf{y}=\left[\begin{array}{c}y_{1} \ \vdots \y_{n}\end{array}\right]$$</p><p>$$\boldsymbol{\beta}=\left[\begin{array}{c}\beta_{1} \ \vdots \\beta_{p-1}\end{array}\right]$$</p><p>$$ \mathbf{Y}<em>{n \times 1}=\mathbf{X}</em>{n \times p} \boldsymbol{\beta}<em>{p \times 1}+\boldsymbol\varepsilon</em>{n \times 1}$$</p><h2 id=mle-of-estimators>M.L.E of Estimators</h2><p>$$</p><p>\widehat{\boldsymbol{\beta}}=\left(\mathbf{X}^{\prime} \mathbf{X}\right)^{-1} \mathbf{X}^{\prime} \mathbf{Y}
$$</p><h2 id=mean-vector-and-covariance-matrix>Mean Vector and Covariance Matrix</h2><p>The coordinates $Y_1, . . . , Y_n$ of $\mathbf{Y}$ are independent.</p><p>$$\mathbf{Y}=\left[\begin{array}{c}Y_{1} \ \vdots \Y_{n}\end{array}\right]$$</p><p>$$</p><p>\varepsilon_{i} \sim N\left(0, \sigma_{i}^{2}\right),
\quad E(\varepsilon)=\mathbf{0}
$$</p><p>$$
E(\mathbf{Y}) = \mathbf{X} \boldsymbol{\beta}
$$</p><p>$$
\quad \operatorname{Cov}(\mathbf{Y})=\operatorname{Cov}(\varepsilon)=\sigma^{2} \mathbf{I}
$$</p><p>$$
\begin{aligned}
\operatorname{Cov}(\hat{\boldsymbol{\beta}}) &=\left(\mathbf{X}^{\prime} \mathbf{X}\right)^{-1} \mathbf{X}^{\prime} \operatorname{Cov}(\boldsymbol{Y}) \mathbf{X}\left(\mathbf{X}^{\prime} \mathbf{X}\right)^{-1} \<br>&=\left(\mathbf{X}^{\prime} \mathbf{Z}\right)^{-1} \mathbf{Z}^{\prime}\left(\sigma^{2} \boldsymbol{I}\right) \mathbf{X}\left(\mathbf{Z}^{\prime} \mathbf{Z}\right)^{-1} \<br>&=\sigma^{2}\left(\mathbf{Z}^{\prime} \mathbf{Z}\right)^{-1}
\end{aligned}
$$</p><h2 id=the-joint-distribution-of-the-estimators>The Joint Distribution of the Estimators</h2><p>Let</p><p>$$
\left( \mathbf{X}^{\prime} \mathbf{X}\right)^{-1}<em>{p\times p}=\left[\begin{array}{ccc}\xi</em>{00} & \cdots & \xi_{0 p-1} \\xi_{1 0} & \cdots & \xi_{1 p-1} \\vdots & \ddots & \vdots \\xi_{p-1 0} & \cdots & \xi_{p-1 p-1}\end{array}\right]</p><p>$$</p><p>$$
E(\widehat{\boldsymbol{\beta}})=\left(\mathbf{X}^{\prime} \mathbf{X}\right)^{-1} \mathbf{X}^{\prime} E(\mathbf{Y})=\left(\mathbf{X}^{\prime} \mathbf{X}\right)^{-1} \mathbf{X}^{\prime} \mathbf{X} \boldsymbol{\beta}=\boldsymbol{\beta}
$$</p><p>$$</p><p>\operatorname{Var}(\widehat{\boldsymbol{\beta}})=\sigma^{2}\left(\mathbf{X}^{\prime} \mathbf{X}\right)^{-1}=\sigma^{2}\left(\xi_{i j}\right)_{i, j=0, \cdots, k}
$$</p><p>$$
\boldsymbol{\beta}\sim N_{r}\left(\boldsymbol{\beta},\sigma^{2}\left(\mathbf{X}^{\prime} \mathbf{X}\right)^{-1}\right)
$$</p><p>$$
{{\sigma}^{\prime}}^{2}=\frac{\widehat{\varepsilon}^{\prime} \widehat{\varepsilon}}{n-p},\quad \frac{(n-p){{\sigma}^{\prime}}^{2}}{\sigma^2}\sim\chi^2(n-p)
$$</p><p>$$ \frac{\hat\beta_j-\beta_j^{\star}}{\sqrt{\xi_{jj}}{{\sigma}^{\prime}}^{2}}\sim t(n-p)
$$</p><h2 id=prediction>Prediction</h2><p>$$
\widehat{\mathbf{Y}}=\mathbf{x}^{\prime}\left(\mathbf{X}^{\prime} \mathbf{X}\right)^{-1} \mathbf{X}^{\prime} \mathbf{Y}
$$</p><p>$$
\operatorname{Var}(\hat{\mathbf{Y}})=\mathbf{x}^{\prime}\left(\mathbf{X}^{\prime}\mathbf{X}\right)^{-1}\mathbf{x}\sigma^2
$$</p><p>$$
\frac{Y-\hat{Y}}{\sigma^{\prime}\left[1+\mathbf{x}^{\prime}\left(\mathbf{X}^{\prime}\mathbf{X}\right)^{-1}\mathbf{x}\right]^{1 / 2}}\sim t(n-p)
$$</p><h2 id=tests-of-joint-hypotheses>Tests of Joint Hypotheses</h2><p>Test for an overall significant relationship between the response variable and all of the explanatory variables.</p><h3 id=f-test>F Test</h3><p>$$F=\frac{1}{2}\left(\frac{t_{1}^{2}+t_{2}^{2}-2 \hat{\rho}_{t_{1}, t_{2}} t_{1} t_{2}}{1-\hat{\rho}_{t_{1}, t_{2}}^{2}}\right)$$</p><p>The homoskedasticity-only F-statistic</p><p>$$F =\frac{(SSR_{restricted} - SSR_{unrestricted})/q}{SSR_{unrestricted}/(n - k_{unrestricted} - 1)}$$</p><p>$$F =\frac{(R_{unrestricted}^2 - R_{restricted}^2)/q}{(1 - R_{unrestricted}^2)(n -k_{unrestricted} - 1)} $$</p><h2 id=multiple-r-squared>Multiple R Squared</h2><p>In general, $R^2$ never decreases when a regressor is added to the model, regardless of the value of the contribution of that variable. Therefore, it is difficult to judge whether an increase in $R^2$ is really telling us anything important.</p><p>$$R^{2}=1-\frac{\sum_{i=1}^{n}\left(y_{i}-\hat{y}_{i}\right)^{2}}{\sum_{i=1}^{n}\left(y_{i}-\bar{y}\right)^{2}}$$</p><p>$$R^2_{adj}=1-\frac{\hat\sigma^2}{\text {SST}/n-1}=1-\frac{(1-R^2)(n-1)}{n-p}$$</p><h2 id=hidden-extrapolation>Hidden Extrapolation</h2><p>Data extrapolating beyond the region containing the original observations.</p><p>In multiple regression it is easy to inadvertently extrapolate, since the levels of the regressors jointly define the region containing the data.</p><p>Hat Matrix:
$$
\mathbf{H}=\mathbf{X}\left(\mathbf{X}\right)^{-1} \mathbf{X}^{\prime}
$$</p><p>If $h_{ii}>h{max}$, then points are extrapolation points.</p><h2 id=multicollinearity>Multicollinearity</h2><p>$$
VIF_j=\frac{1}{1-R_j^2}
$$
where $R_j^2$ is the coefficient of multiple determination obtained from regressing $x_j$ on the other regressor variables.</p><p>Clearly, if $x_j$ is nearly linearly dependent on some of the other regressors, then $R_j^2$ will be near unity and $VIF_j$ will be large.</p><p>VIFs larger than 10 imply serious problems with multicollinearity.</p></article><hr><div class=page-end><div class=backlinks-container><h3>Backlinks</h3><ul class=backlinks><li>No backlinks found</li></ul></div><div><script src=https://cdn.jsdelivr.net/npm/d3@6></script><h3>Interactive Graph</h3><div id=graph-container></div><style>:root{--g-node:var(--secondary);--g-node-active:var(--primary);--g-node-inactive:var(--visited);--g-link:var(--outlinegray);--g-link-active:#5a7282}</style><script>const index={backlinks:{"/t":[{source:"/Options",target:"/t",text:"S, S"}]},links:{"/Options":[{source:"/Options",target:"/t",text:"S, S"}]}},links=[{source:"/Options",target:"/t",text:"S, S"}],curPage="/Multiple-Linear-Regression",pathColors=[{"/moc":"#4388cc"}],parseIdsFromLinks=a=>[...new Set(a.flatMap(a=>[a.source,a.target]))],data={nodes:parseIdsFromLinks(links).map(a=>({id:a})),links},color=a=>{if(a.id===curPage||a.id==="/"&&curPage==="")return"var(--g-node-active)";for(const b of pathColors){const c=Object.keys(b)[0],d=b[c];if(a.id.startsWith(c))return d}return"var(--g-node)"},drag=c=>{function d(b,a){b.active||c.alphaTarget(1).restart(),a.fx=a.x,a.fy=a.y}function e(a,b){b.fx=a.x,b.fy=a.y}function f(b,a){b.active||c.alphaTarget(0),a.fx=null,a.fy=null}const a=!0,b=()=>{};return d3.drag().on("start",a?d:b).on("drag",a?e:b).on("end",a?f:b)},height=250,width=document.getElementById("graph-container").offsetWidth,simulation=d3.forceSimulation(data.nodes).force("charge",d3.forceManyBody().strength(-20)).force("link",d3.forceLink(data.links).id(a=>a.id)).force("center",d3.forceCenter()),svg=d3.select('#graph-container').append('svg').attr('width',width).attr('height',height).attr("viewBox",[-width/2,-height/2,width,height]),enableLegend=!1;if(enableLegend){const a=[{Current:"var(--g-node-active)"},{Note:"var(--g-node)"},...pathColors];a.forEach((a,b)=>{const c=Object.keys(a)[0],d=a[c];svg.append("circle").attr("cx",-width/2+20).attr("cy",height/2-30*(b+1)).attr("r",6).style("fill",d),svg.append("text").attr("x",-width/2+40).attr("y",height/2-30*(b+1)).text(c).style("font-size","15px").attr("alignment-baseline","middle")})}const link=svg.append("g").selectAll("line").data(data.links).join("line").attr("class","link").attr("stroke","var(--g-link)").attr("stroke-width",2).attr("data-source",a=>a.source.id).attr("data-target",a=>a.target.id),graphNode=svg.append("g").selectAll("g").data(data.nodes).enter().append("g"),node=graphNode.append("circle").attr("class","node").attr("id",a=>a.id).attr("r",a=>{const b=index.links[a.id]?.length||0,c=index.backlinks[a.id]?.length||0;return 3+(b+c)/4}).attr("fill",color).style("cursor","pointer").on("click",(b,a)=>{window.location.href="https://maeve-l.github.io/"+a.id.replace(" ","-").replace("%20","-")}).on("mouseover",function(f,a){d3.selectAll(".node").transition().duration(100).attr("fill","var(--g-node-inactive)");const c=parseIdsFromLinks([...index.links[a.id]||[],...index.backlinks[a.id]||[]]),d=d3.selectAll(".node").filter(a=>c.includes(a.id)),b=a.id,e=d3.selectAll(".link").filter(a=>a.source.id===b||a.target.id===b);d.transition().duration(200).attr("fill",color),e.transition().duration(200).attr("stroke","var(--g-link-active)"),d3.select(this.parentNode).select("text").raise().transition().duration(200).style("opacity",1)}).on("mouseleave",function(d,b){d3.selectAll(".node").transition().duration(200).attr("fill",color);const a=b.id,c=d3.selectAll(".link").filter(b=>b.source.id===a||b.target.id===a);c.transition().duration(200).attr("stroke","var(--g-link)"),d3.select(this.parentNode).select("text").transition().duration(200).style("opacity",0)}).call(drag(simulation)),labels=graphNode.append("text").attr("dx",12).attr("dy",".35em").text(a=>encodeURI(a.id)).style("opacity",0).style("pointer-events","none").call(drag(simulation)),enableZoom=!0;enableZoom&&svg.call(d3.zoom().extent([[0,0],[width,height]]).scaleExtent([.25,4]).on("zoom",({transform:a})=>{link.attr("transform",a),node.attr("transform",a),labels.attr("transform",a)})),simulation.on("tick",()=>{link.attr("x1",a=>a.source.x).attr("y1",a=>a.source.y).attr("x2",a=>a.target.x).attr("y2",a=>a.target.y),node.attr("cx",a=>a.x).attr("cy",a=>a.y),labels.attr("x",a=>a.x).attr("y",a=>a.y)})</script></div></div><div id=contact_buttons><footer><p>Made by Maeve Liu using <a href=https://github.com/jackyzha0/quartz>Quartz</a>, © 2022</p><a href=../>Home</a></footer></div></div></body></html>